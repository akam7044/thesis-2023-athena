{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akam7044/thesis-2023-athena/blob/bert_embeddings/BERT_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSpeEGq27zwA"
      },
      "source": [
        "# Creating BERT embeddings \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run this section when using google collab\n"
      ],
      "metadata": {
        "id": "gwaoexyvSONy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cloud-tpu-client==0.10 torch==2.0.0 torchvision==0.15.1 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZbWcvBP2ZZxg",
        "outputId": "ec8a4dc4-6b1b-48c9-c653-f07315045456"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-xla==2.0\n",
            "  Downloading https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl (162.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.9/162.9 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cloud-tpu-client==0.10\n",
            "  Downloading cloud_tpu_client-0.10-py3-none-any.whl (7.4 kB)\n",
            "Collecting torch==2.0.0\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.1\n",
            "  Downloading torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-api-python-client==1.8.0 (from cloud-tpu-client==0.10)\n",
            "  Downloading google_api_python_client-1.8.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (8.4.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.21.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.1.0)\n",
            "Collecting google-api-core<2dev,>=1.13.0 (from google-api-python-client==1.8.0->cloud-tpu-client==0.10)\n",
            "  Downloading google_api_core-1.34.0-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.2/120.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.16.0)\n",
            "Collecting uritemplate<4dev,>=3.0.0 (from google-api-python-client==1.8.0->cloud-tpu-client==0.10)\n",
            "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.40.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0) (16.0.5)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from torch-xla==2.0) (1.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (2.1.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client==0.10) (4.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.59.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.20.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (5.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.9)\n",
            "Installing collected packages: uritemplate, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, google-api-core, google-api-python-client, cloud-tpu-client, torch-xla, torch, torchvision\n",
            "  Attempting uninstall: uritemplate\n",
            "    Found existing installation: uritemplate 4.1.1\n",
            "    Uninstalling uritemplate-4.1.1:\n",
            "      Successfully uninstalled uritemplate-4.1.1\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 2.11.0\n",
            "    Uninstalling google-api-core-2.11.0:\n",
            "      Successfully uninstalled google-api-core-2.11.0\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 2.84.0\n",
            "    Uninstalling google-api-python-client-2.84.0:\n",
            "      Successfully uninstalled google-api-python-client-2.84.0\n",
            "  Attempting uninstall: torch-xla\n",
            "    Found existing installation: torch-xla 1.0\n",
            "    Uninstalling torch-xla-1.0:\n",
            "      Successfully uninstalled torch-xla-1.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.2+cu118\n",
            "    Uninstalling torchvision-0.15.2+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.2+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "earthengine-api 0.1.350 requires google-api-python-client>=1.12.1, but you have google-api-python-client 1.8.0 which is incompatible.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 2.0.0 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 2.0.0 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cloud-tpu-client-0.10 google-api-core-1.34.0 google-api-python-client-1.8.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 torch-xla-2.0.0.dev20230516+colab torchvision-0.15.1 uritemplate-3.0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "googleapiclient",
                  "nvfuser",
                  "torch",
                  "uritemplate"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports pytorch\n",
        "import torch\n",
        "\n",
        "# imports the torch_xla package\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm"
      ],
      "metadata": {
        "id": "x0-HkCD-SUHC"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates a random tensor on xla:1 (a Cloud TPU core)\n",
        "device = xm.xla_device()\n",
        "t1 =torch.arange(0, 100, device=device)\n",
        "print(t1)"
      ],
      "metadata": {
        "id": "5H0rY36JSaY4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb919c3a-6ff5-4a6e-cc10-7cf255da75fd"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
            "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
            "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
            "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
            "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99], device='xla:1')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLYc0zxsROBF"
      },
      "source": [
        "## Investigate the token problem \n",
        "See what the max tokens is for each csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAsIWcCnROBG",
        "outputId": "a111ba62-f8ce-4b39-8dc7-c7c48eb72202",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUQZgyZK75Nu"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSjB439IROBI",
        "outputId": "b448ba2a-82c2-476c-aeb5-d71af16d558e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([\" Yeah, in London you can go to Oxford Street, which is famous for shopping and there's self-aguse there and a lot of tourists come there and a lot there. So it's a good place to see when you come to London and there's Buckingham Palace where the Queen lives and that's a good place. That's the Royal Family lives so you can come there. And there's other, there's Big Ben, the houses of Parliament where the government, the government are, British government are. So that's a good place to go and there's the London Eye where you can see the whole of London, you go and you can see the whole of London. So that's a good place to visit in London. Yeah, so if I was, I would probably, I would go by public transport then you would see how London really is and you would see the whole of London if you go in a bus or the transport you would see how London is. So I would advice you go on public transport buses and trains so you would really enjoy it. You would get on a like an open tour bus where you can see the whole of London and go around and it doesn't cost that much. So yeah, that's good. Yeah, you can see more of London, yeah. Yeah, yeah. Okay then. Well.\",\n",
              "       \" Okay. Okay. Yes. Okay. So you want to know what places would be nice to visit in London? Yeah. Okay. Well, there are several places you could visit in London. As you know, the world famous Trafalgar Square. There is also the famous Oxford Street where people go a lot for shopping as well as places like Night's Bridge. But in and around London as well, apart from just those sightseeing areas, for me, I also like to look at areas where, you know, in and around London, like those places, there are also nice restaurants and theatres as well for you to go to, not just the sights. But, you know, place, yeah. I would recommend you go by tube because it's a bit quicker in terms of traveling time because of the traffic, really. Okay.\",\n",
              "       \" So this is your first time in London, you've never been here before. So what sort of things are you interested in? Some nice buildings. Well, London has many, many interesting buildings because the city has been around for a very long time. So perhaps you could start by going to the Tower of London, which is on the river. And that's originally a Roman building, which was... It's very nice, it's a bit expensive to get into, but you have to queue for a long while as well. But if you want modern buildings, then there are two places you can go. You can go to the city. City of London has many fine modern buildings. They're named after strange things. The one that looks like a giant cigar is in fact called the Gürkin. Richard Rogers was the architect for that one. There's another one which is in the shape of a walkie-talkie. And another one which is wide at the bottom and narrow at the top is called the Cheese Gracer. But the one that dominates the skyline, I think it's the tallest building in Europe, is the Shard, which was designed by an Italian architect. And you can take a lift up to... You can take a lift up to about two thirds of the way up and get fantastic views. You can also buy very expensive drinks there. Well, the tube is interesting. I know some tourists find it difficult to navigate on the tube. But once you get a hang of the connections and where you get off one station to transfer onto another line, it'll work for you. The bus is good for seeing what's going on outside and there are some very good tourist buses you can hop on and off. Like you can in most big cities, really. Good? Okay.\",\n",
              "       \" Okay, so I'm much very long than you're here. I came here for the first time, by the way from Russia. So, yeah. So, of course, you should visit Vismissar Abbey because of Big Ben Tower. It's a great pleasure to see. It's very beautiful and that bridges around are also very nice across the Thames River and then probably should have a walk towards to the London Eye, have a round on it and come along with a, I think, going to the Omega Tower bridge because it's quite beautiful as well, yeah. So, to their probably the better to go by bus and then by foot. Oh, yeah. From here is possible to go by bus. Okay, should they continue? Okay. No. Sorry? Favorite sport? I think it's no boarding for me. Yeah. Okay, okay, I hope so. Okay.\",\n",
              "       \" Okay, so I'm much very long than you're here. I came here for the first time, by the way from Russia. So, yeah. So, of course, you should visit Vismissar Abbey because of Big Ben Tower. It's a great pleasure to see. It's very beautiful and that bridges around are also very nice across the Thames River and then probably should have a walk towards to the London Eye, have a round on it and come along with a, I think, going to the Omega Tower bridge because it's quite beautiful as well, yeah. So, to their probably the better to go by bus and then by foot. Oh, yeah. From here is possible to go by bus. Okay, should they continue? Okay. No.\",\n",
              "       \" Yes, yes, I've been asked that question before by other visitors and I like to go to suggest people take a river to boat trip down from the Tower of London Which is a very old-estort building down to Greenwich and then walk up the hill to see Greenwich Observatory and look back across the Skyscape of London from there. I think that's a great way of seeing a lot of London. I would suggest, well buses more interesting because you see more but tubes are more direct and probably quicker for longer distances. So a bit of both, depending on whether you want to get somewhere fast or you want to have plenty of time and you want to see buildings as you travel around, buses are great. I think really. Yes, you don't see much on a tube, you see how other people dress and what they're like but you notice much of London really. You see a lot of buses out there. Okay, thank you, thank you.\",\n",
              "       \" Yes, yes, I've been asked that question before by other visitors and I like to go to suggest people take a river to boat trip down from the Tower of London Which is a very old-estort building down to Greenwich and then walk up the hill to see Greenwich Observatory and look back across the Skyscape of London from there. I think that's a great way of seeing a lot of London. I would suggest, well buses more interesting because you see more but tubes are more direct and probably quicker for longer distances. So a bit of both, really depending whether you want to get somewhere fast or you want to have plenty of time and you want to see buildings as you travel around, buses are great. I think really. Yes, you don't see much on a tube, you see how other people dress and what they're like but you notice much of London really. You see a lot of bussie up there. Have a favourite spot in the middle. Oh sport, oh I'm a football fan, yes I must admit. For my sins I support and... Soccer. Yes, sure, yes. Soccer is a team game between 11 people on either side defending a goal which is with playing with a ball by foot. You can't touch with your hands trying to get the ball into the opponent's goal. Yes, it's an interesting game to try and explain. But not a bit of a creek. That's going to set up. Okay. Okay, thank you, thank you.\",\n",
              "       \" So I would go and see the Tower of London, which is near Holborn I think. There's nearby that there's Tower Bridge and there's a nice walk you can do along there. And then some other interesting places would be things like Leicester Square and Piccadilly Circus. Yeah. Boss can be quite nice because then you can see like the streets as you go by but I think tube is quicker and more efficient.\",\n",
              "       \" So I would go and see the Tower of London, which is near Holborn I think. There's nearby that there's Tower Bridge and there's a nice walk you can do along there. And then some other interesting places would be things like Leicester Square and Piccadilly Circus. Yeah. Boss can be quite nice because then you can see like the streets as you go by but I think tube is quicker and more efficient. So I'm not really into spots but I don't mind sometimes like watching rugby or something like that. Oh my god. Not really but there's... oh I have no idea. Like 11 maybe, 11 or 12. It's not my strongest point. I know what, sorry. Ah, okay. To a garment, yeah. Yeah, so yeah I have a favourite dress at home and it's... It's like a turquoisey teal colour. It's a bit... It's more like formal for work and it's just... Yeah, it's a little bit short, just above the knee. Okay, thanks.\",\n",
              "       \" Okay, well the first one that comes to mind is the Tower of London, which is across, which is across from the south of London, and there many historical events have taken place. The other place that is in the west of London is Hampton Court. Have you heard of that? Okay, then again in the centre of London there's the tallest building in Europe is called the Shard, above London Bridge Station, and then if you're right, yes. Well Hampton Court you can go by tube and also London Bridge, you can go by tube and also Tower Hill, so they're all very easily accessed. No, no, there are lots of people on both buses and tube, but I guess if you want to see the surrounding area, it's better to be on a bus, but it'll take a lot longer. Okay.\",\n",
              "       \" Okay, well first of all welcome to London and some of the places that I would recommend are the British Museum. Up in the university area is a fantastic collection of collectives sorts and then the Museum area of the Victoria and Albert and National Natural History and the Science Museum. I've right up near Hyde Park are very interesting and then if you go one thing that I've enjoyed doing in the past is to get the Docklands Light Railway through the Old Docklands which is now Canary Wharf in the New Industrial Area but you get a good above ground view of the redevelopment and it's very interesting in the Old Docks and the east of part of London so that's something a bit different. More to get to the British Museum and the Science Museum I would recommend the Tube but to go around the east end of London I would suggest going on the Docklands Light Railway. Okay shall I switch off?\",\n",
              "       \" Okay, well first of all welcome to London and some of the places that I would recommend are the British Museum. Up in the university area is a fantastic collection of collectives sorts and then the Museum area of the Victoria and Albert and National Natural History and the Science Museum. I've right up near Hyde Park are very interesting and then if you go one thing that I've enjoyed doing in the past is to get the Docklands Light Railway through the Old Docklands which is now Canary Wharf in the New Industrial Area but you get a good above ground view of the redevelopment and it's very interesting in the Old Docks and the east of part of London so that's something a bit different. More to get to the British Museum and the Science Museum I would recommend the Tube but to go around the east end of London I would suggest going on the Docklands Light Railway. I'll be make it difficult for you and say I prefer cricket but it could be football. Football not much so much because there is a very famous explanation of cricket about when people are in their out and when they're out they're in but it's a case of it's very interesting and amusing to read but it's quite a complicated game with a bowler and a fielding side trying to bowl out a side that's batting and trying to score runs and the objective is to score more runs from one side than the other but you can be caught out or bowled out or run out there are all sorts of intricacies but it's very time consuming it can go on for five days so it's a bit longer than a game of football. Okay shall I switch off?\",\n",
              "       \" about what? Sorry about what? Oh where I come from? Yes I come from North Germany. I've grown up there but my parents I was born in Gryfswald which is in East Germany. My parents came over before the war was built. They fled so we stayed in a refugee camp and then my parents worked in North Germany. Okay and I came to England when I met my husband. We met when I was in a pair for three months during my studies at university in Kiel and so we kept in touch and then we lived abroad for a few years and yeah so our life then was in the south of England and yeah we now live in the new forest which is a lovely area near South Empton, Bournemouth and it's beautiful with lots of ponies and cattle walking around freely. It's a lovely area. You can go to the beach in half an hour and where we are is a national park so I can recommend it to you to come and visit. Yeah you can take the train. Yeah you can take the train. Yeah okay.\",\n",
              "       \" Okay, so in London there are lots of different places, lots of different areas and it really just depends where you're staying. But I would always say that it's good to go to the centre of London so maybe somewhere like Piccadilly Circus. There's a really nice restaurant there which are quite like going to which is called Zedelles and it's kind of a brazary so there's a cafe upstairs and you go downstairs and there's a massive old-style English kind of hall with lots of marble and nice tables and it's a Parisian-style restaurant and also there's a cocktail bar there but there's also jazz that plays I think it might be in the evening so while you're having a dinner they play music. So that's a really lovely place. Yeah. So all of the museums are free in London which is great and so in that similar area which is kind of around Trafalgar Square is the National Portrait Gallery which is really beautiful and there's lots of floors and lots of different kinds of artwork and there is also another one. I can't quite remember the name but it's just opposite Green Park Station which is maybe one tube stop down from Piccadilly Circus and it's kind of hidden a bit further back and it's very nice there. If you're going from here you could take a bus. There's a bus just outside the front of the hospital or if you want to take the tube it's best to get to Elephant and Castle and then you can either take the Northern line or I think it's the Bakerloo line. Okay, you're welcome.\",\n",
              "       \" most impressive. I guess I would say it's I like London. Okay, I like Greenwich. Greenwich is I think it's more city nearby and you can spend a day there and you can visit markets or garden within the same visit. Yeah, I seldom play sports but I like yoga. Yeah, so I have been practicing yoga so yeah. Okay, you mentioned about the okay. Yeah, I like yoga and I have been practicing yoga since 10 years ago and why I like yoga basically it helped me to relax and it also improved my flexibility. Yeah, and yeah, I would say that. I would recommend other people's to to take up yoga if they are interested in yes. Yeah, I am a neurologist. I'm currently in London for a year but prior to this I'm a consultant back in Singapore General Hospital and before this I have been I would say all these years I have been a clinician. Yeah, so I have since my training is start from basics and then I need to take exam in internal medicines then subsequently I specialize in neurology and then I come here for further study about movement disorders. Okay, yes, thank you.\",\n",
              "       \" most impressive. I guess I would say it's I like London. Okay I like Greenwich. Greenwich is I think it's more city nearby and you can spend a day there and you can visit markets or garden within the same visit.\",\n",
              "       \" What are you interested in? Oh, then Central London is always the best place to go. You can find a lot of historical buildings there. Yeah. You could go to the Shard in London Bridge, London Bridge. That's really good. You could take the tube. That would be quicker. Where are you coming from? What? I have no idea where that is. Okay, yeah. Victoria. Oh, okay, then. Yes, I guess you can take that to Green Park, Victoria Line. And then from Green Park, you can take the Jubilee Line down to London Bridge. Yeah. So I work in research for Parkinson's disease. And I help with collecting a lot of data for observational studies and clinical trials. So I have a background in psychology and with a bit of neuroscience and mental health. So the research studies here are like a mixture, yeah. Of everything, yeah. Okay, thanks.\",\n",
              "       \" What are you interested in? Oh, then Central London is always the best place to go. You can find a lot of historical buildings there. Yeah. You could go to the Shard in London Bridge, London Bridge. That's really good. You could take the tube. That would be quicker. Where are you coming from? What? I have no idea where that is. Okay, yeah. Victoria. Oh, okay, then. Yes, I guess you can take that to Green Park, Victoria Line. And then from Green Park, you can take the Jubilee Line down to London Bridge. Yeah.\",\n",
              "       \" Well, I think all the common touristy places are very nice, like back in Capellis and London. I think a path along the south river of the Thames is very nice. The museums are perfect in London. Should I just speak as much as I can? Yeah, the museums are very nice. I don't know if you like art or science. Yeah, the modern and the date bridge now really nice, but the Natural History Museum is very nice. The National Gallery is for free, but just always worth a visit. I would recommend to travel there by bus, because you can also see a little bit about the environment, but otherwise the tube is probably the fastest. Yeah. So I'm a doctor and I have studied medicine in Germany, and then I came over here five years ago, and I now work as a clinical research fellow, which is half clinical work and half research. So my special field, I would say, is the impact of ethnicity on Parkinson's disease. So that's my PhD project. Yeah, I compare the presentation of Parkinson's between white Caucasians, Asians, and African-Curivians. Okay, thank you, bye.\",\n",
              "       \" Well, I think all the common touristy places are very nice, like back in Capellis and London. I think a path along the south river of the Thames is very nice. The museums are perfect in London. Should I just speak as much as I can? Yeah, the museums are very nice. I don't know if you like art or science. Yeah, the modern and the date bridge now really nice, but the natural history museum is very nice. The National Gallery is for free, but just always worth a visit. I would recommend to travel there by bus, because you can also see a little bit about the environment. But otherwise the tube is probably the fastest. Yeah.\",\n",
              "       \" That's the end. Yes, yes. Yes, yes, yes. The most places of interest are the Dutton of Hallis, which is the home of the Queen, which is the centre of the second and the Westminster Ave, which is the main church of England, church and passes. Yes, yes. Sorry, I didn't hear anything. If we need to see the Tower of Parliament where the Government says which is near Western Strabby, so you can do this in the town. What is nice is a trip down the river on one of the boats that you can get to the Tower and you go down and then you come to Greenwich, which is the nasal area. There's the Criticite there, which is a tea triff. There are also in Greenwich area, there's Queen Anne's house. A bus is the easiest way because you get a card, a card from certain shops, and you use the new seduance quite often, seldom. And then you can use that card all day and it will be useful when you enter it. And you can go into any shop and build it up, but the tube is easier if you want to go pretty quickly somewhere. And I wouldn't recommend the train, they're very expensive. Thank you.\",\n",
              "       \" Absolutely, there are many, many places. Now I can hear in your accent that you are not from the UK anyway. So, Andrew German. So, I'm going to be really stereotypical and say you've got to try some beers. Because if you're from Germany, you must love beer. I would say I'm not the best at finding places myself. So, the best thing to do is Google a pub crawl. There are some absolutely fabulous pubs. They're wonderful. The architecture is great. You can go to some John Smith's pubs. They're fantastic. But the landlords of the pubs are always really fabulous. And they'll tell you the history. So, if there's a bit of a haunting in their pub, they're very happy to let you know that. Do you know when in London I always stay above ground. The architecture is lovely. The people have said not to be so friendly, but they are. You smile and say hello. They'll say hello back. I'd probably end up in a strange conversation at a bus stop. So, stay above ground. A bus, if it's a longer distance, keep a lookout. All the buses will now give you the stops that they're stopping at. It's just an automated. It will say park lane or wherever you are. So, it gives landmarks. Oh, walk. Because, honestly, everything is lovely. Lovely. Thank you. Bye.\",\n",
              "       \" So yes, absolutely. You should go and visit some of the London landmarks, such as the Big Ben, the Buckingham Palace and Trophago Square. Also there are some very nice museums where you can go and explore. For example, you can visit the British Museum and Victorian Albert Museum or the Science Museum. In addition, you could just walk around and along the famous streets and like main roads such as Oxford Circus and Piccadilly Circus. Finally, you can walk by the river. This is a very nice prominent from embankment to the Tower Bridge. Okay, so I would suggest you travel on a bus because you would be able to be looking outside, with wheels traveling. Yes, that's true. Also the tube is more expensive. You're welcome.\",\n",
              "       \" So yes, absolutely. You should go and visit some of the London landmarks, such as the Big Ben, the Buckingham Palace and Trophago Square. Also there are some very nice museums where you can go and explore. For example, you can visit the British Museum and Victorian Albert Museum or the Science Museum. In addition, you could just walk around and along the famous streets and like main roads such as Oxford Circus and Piccadilly Circus. Finally, you can walk by the river. This is a very nice prominent from embankment to the Tower Bridge. Okay, so I would suggest you travel on a bus because you would be able to be looking outside, wheels traveling. Yes, that's true. Also the tube is more expensive. You're welcome. My favorite sport is football, yes. Yes, I will try to do that. I'm not very good with football terminology but I will do my best. So to play football, you need to have two teams, 11 players each, you need to have a ball and a referee. So you usually go out to play football in a stadium as opposed to a pitch and each football game lasts for about, no, it lasts 90 minutes. Yes, do you want to know the rules of football or was that enough? Yeah, you're welcome.\",\n",
              "       \" Okay, well in London the whole of London is fantastic. Every little corner of London has something of interest, but perhaps the area that I like most is the temple area near the Thames. It's an area where there's a lot of history and a lot of the legal things are there. And there's a church that is very nice to visit as well. Do you want me to carry on? Something else, okay. Well I think the best if you really want to see London is to use the buses because they knew above the ground and there's so much to see. Yeah, if you need to get quickly from point A to point B, maybe the tube is better, but otherwise it's better on the bus. Especially up at the top, okay. Yes? All right, thanks very much.\",\n",
              "       \" Okay, well in London the whole of London is fantastic. Every little corner of London has something of interest, but perhaps the area that I like most is the temple area near the Thames. It's an area where there's a lot of history and a lot of the legal things are there. And there's a church that is very nice to visit as well. Do you want me to carry on? Something else, okay. Well I think the best if you really want to see London is to use the buses because they knew above the ground and there's so much to see. Yeah, if you need to get quickly from point A to point B, maybe the tube is better, but otherwise it's better on the bus. Especially up at the top, okay. Okay, well I have a wonderful profession. I am on holiday all the time. I was a teacher, okay. So I was a teacher and I was a psychology teacher, which is in South Africa we call it a guidance counselor at a high school. And that was very, very interesting work and I really enjoyed it a lot. Yeah, but I'm retired now so I'm on holiday. All right, thanks very much.\",\n",
              "       \" See that again. Vity the hospital, the hospital like gets a stomachache. You have Vity the hospital's stomachache as you Vity the kids college hospital. Vity the stomachache is London bridge, guys hospital. Sorry. Gloucester road, Gloucester road. That is the marble lash. It should be marble lash side, yeah, yeah, yeah, Gloucester road. Why is it full school? Okay then, okay then, okay, thanks.\",\n",
              "       \" Well, there are so many nice buildings, get yourself a good map and walk. There is so much to see in London and you can choose any building you want. Well, I love the British Museum. Bus. Because you can see as it's going through, you can see the rest of London.\",\n",
              "       \" Well, there were so many nice buildings, get yourself a good map and walk. There is so much to see in London and you can choose any building you want. Well, I love the British Museum. Bus. Because you can see as it's going through, you can see the rest of London. I was a teacher, I'm now retired. I was a teacher of junior aged children. Okay, bye.\",\n",
              "       \" I would recommend most of the museums, the Science Museum in particular. I think the Science Museum is one of my favourites. Whereabouts? Tower of London, more of the cultural side. I depend where you're coming from. I would go by public transport to the Tower of London and get the district of Circle Line. Okay?\",\n",
              "       \" I would recommend most of the museums, the Science Museum in particular. I think the Science Museum is one of my favourites. Whereabouts? Tower of London, more of the cultural side. I depend where you're coming from. I would go by public transport to the Tower of London. I get the district of Circle Line. I've no retired, but my profession was a civil engineer by training. I specialised in transport planning.\",\n",
              "       \" Okay, I think it's good to have a walk along by the river, just to sort of get the atmosphere of London, to go to Covent Garden, where maybe sort of visit some of the museums. Obviously go out for a nice meal or two, go to the theatre, there's lots of shows that you might be interested in and you get some last minute deals as well to make save a bit of money on those. Yeah, it depends where you're coming from. You can sort of do a lot of walking as well, which is good. It's pretty easy, but I say just do lots of walking, you can walk to see big ben, houses of parliament, walk along the river to the south bank, see some of the art galleries, that sort of thing. So you can do lots of walking as well. Okay, alright.\",\n",
              "       \" Okay, I'm gonna recommend Central London. Yeah, go to Transvaga Square. You know, lots of sites in there. I recommend to drive by bus. Let's go on the bus. Yeah, so you'll be able to, you know, see everywhere. If you go by train, yeah. Yeah, yeah. Okay, okay, thank you.\",\n",
              "       \" Okay, thank you. This is great. Now let's try to have this container dialogue. I will start with a question. It's my first time in London. And can you recommend a place? I should with it, for example, places with the night buildings. Okay. I'm going to recommend Central London. Yeah, go down to Transfagga Square. You know, lots of sightseeing there. Okay. And would you recommend to drive by the bus by rail or by tube? I would recommend to drive by a bus. To go on the bus. Okay, for which reason? Yeah, so you'll be able to see everywhere. Okay, if you're good by train, yeah. Okay, yes, once you drive with you. Yeah, yeah. Let's try another topic. Do you have a favourite sport? Do I have what? A favourite sport, like tennis volleyball football or tennis? Nah. I don't have a favourite sport. Okay, yeah, I do swimming. It's swimming there. Okay. Can you roughly explain what is this sport about? Just to end this for change of dialogue. Okay, it's all about trying to build your body. Work out your body in the water. Yeah. Okay, good. Let's try a last topic. Can you tell me something about your profession? Okay. I work in the hospital as a nursing assistant. So I meet patients every day. What? Yeah, I meet patients every day. Help them with, you know, doing... Yes, yes, I do. Yeah, I love my work. Great. Okay, I think there's a lot of thank you. All right, then, thank you. Okay, thank you.\",\n",
              "       \" Well, the buildings that most people want to see are the Tower of London, the houses of Parliament, Buckingham Palace, and then perhaps you can go to the Royal Academy, the National Gallery, Summer Set House, or perhaps you would like to go and see some of the more modern buildings like the Gherkin, the Cheese Grater, where you can actually go up for free and see the whole of Ed London from the top or the Shard, the Shard isn't okay, is that enough? Thank you very much, bye!\",\n",
              "       \" Well, the buildings that most people want to see are the Tower of London, the houses of Parliament, Buckingham Palace, and then perhaps you can go to the Royal Academy, the National Gallery, Summer Set House, or perhaps you would like to go and see some of the more modern buildings like the Gherkin, the Cheese Grater, where you can actually go up for free and see the whole of Ed London from the top or the Shard, the Shard isn't okay, is that enough? Well, I'm a volunteer, I've been a volunteer for 20 years, giving out working, giving out information and epilepsy. I used to run a support group for people with epilepsy once a month. I've been trained to do this and I've been enjoyed it. I ended up doing this because I had to retake medical retirement, usually the level of seizures. I was having, which meant that teaching was no longer able to keep on teaching. Is that enough? All right, I can talk. Endless about epilepsy. Thank you very much. Bye.\",\n",
              "       \" You should visit the shard and see London from the top. You should visit Buckingham Palace and see the state rooms and the open rooms of Buckingham Palace. And perhaps go to Apsley House. We visited recently. Apsley House is at the bottom of Hyde Park on Hyde Park Corner and is an English Heritage property used to be frequented by the Duke of Wellington I think. I would always travel by tube because it's easy to understand the map. It's certainly not a rail journey and the bus is you need to know the routes. I don't know the bus routes so personally I would say tube. Okay, thank you.\",\n",
              "       \" You should visit the shard and see London from the top. You should visit Buckingham Palace and see the state rooms and the open rooms of Buckingham Palace. And perhaps go to Apsley House. We visited recently. Apsley House is at the bottom of Hyde Park on Hyde Park Corner and is an English Heritage property used to be frequented by the Duke of Wellington I think. I would always travel by tube because it's easy to understand the map. It's certainly not a rail journey and the bus is you need to know the routes. I don't know the bus routes so personally I would say tube. I don't really have a favourite sport place to watch basketball quite a lot. We went to London Arena. The game is split up into four quarters and there are two teams. The teams have to get the ball through the hoop at the other end for which they get two or three. Points. Sometimes they're a penalty shootouts and often the game can change. It's direction very quickly in seconds as the clock's run towards the end of the 10 minute quarters. Okay, thank you.\",\n",
              "       \" I would suggest you go to the house of the parliament. I suggest you go to... is that okay? They have another building in the centre of London. I can't remember the name of the building. But yeah, there's quite a few buildings you can go and see. Buckingham Palace. Buckingham Palace, you know that one? Big Ben, yes, Big Ben is quite nice, but they're having work done at the moment. It's a big Ben. I would recommend you go by bus, because if you go by bus, the reason why I would suggest this is because you might see some other landmarks that might interest you and, you know, yeah, that's the end of the reason. That's right, that's...\",\n",
              "       \" I would suggest you go to the house of the parliament. I suggest you go to... is that okay? They have another building in the centre of London. I can't remember the name of the building. But yeah, there's quite a few buildings you can go and see. Buckingham Palace. Buckingham Palace, you know that one? Big Ben, yes. Big Ben is quite nice, but they're having work done at the moment. It's a big Ben. I would recommend you go by bus. Because if you go by bus, the reason why I would suggest this is because you might see some other places... Some other landmarks that might interest you and, you know... Yeah, that's the end of the reason. That's right, that's... The profession I'm working in the health trust, I'm a clinical support worker. Which I support, the clinic, I support doctors and nurses in the clinical area. And the job's okay. Can be interesting. I also work with the Parkinson's department and the M&D MS. We do a lot of new political problems in the department. Okay. You're welcome. Lovely. Thank you.\",\n",
              "       \" Okay, well I definitely think you should visit the Royal Parks in London. There's St James's, Hyde Park and Green Park and there is the Serpentine which I think is in Hyde Park and during the summer months you can go and you can swim with the ducks and the geese. So that's a lovely place to go. I would also maybe go to some of the museums. There's the Natural History Museum and the Science Museum. Where else should I go? Okay, I would definitely go on the cheap. The buses are okay but sometimes it can be quite busy on the road so I would use the cheap. Okay.\",\n",
              "       \" Okay, well I definitely think you should visit the Royal Parks in London. There's St James's, Hyde Park and Green Park and there is the Serpentine which I think is in Hyde Park and during the summer months you can go and you can swim with the ducks and the geese. So that's a lovely place to go. I would also maybe go to some of the museums. There's the Natural History Museum and the Science Museum. Where else should I go? Okay, I would definitely go on the cheap. The buses are okay but sometimes it can be quite busy on the road so I would use the cheap. Okay, well I used to be a swimming teacher so that is what related but I used to teach, I used to teach school children so it was during the daytime and we'd have coach loads of children arrive at the pool and it was my job to put them into different groups whether they couldn't swim or whether they could swim very well and then we had about ten weeks to get the non-shrimmers swimming and then we would teach them all different strikes. Okay, okay, thank you.\",\n",
              "       \" I believe you all me, I may be here a little bit, but I don't know much about London myself. If I ever go up London sites, I have done naturally enough. I just start out from point B and just walk round and if I walk into the leaf site and want to look at, then I do so. But no, it's a bit tiring and it's also walking around. But it's quite pleasant. All you've got to do is make sure it doesn't rain. I think I go by bus because the Chichubism isn't known. I went up, like, a couple of years ago for the first time in about 15, 18 years because I'm not being used to using my messenger. And it would be well, well, when I'm shaking along, I thought we'd just eat a wrap at a patch on the track. It wasn't, it was the actual train itself. And I don't know, people will walk through, I'll do work on those things. I should never know.\",\n",
              "       \" I believe you all me, I may be here a little bit, but I don't know much about London myself. If I ever go up London sites, I have done naturally enough. I just start out from point B and just walk round and if I walk into the leaf site and want to look at, then I do so. But no, it's a bit tiring and it's also walking around. But it's quite pleasant. You all you've got to do is make sure it doesn't rain. I think I go by bus because the Chitu is a no-no. I went on it a couple of years ago for the first time in about 15, 18 years because I'm not being a bit unusual to use him as a messenger. And we went on a shake. It's shaking along the line. I thought we'd just ate a rough bit of patch on the track. It wasn't. It was the actual train itself. I wonder what had worked on those things. I should never know. Well actually, I'm retired now. I've been retired now for about 15 years, I think. I was 40 years. I was a postman. Well, it's not much to do. You do have to get up at 5 o'clock in the morning, six days a week. And just to go down, if you like, I was lucky. I would work for local. I really, really did have to use the pass to go to work on. And just as I just walked straight down the road, pick up the work here on my master. And then the government's going to decide if it is getting going, but it doesn't matter what time it is until some bright spot got there. They all got different. We were absolutely, we were told to pack it up.\",\n",
              "       \" Well, I've always found that Buckingham Palace and Trafalgar Square and the Tower of London, they're very interesting, been there quite a lot myself over the years, and there's quite a lot in London really. Yeah. Well, the tubes, the best option because it gets you to place is quicker. I used to travel there when I was at work, but it's very claustrophobic. I mean, bass is fine because you see more on the route, but if you want to get there, they quit. Yeah.\",\n",
              "       \" Well, I've always found that Buckingham Palace and Trafalgar Square and the Tower of London, they're very interesting, been there quite a lot myself over the years, and there's quite a lot in London really. Yeah. Well, the tubes, the best option because it gets you to place is quicker. I used to travel there when I was at work, but it's very claustrophobic. I mean, bass is fine because you see more on the route, but if you want to get there, wait, yeah. I used to be a payroll supervisor. I was made redundant in 2001 when I stayed at home, looked after my mum, and then of course I now look after my brother. But when I was at work, I used to work at my blotch, so I had to get the tube every day or, and then I got the train. But I used to do all the payroll for the whole country of CNA, or I used to work for. Okay.\",\n",
              "       \" where you've got a horse guard's parade, wedding barracks, Buckham and Palace, you've got night's bridge, isn't there the dolly? Because I did a good change in the guard, which is when the residence changed over the guard duties. You've got the history in it, National Museum, you've got the sights in the museum, you've got the British Warn Museum, you've got loads of stuff in there, don't see. And don't forget the Christmas lights, it's here, breaking up a little bit. Go on the NJUK TO, do a train up, yeah, okay.\",\n",
              "       \" where you've got a horse guard's parade, wedding barracks, Buckham and Palace, you've got night's bridge, isn't there the dolly? Because I did a good change in the guard, which is when the residence changed over the guard duties. You've got the history in it, National Museum, you've got the sights in the museum, you've got the British Warn Museum, you've got loads of stuff in there, don't see. And don't forget the Christmas lights, it's here, breaking up a little bit. Going to the NXUTO, my confession, what do I do? I'm retired. Hobbies, I don't use the light going then, Jim and Danny Bitter will work out. I do shoeing, air rifles, remote control cars, and stuff, planes. Do you join up? Yeah, OK.\",\n",
              "       \" The thing I'd recommend is that you take one of the red bus tours. You can get an open-topped red bus and it will go to all the main sites. Buckingham Palace, the Tower of London, Westminster Bridge and Big Ben. And you can get on the bus and get off the bus whenever you like and it's very good value. Okay.\",\n",
              "       \" The thing I'd recommend is that you take one of the red bus tours. You can get an open-topped red bus and it will go to all the main sites. Buckingham Palace, the Tower of London, Westminster Bridge and Big Ben. And you can get on the bus and get off the bus whenever you like and it's very good value. Okay, well I'm retired now but I was a geography teacher. I have a bachelor's degree and a master's degree in geography and I taught university, high school, middle school and primary school. My what? Hobbies? Hobbie. Okay, well I do a lot of volunteering for Parkinson's UK so I suppose that's a hobby. I love gardening, we have a big garden. We have a dog and I love playing with our dog. And I like going to the theatre and the opera and reading. Okay.\",\n",
              "       \" St. James's Park in London and Buckingham Palace. Sorry. I see now what other places. Travolga Square, Travolga Square and Buckingham Palace. We've done Buckingham Palace with Minister, with Minister, Lambert Bridge.\",\n",
              "       \" What type of food do you like? Indian, Chinese, English, which one do you like the most? The special restaurant is in Southeast. It's called Tamasha. It's in Bromley. They are catered for the four-industry nationalities to taste the Indian restaurant. And it's been prepared, especially for them. From here, it's easy to go by train to Bromley South. One train from Denmark, Australia, Australia Bromley South, and take a taxi or walk to the distance. About ten minutes walk. Sorry.\",\n",
              "       \" I recommend seeing the city of London and going to South Kensington to see the museums. And there are lots of places to eat along Oxford Street. I can't think of any more. Where else? It depends what your interests are, I guess. Art galleries are always around and they're all free to go and visit. Sorry, I can't hear you very well. No, I didn't hear you, I'm sorry. You just cut out, just as you're saying something. So I'm afraid I can't hear you very well. Sorry. I can't hear you. I'm so sorry.\",\n",
              "       \" some places, can you repeat your questions please. London Bridge and London Eye and Travel Square and Madame Tusa and Kent. Sorry I couldn't hear. Can you repeat that? By train. Train is quicker than bus. Okay. Okay then yeah thank you.\",\n",
              "       \" some places, can you repeat your questions please. London Bridge and London Eye and Travel Square and Madame Tusa and Kent. Sorry I couldn't hear. Can you repeat then? By train. Train is quicker than bus. Sorry. Hello. Professional. What profession? You mean the accountant? Yeah. Okay. Thank you.\",\n",
              "       \" Right, if you would like to see some interesting places in London, I will suggest that you go to first of all the Big Pen. I mean to see the West Mr. Abbey and the Big Clock and then probably go to the Bakheon Palace. Yeah. Nice restaurant. I mean, honestly speaking, I mean I haven't been to many restaurants around here, but I will recommend the Lebanese restaurant. Okay. I think it's easy for you to travel by tube to King's College from Central London. Yeah. All right, thank you.\",\n",
              "       \" Right, if you would like to see some interesting places in London, I will suggest that you go to first of all the Big Pen. I mean to see the West Mr. Abbey and the Big Clock and then probably go to the Bakheon Palace. Yeah. Nice restaurant. I mean, honestly speaking, I mean I haven't been to many restaurants around here, but I will recommend the Lebanese restaurant. Okay. I think it's easier for you to travel by tube to King's College from Central London. Right. I'm currently a neurology trainee in a movement disorder. I'm trained in Malaysia now. I'm doing one year for research in movement disorder with Professor Chaudhry. All right. Thank you.\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    Ye m in london ygoi to  oxford streets which i...\n",
              "1    O k k yes o k am am so you want you want to kn...\n",
              "2    So this is your your first time in london you'...\n",
              "3    E i so i am not very  londoner here i camp her...\n",
              "4    I iso i am not very londoner here i came here ...\n",
              "Name: transcripts, dtype: object"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0     Yeah, in London you can go to Oxford Street, ...\n",
              "1     Okay. Okay. Yes. Okay. So you want to know wh...\n",
              "2     So this is your first time in London, you've ...\n",
              "3     Okay, so I'm much very long than you're here....\n",
              "4     Okay, so I'm much very long than you're here....\n",
              "Name: transcripts, dtype: object"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd \n",
        "\n",
        "df_whisper = pd.read_csv('/spontaneousDialougeOnly_whisper.csv')\n",
        "df_wav2vec = pd.read_csv('/spontaneousDialougeOnly_wav2vec.csv')\n",
        "df_google  = pd.read_csv('/spontaneousDialougeOnly_whisper.csv')\n",
        "\n",
        "display(df_whisper['transcripts'].values)\n",
        "display(df_wav2vec['transcripts'].head())\n",
        "display(df_google['transcripts'].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJn83VOsROBJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "3ddfde62-fc42-4b56-eac4-d136c4870ef5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Max token whisper:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "390"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Max token wav2vec:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "420"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Max token google:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "390"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "def find_max_token (df):\n",
        "    max_len = 0\n",
        "    transcripts = df['transcripts'].values\n",
        "\n",
        "    for transcript in transcripts:\n",
        "        input_ids = tokenizer.encode(transcript,add_special_tokens=True)\n",
        "        max_len = max(max_len,len(input_ids))\n",
        "    \n",
        "    return max_len\n",
        "\n",
        "max_len_whisper = find_max_token(df_whisper)\n",
        "max_len_wav2vec = find_max_token(df_wav2vec)\n",
        "max_len_google = find_max_token(df_google)\n",
        "\n",
        "display('Max token whisper:',max_len_whisper)\n",
        "display('Max token wav2vec:',max_len_wav2vec)\n",
        "display('Max token google:',max_len_google)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPN7XqWWROBK"
      },
      "source": [
        "All fit within the max limit for 516 so we are okay. The max token will be set to 450 just incase there is any problem. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHqME3wsROBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c576c116-2cbb-4492-94a4-72083a68ec15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "184\n",
            "186\n"
          ]
        }
      ],
      "source": [
        "print(len(tokenizer.tokenize(df_whisper.transcripts.values[10])))\n",
        "print(len(tokenizer.encode_plus(df_whisper.transcripts.values[10])['input_ids']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwlqLjy1ROBL"
      },
      "source": [
        "So the encoder doesn't split the transcript into sentences ...\n",
        "\n",
        "So to start off with I will generate embeddings for the WHOLE transcript"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee-CK1BEROBL"
      },
      "source": [
        "### Generate Tokens for the whole transcript"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaTDaJkoROBM"
      },
      "source": [
        "http://mccormickml.com/2019/07/22/BERT-fine-tuning/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b21SQp8uROBM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs6jmFaQROBM"
      },
      "source": [
        "### Whisper \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwsWy-hHROBM"
      },
      "outputs": [],
      "source": [
        "transcripts = df_whisper.transcripts.values\n",
        "labels = df_whisper.classification.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59Ooaq27ROBM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d37cfbdd-2191-4e62-ba0c-24e016b0a829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:   Yeah, in London you can go to Oxford Street, which is famous for shopping and there's self-aguse there and a lot of tourists come there and a lot there. So it's a good place to see when you come to London and there's Buckingham Palace where the Queen lives and that's a good place. That's the Royal Family lives so you can come there. And there's other, there's Big Ben, the houses of Parliament where the government, the government are, British government are. So that's a good place to go and there's the London Eye where you can see the whole of London, you go and you can see the whole of London. So that's a good place to visit in London. Yeah, so if I was, I would probably, I would go by public transport then you would see how London really is and you would see the whole of London if you go in a bus or the transport you would see how London is. So I would advice you go on public transport buses and trains so you would really enjoy it. You would get on a like an open tour bus where you can see the whole of London and go around and it doesn't cost that much. So yeah, that's good. Yeah, you can see more of London, yeah. Yeah, yeah. Okay then. Well.\n",
            "Token IDs: tensor([  101,  3398,  1010,  1999,  2414,  2017,  2064,  2175,  2000,  4345,\n",
            "         2395,  1010,  2029,  2003,  3297,  2005,  6023,  1998,  2045,  1005,\n",
            "         1055,  2969,  1011, 12943,  8557,  2045,  1998,  1037,  2843,  1997,\n",
            "         9045,  2272,  2045,  1998,  1037,  2843,  2045,  1012,  2061,  2009,\n",
            "         1005,  1055,  1037,  2204,  2173,  2000,  2156,  2043,  2017,  2272,\n",
            "         2000,  2414,  1998,  2045,  1005,  1055, 17836,  4186,  2073,  1996,\n",
            "         3035,  3268,  1998,  2008,  1005,  1055,  1037,  2204,  2173,  1012,\n",
            "         2008,  1005,  1055,  1996,  2548,  2155,  3268,  2061,  2017,  2064,\n",
            "         2272,  2045,  1012,  1998,  2045,  1005,  1055,  2060,  1010,  2045,\n",
            "         1005,  1055,  2502,  3841,  1010,  1996,  3506,  1997,  3323,  2073,\n",
            "         1996,  2231,  1010,  1996,  2231,  2024,  1010,  2329,  2231,  2024,\n",
            "         1012,  2061,  2008,  1005,  1055,  1037,  2204,  2173,  2000,  2175,\n",
            "         1998,  2045,  1005,  1055,  1996,  2414,  3239,  2073,  2017,  2064,\n",
            "         2156,  1996,  2878,  1997,  2414,  1010,  2017,  2175,  1998,  2017,\n",
            "         2064,  2156,  1996,  2878,  1997,  2414,  1012,  2061,  2008,  1005,\n",
            "         1055,  1037,  2204,  2173,  2000,  3942,  1999,  2414,  1012,  3398,\n",
            "         1010,  2061,  2065,  1045,  2001,  1010,  1045,  2052,  2763,  1010,\n",
            "         1045,  2052,  2175,  2011,  2270,  3665,  2059,  2017,  2052,  2156,\n",
            "         2129,  2414,  2428,  2003,  1998,  2017,  2052,  2156,  1996,  2878,\n",
            "         1997,  2414,  2065,  2017,  2175,  1999,  1037,  3902,  2030,  1996,\n",
            "         3665,  2017,  2052,  2156,  2129,  2414,  2003,  1012,  2061,  1045,\n",
            "         2052,  6040,  2017,  2175,  2006,  2270,  3665,  7793,  1998,  4499,\n",
            "         2061,  2017,  2052,  2428,  5959,  2009,  1012,  2017,  2052,  2131,\n",
            "         2006,  1037,  2066,  2019,  2330,  2778,  3902,  2073,  2017,  2064,\n",
            "         2156,  1996,  2878,  1997,  2414,  1998,  2175,  2105,  1998,  2009,\n",
            "         2987,  1005,  1056,  3465,  2008,  2172,  1012,  2061,  3398,  1010,\n",
            "         2008,  1005,  1055,  2204,  1012,  3398,  1010,  2017,  2064,  2156,\n",
            "         2062,  1997,  2414,  1010,  3398,  1012,  3398,  1010,  3398,  1012,\n",
            "         3100,  2059,  1012,  2092,  1012,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
          ]
        }
      ],
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for transcript in transcripts:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        transcript,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 450,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', transcripts[0])\n",
        "print('Token IDs:', input_ids[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbANCgemROBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d4fdfdf-10b3-4b69-d655-889bb753eb54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   51 training samples\n",
            "    6 validation samples\n"
          ]
        }
      ],
      "source": [
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "IglMHaCVROBN"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "#model.cuda()"
      ],
      "metadata": {
        "id": "nqYm3NZ0RS7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d2c26e-0413-4b97-d6ff-bc18e2df7edf"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9mAbvyuTuei",
        "outputId": "b33f9855-294f-4972-c889-a5f32222a48f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9Swagg-Ty9i",
        "outputId": "60ec7142-1342-4a89-c008-e987f026140a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "DVIa4bNkT5lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score,confusion_matrix\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "DkPUG-Y-T-_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "metadata": {
        "id": "SoQNs5dRUXbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "model.to(device)\n",
        "print(model)\n",
        "print(device)\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        output = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        loss = output.loss\n",
        "        logits = output.logits\n",
        "        print(loss)\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        #loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_oLOb0mUZwW",
        "outputId": "08e76977-a989-4569-b58a-17e81ad795a5"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertForSequenceClassification(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
            ")\n",
            "xla:1\n",
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "tensor(0.5948, device='xla:1', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6350, device='xla:1', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6449, device='xla:1', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0139, device='xla:1', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "  Average training loss: 0.72\n",
            "  Training epcoh took: 0:01:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.33\n",
            "  Validation Loss: 0.75\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "tensor(0.6681, device='xla:1', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6513, device='xla:1', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6805, device='xla:1', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5923, device='xla:1', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "  Average training loss: 0.65\n",
            "  Training epcoh took: 0:01:35\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.33\n",
            "  Validation Loss: 0.75\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "tensor(0.6514, device='xla:1', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6392, device='xla:1', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6222, device='xla:1', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6782, device='xla:1', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "  Average training loss: 0.65\n",
            "  Training epcoh took: 0:01:52\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.33\n",
            "  Validation Loss: 0.75\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "tensor(0.6295, device='xla:1', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7206, device='xla:1', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7164, device='xla:1', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5438, device='xla:1', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "  Average training loss: 0.65\n",
            "  Training epcoh took: 0:02:10\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.33\n",
            "  Validation Loss: 0.75\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:07:02 (h:mm:ss)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}