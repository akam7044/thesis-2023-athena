{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akam7044/thesis-2023-athena/blob/bert_embeddings/BERT_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jSpeEGq27zwA"
      },
      "source": [
        "# Creating BERT embeddings \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gwaoexyvSONy"
      },
      "source": [
        "### Run this section when using google collab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZbWcvBP2ZZxg",
        "outputId": "ec8a4dc4-6b1b-48c9-c653-f07315045456"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-xla==2.0\n",
            "  Downloading https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl (162.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.9/162.9 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cloud-tpu-client==0.10\n",
            "  Downloading cloud_tpu_client-0.10-py3-none-any.whl (7.4 kB)\n",
            "Collecting torch==2.0.0\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.1\n",
            "  Downloading torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-api-python-client==1.8.0 (from cloud-tpu-client==0.10)\n",
            "  Downloading google_api_python_client-1.8.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (8.4.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.21.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.1.0)\n",
            "Collecting google-api-core<2dev,>=1.13.0 (from google-api-python-client==1.8.0->cloud-tpu-client==0.10)\n",
            "  Downloading google_api_core-1.34.0-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.2/120.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.16.0)\n",
            "Collecting uritemplate<4dev,>=3.0.0 (from google-api-python-client==1.8.0->cloud-tpu-client==0.10)\n",
            "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.40.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0) (16.0.5)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from torch-xla==2.0) (1.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (2.1.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client==0.10) (4.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.59.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.20.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (5.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.9)\n",
            "Installing collected packages: uritemplate, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, google-api-core, google-api-python-client, cloud-tpu-client, torch-xla, torch, torchvision\n",
            "  Attempting uninstall: uritemplate\n",
            "    Found existing installation: uritemplate 4.1.1\n",
            "    Uninstalling uritemplate-4.1.1:\n",
            "      Successfully uninstalled uritemplate-4.1.1\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 2.11.0\n",
            "    Uninstalling google-api-core-2.11.0:\n",
            "      Successfully uninstalled google-api-core-2.11.0\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 2.84.0\n",
            "    Uninstalling google-api-python-client-2.84.0:\n",
            "      Successfully uninstalled google-api-python-client-2.84.0\n",
            "  Attempting uninstall: torch-xla\n",
            "    Found existing installation: torch-xla 1.0\n",
            "    Uninstalling torch-xla-1.0:\n",
            "      Successfully uninstalled torch-xla-1.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.2+cu118\n",
            "    Uninstalling torchvision-0.15.2+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.2+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "earthengine-api 0.1.350 requires google-api-python-client>=1.12.1, but you have google-api-python-client 1.8.0 which is incompatible.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 2.0.0 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 2.0.0 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cloud-tpu-client-0.10 google-api-core-1.34.0 google-api-python-client-1.8.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 torch-xla-2.0.0.dev20230516+colab torchvision-0.15.1 uritemplate-3.0.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "googleapiclient",
                  "nvfuser",
                  "torch",
                  "uritemplate"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# !pip install cloud-tpu-client==0.10 torch==2.0.0 torchvision==0.15.1 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "x0-HkCD-SUHC"
      },
      "outputs": [],
      "source": [
        "# # imports pytorch\n",
        "# import torch\n",
        "\n",
        "# # imports the torch_xla package\n",
        "# import torch_xla\n",
        "# import torch_xla.core.xla_model as xm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H0rY36JSaY4",
        "outputId": "fb919c3a-6ff5-4a6e-cc10-7cf255da75fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
            "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
            "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
            "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
            "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99], device='xla:1')\n"
          ]
        }
      ],
      "source": [
        "# # Creates a random tensor on xla:1 (a Cloud TPU core)\n",
        "# device = xm.xla_device()\n",
        "# t1 =torch.arange(0, 100, device=device)\n",
        "# print(t1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pLYc0zxsROBF"
      },
      "source": [
        "## Investigate the token problem \n",
        "See what the max tokens is for each csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAsIWcCnROBG",
        "outputId": "a111ba62-f8ce-4b39-8dc7-c7c48eb72202"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: transformers in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (4.28.1)\n",
            "Requirement already satisfied: filelock in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from transformers) (0.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from transformers) (2023.3.23)\n",
            "Requirement already satisfied: requests in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from transformers) (2.28.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2022.12.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "fUQZgyZK75Nu"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kSjB439IROBI",
        "outputId": "b448ba2a-82c2-476c-aeb5-d71af16d558e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     Yeah, in London you can go to Oxford Street, ...\n",
              "1     Okay. Okay. Yes. Okay. So you want to know wh...\n",
              "2     So this is your first time in London, you've ...\n",
              "3     Okay, so I'm much very long than you're here....\n",
              "4     Okay, so I'm much very long than you're here....\n",
              "Name: transcripts, dtype: object"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0    Ye m in london ygoi to  oxford streets which i...\n",
              "1    O k k yes o k am am so you want you want to kn...\n",
              "2    So this is your your first time in london you'...\n",
              "3    E i so i am not very  londoner here i camp her...\n",
              "4    I iso i am not very londoner here i came here ...\n",
              "Name: transcripts, dtype: object"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0    Yeah, I'm in London. You can go to Oxford Stre...\n",
              "1    Okay.  Okay. Yes. Okay, so you want you want t...\n",
              "2    So this is your your first time in London, you...\n",
              "3    Okay. So I'm a Londoner fewer. I came here for...\n",
              "4    Okay. So I'm a Londoner fewer. I came here for...\n",
              "Name: transcripts, dtype: object"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd \n",
        "\n",
        "df_whisper = pd.read_csv('spontaneousDialougeOnly_whisper.csv')\n",
        "df_wav2vec = pd.read_csv('spontaneousDialougeOnly_wav2vec.csv')\n",
        "df_google  = pd.read_csv('spontaneousDialogueOnly_google.csv')\n",
        "\n",
        "display(df_whisper['transcripts'].head())\n",
        "display(df_wav2vec['transcripts'].head())\n",
        "display(df_google['transcripts'].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "jJn83VOsROBJ",
        "outputId": "3ddfde62-fc42-4b56-eac4-d136c4870ef5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Max token whisper:'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "390"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'Max token wav2vec:'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "420"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'Max token google:'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "378"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import nltk.data\n",
        "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "\n",
        "def find_max_token (df):\n",
        "    max_len = 0\n",
        "    transcripts = df['transcripts'].values\n",
        "\n",
        "    for transcript in transcripts:\n",
        "        #transcript = \"[SEP]\".join(sent_detector.tokenize(transcript.strip())) #for each sentence we need a sentence seperator operator \n",
        "        input_ids = tokenizer.encode(transcript,add_special_tokens=True)\n",
        "        max_len = max(max_len,len(input_ids))\n",
        "    \n",
        "    return max_len\n",
        "\n",
        "max_len_whisper = find_max_token(df_whisper)\n",
        "max_len_wav2vec = find_max_token(df_wav2vec)\n",
        "max_len_google = find_max_token(df_google)\n",
        "\n",
        "display('Max token whisper:',max_len_whisper)\n",
        "display('Max token wav2vec:',max_len_wav2vec)\n",
        "display('Max token google:',max_len_google)\n",
        "\n",
        "    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rPN7XqWWROBK"
      },
      "source": [
        "All fit within the max limit for 516 so we are okay. The max token will be set to 450 just incase there is any problem. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHqME3wsROBK",
        "outputId": "c576c116-2cbb-4492-94a4-72083a68ec15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "184\n",
            "186\n"
          ]
        }
      ],
      "source": [
        "print(len(tokenizer.tokenize(df_whisper.transcripts.values[10])))\n",
        "print(len(tokenizer.encode_plus(df_whisper.transcripts.values[10])['input_ids']))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IwlqLjy1ROBL"
      },
      "source": [
        "So the encoder doesn't split the transcript into sentences ...\n",
        "\n",
        "So to start off with I will generate embeddings for the WHOLE transcript"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee-CK1BEROBL"
      },
      "source": [
        "### Generate Tokens for the whole transcript - testing with one first"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JaTDaJkoROBM"
      },
      "source": [
        "http://mccormickml.com/2019/07/22/BERT-fine-tuning/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b21SQp8uROBM"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from torch.utils.data import TensorDataset, random_split\n",
        "# from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "#logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs6jmFaQROBM"
      },
      "source": [
        "### Whisper \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "BwsWy-hHROBM"
      },
      "outputs": [],
      "source": [
        "df_whisper = pd.read_csv('spontaneousDialougeOnly_whisper.csv')\n",
        "\n",
        "transcripts = df_whisper.transcripts.values\n",
        "labels = df_whisper.classification.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "57"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df_whisper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59Ooaq27ROBM",
        "outputId": "d37cfbdd-2191-4e62-ba0c-24e016b0a829"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:   Yeah, in London you can go to Oxford Street, which is famous for shopping and there's self-aguse there and a lot of tourists come there and a lot there. So it's a good place to see when you come to London and there's Buckingham Palace where the Queen lives and that's a good place. That's the Royal Family lives so you can come there. And there's other, there's Big Ben, the houses of Parliament where the government, the government are, British government are. So that's a good place to go and there's the London Eye where you can see the whole of London, you go and you can see the whole of London. So that's a good place to visit in London. Yeah, so if I was, I would probably, I would go by public transport then you would see how London really is and you would see the whole of London if you go in a bus or the transport you would see how London is. So I would advice you go on public transport buses and trains so you would really enjoy it. You would get on a like an open tour bus where you can see the whole of London and go around and it doesn't cost that much. So yeah, that's good. Yeah, you can see more of London, yeah. Yeah, yeah. Okay then. Well.\n",
            "Token IDs: tensor([  101,  3398,  1010,  1999,  2414,  2017,  2064,  2175,  2000,  4345,\n",
            "         2395,  1010,  2029,  2003,  3297,  2005,  6023,  1998,  2045,  1005,\n",
            "         1055,  2969,  1011, 12943,  8557,  2045,  1998,  1037,  2843,  1997,\n",
            "         9045,  2272,  2045,  1998,  1037,  2843,  2045,  1012,  2061,  2009,\n",
            "         1005,  1055,  1037,  2204,  2173,  2000,  2156,  2043,  2017,  2272,\n",
            "         2000,  2414,  1998,  2045,  1005,  1055, 17836,  4186,  2073,  1996,\n",
            "         3035,  3268,  1998,  2008,  1005,  1055,  1037,  2204,  2173,  1012,\n",
            "         2008,  1005,  1055,  1996,  2548,  2155,  3268,  2061,  2017,  2064,\n",
            "         2272,  2045,  1012,  1998,  2045,  1005,  1055,  2060,  1010,  2045,\n",
            "         1005,  1055,  2502,  3841,  1010,  1996,  3506,  1997,  3323,  2073,\n",
            "         1996,  2231,  1010,  1996,  2231,  2024,  1010,  2329,  2231,  2024,\n",
            "         1012,  2061,  2008,  1005,  1055,  1037,  2204,  2173,  2000,  2175,\n",
            "         1998,  2045,  1005,  1055,  1996,  2414,  3239,  2073,  2017,  2064,\n",
            "         2156,  1996,  2878,  1997,  2414,  1010,  2017,  2175,  1998,  2017,\n",
            "         2064,  2156,  1996,  2878,  1997,  2414,  1012,  2061,  2008,  1005,\n",
            "         1055,  1037,  2204,  2173,  2000,  3942,  1999,  2414,  1012,  3398,\n",
            "         1010,  2061,  2065,  1045,  2001,  1010,  1045,  2052,  2763,  1010,\n",
            "         1045,  2052,  2175,  2011,  2270,  3665,  2059,  2017,  2052,  2156,\n",
            "         2129,  2414,  2428,  2003,  1998,  2017,  2052,  2156,  1996,  2878,\n",
            "         1997,  2414,  2065,  2017,  2175,  1999,  1037,  3902,  2030,  1996,\n",
            "         3665,  2017,  2052,  2156,  2129,  2414,  2003,  1012,  2061,  1045,\n",
            "         2052,  6040,  2017,  2175,  2006,  2270,  3665,  7793,  1998,  4499,\n",
            "         2061,  2017,  2052,  2428,  5959,  2009,  1012,  2017,  2052,  2131,\n",
            "         2006,  1037,  2066,  2019,  2330,  2778,  3902,  2073,  2017,  2064,\n",
            "         2156,  1996,  2878,  1997,  2414,  1998,  2175,  2105,  1998,  2009,\n",
            "         2987,  1005,  1056,  3465,  2008,  2172,  1012,  2061,  3398,  1010,\n",
            "         2008,  1005,  1055,  2204,  1012,  3398,  1010,  2017,  2064,  2156,\n",
            "         2062,  1997,  2414,  1010,  3398,  1012,  3398,  1010,  3398,  1012,\n",
            "         3100,  2059,  1012,  2092,  1012,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
            "Attention: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "[14, 14, 25, 18, 12, 8, 18, 5, 18, 7, 5, 7, 14, 10, 14, 4, 23, 17, 15, 11, 15, 32, 11, 18, 11, 16, 10, 5, 8, 7, 9, 7, 9, 49, 2, 11, 9, 16, 11, 23, 9, 10, 12, 28, 6, 10, 5, 10, 5, 14, 5, 11, 13, 8, 14, 9, 13]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/zx/41yyp8n50255b1fh_dg2stwr0000gn/T/ipykernel_50190/3711164511.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(labels)\n"
          ]
        }
      ],
      "source": [
        "import nltk.data\n",
        "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "count = []\n",
        "\n",
        "for transcript in transcripts:\n",
        "\n",
        "    #transcript = \"[SEP]\".join(sent_detector.tokenize(transcript.strip()))\n",
        "    count.append(len(sent_detector.tokenize(transcript.strip())))\n",
        "\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        transcript,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 450,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', transcripts[0])\n",
        "print('Token IDs:', input_ids[0])\n",
        "print('Attention:', attention_masks[0])\n",
        "print(count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[  101,  3398,  1010,  1999,  2414,  2017,  2064,  2175,  2000,  4345,\n",
            "          2395,  1010,  2029,  2003,  3297,  2005,  6023,  1998,  2045,  1005,\n",
            "          1055,  2969,  1011, 12943,  8557,  2045,  1998,  1037,  2843,  1997,\n",
            "          9045,  2272,  2045,  1998,  1037,  2843,  2045,  1012,  2061,  2009,\n",
            "          1005,  1055,  1037,  2204,  2173,  2000,  2156,  2043,  2017,  2272,\n",
            "          2000,  2414,  1998,  2045,  1005,  1055, 17836,  4186,  2073,  1996,\n",
            "          3035,  3268,  1998,  2008,  1005,  1055,  1037,  2204,  2173,  1012,\n",
            "          2008,  1005,  1055,  1996,  2548,  2155,  3268,  2061,  2017,  2064,\n",
            "          2272,  2045,  1012,  1998,  2045,  1005,  1055,  2060,  1010,  2045,\n",
            "          1005,  1055,  2502,  3841,  1010,  1996,  3506,  1997,  3323,  2073,\n",
            "          1996,  2231,  1010,  1996,  2231,  2024,  1010,  2329,  2231,  2024,\n",
            "          1012,  2061,  2008,  1005,  1055,  1037,  2204,  2173,  2000,  2175,\n",
            "          1998,  2045,  1005,  1055,  1996,  2414,  3239,  2073,  2017,  2064,\n",
            "          2156,  1996,  2878,  1997,  2414,  1010,  2017,  2175,  1998,  2017,\n",
            "          2064,  2156,  1996,  2878,  1997,  2414,  1012,  2061,  2008,  1005,\n",
            "          1055,  1037,  2204,  2173,  2000,  3942,  1999,  2414,  1012,  3398,\n",
            "          1010,  2061,  2065,  1045,  2001,  1010,  1045,  2052,  2763,  1010,\n",
            "          1045,  2052,  2175,  2011,  2270,  3665,  2059,  2017,  2052,  2156,\n",
            "          2129,  2414,  2428,  2003,  1998,  2017,  2052,  2156,  1996,  2878,\n",
            "          1997,  2414,  2065,  2017,  2175,  1999,  1037,  3902,  2030,  1996,\n",
            "          3665,  2017,  2052,  2156,  2129,  2414,  2003,  1012,  2061,  1045,\n",
            "          2052,  6040,  2017,  2175,  2006,  2270,  3665,  7793,  1998,  4499,\n",
            "          2061,  2017,  2052,  2428,  5959,  2009,  1012,  2017,  2052,  2131,\n",
            "          2006,  1037,  2066,  2019,  2330,  2778,  3902,  2073,  2017,  2064,\n",
            "          2156,  1996,  2878,  1997,  2414,  1998,  2175,  2105,  1998,  2009,\n",
            "          2987,  1005,  1056,  3465,  2008,  2172,  1012,  2061,  3398,  1010,\n",
            "          2008,  1005,  1055,  2204,  1012,  3398,  1010,  2017,  2064,  2156,\n",
            "          2062,  1997,  2414,  1010,  3398,  1012,  3398,  1010,  3398,  1012,\n",
            "          3100,  2059,  1012,  2092,  1012,   102,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n"
          ]
        }
      ],
      "source": [
        "#print(input_ids[0])\n",
        "input_id_resize = input_ids[0].reshape(1,450)\n",
        "attention_masks_resize = attention_masks[0].reshape(1,450)\n",
        "print(input_id_resize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9mAbvyuTuei",
        "outputId": "b33f9855-294f-4972-c889-a5f32222a48f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "199\n",
            "The BERT model has 199 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "embeddings.word_embeddings.weight                       (30522, 768)\n",
            "embeddings.position_embeddings.weight                     (512, 768)\n",
            "embeddings.token_type_embeddings.weight                     (2, 768)\n",
            "embeddings.LayerNorm.weight                                   (768,)\n",
            "embeddings.LayerNorm.bias                                     (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "encoder.layer.0.attention.self.query.weight               (768, 768)\n",
            "encoder.layer.0.attention.self.query.bias                     (768,)\n",
            "encoder.layer.0.attention.self.key.weight                 (768, 768)\n",
            "encoder.layer.0.attention.self.key.bias                       (768,)\n",
            "encoder.layer.0.attention.self.value.weight               (768, 768)\n",
            "encoder.layer.0.attention.self.value.bias                     (768,)\n",
            "encoder.layer.0.attention.output.dense.weight             (768, 768)\n",
            "encoder.layer.0.attention.output.dense.bias                   (768,)\n",
            "encoder.layer.0.attention.output.LayerNorm.weight             (768,)\n",
            "encoder.layer.0.attention.output.LayerNorm.bias               (768,)\n",
            "encoder.layer.0.intermediate.dense.weight                (3072, 768)\n",
            "encoder.layer.0.intermediate.dense.bias                      (3072,)\n",
            "encoder.layer.0.output.dense.weight                      (768, 3072)\n",
            "encoder.layer.0.output.dense.bias                             (768,)\n",
            "encoder.layer.0.output.LayerNorm.weight                       (768,)\n",
            "encoder.layer.0.output.LayerNorm.bias                         (768,)\n"
          ]
        }
      ],
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "# Load pre-trained model (weights)\n",
        "model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        "                                  )\n",
        "\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "model.eval()\n",
        "\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print(len(params))\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 450])\n"
          ]
        }
      ],
      "source": [
        "# Run the text through BERT, and collect all of the hidden states produced\n",
        "# from all 12 layers. \n",
        "print(input_id_resize.size())\n",
        "with torch.no_grad():\n",
        "\n",
        "    outputs = model(input_id_resize, attention_masks_resize)\n",
        "\n",
        "    # Evaluating the model will return a different number of objects based on \n",
        "    # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
        "    # becase we set `output_hidden_states = True`, the third item will be the \n",
        "    # hidden states from all layers. See the documentation for more details:\n",
        "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "    hidden_states = outputs[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
            "Number of batches: 1\n",
            "Number of tokens: 450\n",
            "Number of hidden units: 768\n"
          ]
        }
      ],
      "source": [
        "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
        "layer_i = 0\n",
        "\n",
        "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
        "batch_i = 0\n",
        "\n",
        "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
        "token_i = 0\n",
        "\n",
        "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Type of hidden_states:  <class 'tuple'>\n",
            "Tensor shape for each layer:  torch.Size([1, 450, 768])\n"
          ]
        }
      ],
      "source": [
        "# `hidden_states` is a Python list.\n",
        "print('      Type of hidden_states: ', type(hidden_states))\n",
        "\n",
        "# Each layer in the list is a torch tensor.\n",
        "print('Tensor shape for each layer: ', hidden_states[0].size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([13, 1, 450, 768])"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Concatenate the tensors for all layers. We use `stack` here to\n",
        "# create a new dimension in the tensor.\n",
        "token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "\n",
        "token_embeddings.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([13, 450, 768])"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove dimension 1, the \"batches\".\n",
        "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "\n",
        "token_embeddings.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([450, 13, 768])"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Swap dimensions 0 and 1.\n",
        "token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "token_embeddings.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([768])\n"
          ]
        }
      ],
      "source": [
        "# `hidden_states` has shape [13 x 1 x 22 x 768]\n",
        "\n",
        "# `token_vecs` is a tensor with shape [22 x 768]\n",
        "token_vecs = hidden_states[-2][0]\n",
        "\n",
        "# Calculate the average of all 22 token vectors.\n",
        "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "\n",
        "print(sentence_embedding.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 9.2898e-02, -3.1706e-01,  3.0769e-01,  5.9216e-02,  1.2851e-01,\n",
            "        -1.6297e-01, -6.7700e-02,  1.1933e+00, -1.5987e-01, -3.2072e-01,\n",
            "        -2.2333e-01, -3.9926e-02,  6.7172e-02,  1.7070e-01, -6.8330e-02,\n",
            "        -4.3218e-02,  2.2641e-01,  3.3407e-01,  1.4887e-01,  4.6192e-01,\n",
            "         4.6184e-01,  4.2969e-01, -4.1225e-01, -2.2601e-01,  3.5624e-01,\n",
            "         2.4428e-01,  1.6205e-01, -2.3265e-01, -1.1740e-01,  2.9191e-01,\n",
            "         3.9149e-01,  1.8550e-01,  1.8248e-02, -2.1975e-01,  1.2000e-01,\n",
            "        -4.7026e-01,  9.5347e-02,  9.6847e-02, -4.5526e-01, -2.2310e-01,\n",
            "        -2.0141e-01, -2.6811e-01,  3.7789e-01, -3.0233e-01, -3.9713e-01,\n",
            "         1.5721e-02,  4.5926e-01, -2.8779e-01, -1.1606e-02, -4.4356e-01,\n",
            "        -2.6350e-01, -1.9754e-01, -4.6238e-01,  4.3067e-02,  4.6804e-01,\n",
            "        -1.5323e-04, -1.2497e-01, -1.5853e-01, -4.8164e-01,  3.5797e-02,\n",
            "        -8.8510e-02, -2.4844e-01,  2.9803e-02, -1.2080e-01,  3.1578e-01,\n",
            "        -2.0020e-01,  4.0094e-01,  5.1318e-02, -4.2141e-01,  1.7858e-01,\n",
            "        -1.5120e-01, -3.7263e-01,  3.6531e-01, -1.7004e-01, -8.6368e-02,\n",
            "        -3.6058e-01,  5.8696e-02, -1.4773e-01, -2.5940e-01, -1.8418e-01,\n",
            "        -3.4133e-02,  2.1870e-01,  1.1360e-01,  4.6418e-01, -2.0816e-02,\n",
            "         2.6407e-01, -3.5201e-01,  3.6450e-02, -1.7934e-01,  3.0851e-01,\n",
            "        -3.4426e-01, -2.8127e-02, -2.2038e-01,  3.5560e-02,  1.8060e-01,\n",
            "        -2.6521e-01,  4.4135e-02, -7.6289e-02,  2.7575e-01, -1.6252e-01,\n",
            "         1.4173e-01, -9.4898e-01,  2.5014e-01, -4.7341e-01, -1.0268e-01,\n",
            "         6.2219e-02, -3.9255e-02, -2.1149e-01,  3.1563e-01,  2.1016e-01,\n",
            "        -3.5462e-01, -1.1943e-01,  1.2249e-01,  3.7650e-02,  5.8315e-02,\n",
            "         9.3656e-02, -5.1453e-01,  1.4219e-03,  5.0044e-01,  4.0116e-01,\n",
            "        -6.1394e-01, -6.1775e-02,  1.6197e-01,  3.6323e-02, -2.9735e-02,\n",
            "        -3.4520e-02, -2.0810e-01, -2.7961e-01, -4.2342e-01, -9.3128e-02,\n",
            "         6.6198e-01,  2.1479e-01,  1.0637e-01, -3.7680e-01,  1.1228e-02,\n",
            "        -1.7160e-01,  1.3737e-01, -2.5819e-01,  4.0955e-02, -4.8729e-01,\n",
            "         4.7012e-01,  3.6656e-01,  5.5500e-02,  2.6503e-01,  1.7537e-01,\n",
            "        -3.7026e-01, -3.9375e-01, -5.2589e-01, -1.7107e-01, -1.6202e-01,\n",
            "        -4.2616e-01,  6.7617e-01, -7.3900e-02, -7.1558e-01, -8.9010e-02,\n",
            "        -2.2386e-01, -2.7759e-01,  2.9410e-01,  1.9859e-01,  4.6433e-02,\n",
            "         4.4458e-01, -2.9578e-01, -1.1721e-01,  3.3316e-01, -2.6743e-01,\n",
            "         2.0244e-01,  1.2394e-01,  4.8446e-01, -3.7855e-01,  1.2716e-01,\n",
            "        -1.0433e-01, -1.6142e-01,  6.0224e-01, -2.7201e-01,  1.6551e-01,\n",
            "        -1.6268e-01,  2.0623e-01,  1.2226e-01,  2.3996e-01,  3.9203e-01,\n",
            "        -5.5583e-01,  2.6323e-01, -2.8372e-01, -3.7706e-01,  2.1463e-02,\n",
            "         1.6463e-01,  6.4535e-01, -1.4466e-01,  2.7471e-01,  1.2829e-01,\n",
            "         1.4063e-01, -2.3759e-01, -7.8920e-02, -3.2817e-01,  1.2396e-01,\n",
            "        -4.2868e-01, -9.7195e-03, -3.8513e-01,  2.7944e-01, -7.9578e-03,\n",
            "         2.4480e-02,  1.7109e-01,  4.3217e-01,  1.1196e-01,  6.0268e-02,\n",
            "         2.9080e-01,  6.5300e-02,  1.2458e-02, -2.3959e-01,  4.0815e-01,\n",
            "        -7.1747e-02,  3.5183e-01, -2.0193e-02, -2.2778e-01,  2.4905e-02,\n",
            "        -7.2918e-02, -2.9206e-01,  3.2441e-01,  9.0304e-02, -1.1509e-02,\n",
            "         1.4908e-01, -9.1401e-03, -1.4949e-01, -1.2180e-01, -1.1261e-01,\n",
            "         6.9607e-01,  8.8296e-02, -2.9350e-01,  5.8528e-01,  5.6349e-03,\n",
            "        -5.3626e-01,  4.0300e-01, -1.9047e-01, -2.9059e-01,  2.1986e-01,\n",
            "        -7.7308e-02,  1.3746e-02, -2.1380e-01, -2.4357e-01,  5.3435e-01,\n",
            "        -4.1811e-01, -1.6658e-02,  2.1779e-01,  5.1339e-01,  1.0225e-02,\n",
            "         2.5822e-01,  1.2026e-01, -5.5964e-01, -2.8896e-01, -2.0446e-01,\n",
            "         2.0651e-02, -1.5676e-01, -4.2370e-02, -3.4604e-01,  1.2529e-02,\n",
            "        -1.2176e-01, -2.1900e-01, -3.0109e-01,  1.6134e-01, -3.4352e-01,\n",
            "        -3.6152e-01, -8.7560e-02, -3.0016e-01,  1.4464e-01, -1.9655e-01,\n",
            "         1.6661e-01, -8.5583e-02,  6.1453e-02,  2.8477e-02,  1.3917e-01,\n",
            "         1.9757e-01, -1.6224e-01, -1.0480e-01,  5.0570e-01,  1.3316e-01,\n",
            "        -1.6366e-01, -1.2676e-01,  4.8478e-01,  1.1898e-01,  1.2466e-01,\n",
            "        -1.8836e-01,  6.5497e-01, -7.7715e-01,  1.8868e-01,  5.0690e-01,\n",
            "        -2.4633e-01, -2.5359e-03,  9.1899e-02, -1.8372e-01, -3.6950e-01,\n",
            "         2.6460e-01, -1.1893e-02,  1.2768e-01, -4.5538e-01,  7.6155e-01,\n",
            "         2.6614e-02,  1.0736e-01,  5.2801e-02, -1.9289e-01, -3.4779e-01,\n",
            "        -3.8869e-01,  3.1131e-01,  3.6536e-01, -3.0397e-01,  8.7242e-01,\n",
            "        -9.0276e-02, -3.8273e-01, -1.9158e-01, -1.2359e+01, -2.5179e-02,\n",
            "         1.2958e-01,  7.8334e-02,  1.6086e-01, -2.0781e-02, -2.8479e-02,\n",
            "        -1.2935e-01, -3.4622e-01, -3.7830e-01,  4.3646e-01, -5.1772e-01,\n",
            "        -4.1751e-01, -2.0512e-02,  2.7164e-01, -1.3007e-01,  2.6397e-01,\n",
            "        -2.3197e-01, -1.2772e-01,  4.5383e-01, -3.1388e-01, -3.5692e-01,\n",
            "         6.7995e-01, -2.1184e-02, -2.3057e-01,  3.4368e-01,  3.2738e-01,\n",
            "        -1.6952e-01, -4.1803e-01,  2.3126e-02, -1.9836e-01,  1.6925e-01,\n",
            "        -1.1092e-01,  3.3747e-02, -4.3489e-02,  2.0913e-01,  1.0598e-01,\n",
            "        -4.0146e-01,  6.0782e-02, -2.4055e-01, -3.5392e-02, -1.3010e-01,\n",
            "        -7.5043e-02, -9.9874e-02,  4.5954e-01, -1.4074e-01,  6.0192e-02,\n",
            "         1.3981e-01,  3.0187e-01,  1.1959e-01,  2.0364e-01,  6.6960e-02,\n",
            "        -2.5751e-01, -2.8031e-01,  6.5907e-02, -2.3645e-01,  2.0244e-01,\n",
            "         6.3632e-01, -1.8139e-02, -7.4774e-01, -1.5499e-01, -2.5271e-01,\n",
            "        -2.5075e-01,  2.1156e-02, -1.6788e-01,  1.1674e-01, -2.7738e-01,\n",
            "         1.0276e-02,  2.7021e-01, -2.3009e-02, -1.5686e-01, -6.5571e-01,\n",
            "        -1.2159e-01, -1.2054e+00, -9.8797e-02,  3.9004e-01, -9.9786e-02,\n",
            "         7.5163e-02,  1.2539e-01,  1.1385e-01,  3.6914e-02, -2.8950e-01,\n",
            "        -5.3610e-01,  9.1005e-02, -4.2539e-01, -5.1478e-01, -4.3656e-01,\n",
            "         3.4038e-02, -1.2671e-01, -1.9396e-01,  2.3846e-01,  1.1177e-01,\n",
            "         1.6908e-01,  5.3355e-01,  3.4741e-01, -2.4966e-01,  4.8432e-01,\n",
            "        -2.8338e-01, -1.0158e-01, -2.3990e-01, -1.8049e-01,  2.5562e-01,\n",
            "        -1.5400e-01,  1.4520e-01,  1.0161e-01, -3.0869e-01,  9.8718e-02,\n",
            "         1.0822e-01, -1.6539e-01, -1.7954e-01,  1.8156e-01, -3.2807e-01,\n",
            "         9.7014e-02,  1.8952e-01, -5.2487e-01, -2.8286e-01,  9.5846e-02,\n",
            "         8.9137e-02,  2.6528e-01, -2.1616e-02, -1.6435e-01,  2.1613e-01,\n",
            "        -1.8751e-01, -2.4352e-01, -5.3457e-01,  1.6172e-01, -4.5620e-02,\n",
            "        -3.2163e-01, -3.1818e-01,  3.9937e-01,  1.2250e-01,  3.6543e-01,\n",
            "         1.6546e-01, -8.2377e-02, -1.8218e-01, -1.0450e-01, -2.9205e-01,\n",
            "        -2.8956e-01,  1.2572e-01,  4.9714e-01,  5.2365e-01,  1.0974e-01,\n",
            "         4.5730e-01,  2.5505e-01, -1.9316e-01,  2.0975e-01, -2.3919e-01,\n",
            "         3.3922e-01, -3.4754e-01,  1.8289e-01, -4.7858e-01, -4.9405e-01,\n",
            "        -4.4287e-02,  2.6312e-01, -1.3548e-02, -1.5468e-01, -1.5141e-01,\n",
            "         1.2039e-01,  9.3425e-02, -2.1796e-01,  4.9959e-01, -5.6542e-02,\n",
            "         2.6215e-02,  5.6763e-01,  3.2557e-01, -5.2265e-02, -1.9290e-01,\n",
            "         6.8986e-02, -4.2025e-01,  2.8359e-01,  1.8060e-01, -6.4234e-02,\n",
            "        -1.6667e-01, -9.2519e-03, -4.5069e-02,  1.8568e-01, -1.7269e-01,\n",
            "        -2.6189e-01, -2.0036e-01, -1.1599e-01,  2.5074e-01,  3.5912e-01,\n",
            "         8.6523e-02, -6.0952e-01, -1.1880e-01,  3.4845e-01, -4.0058e-01,\n",
            "        -2.1109e-01, -2.2878e-02,  4.2273e-01,  5.4736e-01,  6.5817e-01,\n",
            "        -9.5660e-02, -3.5531e-01,  1.0032e-01, -3.4316e-01,  1.4618e-01,\n",
            "        -3.9925e-01,  5.8439e-02,  5.2520e-02, -1.7650e-01, -5.4546e-01,\n",
            "        -2.2233e-01,  3.4763e-01, -2.1548e-01, -3.1570e-01,  2.3426e-02,\n",
            "         8.4424e-01, -1.1906e-01,  1.6081e-01, -7.7289e-02, -3.4411e-01,\n",
            "        -1.5410e-01, -2.2157e-01, -6.0381e-01, -1.7129e-01,  4.5920e-01,\n",
            "        -4.2094e-01, -6.2653e-01, -1.1224e-01, -5.1603e-01, -6.1031e-01,\n",
            "        -1.8532e-01,  1.0149e-01, -4.8281e-01,  3.2537e-01, -1.2563e-01,\n",
            "        -2.3452e-01, -3.4526e-02, -5.4735e-01, -2.6242e-02, -6.1847e-01,\n",
            "         1.5009e-01,  2.1024e-01,  1.1482e-01,  2.5261e-02, -2.3510e-01,\n",
            "        -2.1310e-01, -1.9314e-01,  1.1408e-01, -4.6663e-01, -4.7714e-01,\n",
            "        -7.4065e-01, -3.6009e-01, -9.0324e-03,  2.2541e-01, -2.0966e-01,\n",
            "         2.1553e-01, -3.4939e-01,  5.0296e-01,  1.8655e-01, -4.2633e-01,\n",
            "         3.8210e-02, -4.4871e-01,  5.8620e-02, -3.2377e-01, -4.6246e-01,\n",
            "         2.3615e-01,  2.5716e-01,  2.4077e-01, -6.4078e-02,  3.6596e-01,\n",
            "         1.2064e-01, -9.2014e-02,  4.7656e-02, -7.8865e-02, -1.5073e-01,\n",
            "         1.5010e-01, -9.8544e-02,  5.8354e-02,  9.5999e-02, -1.5676e-01,\n",
            "         2.6228e-01,  8.8576e-02, -1.6162e-01, -3.2670e-01, -1.6866e-01,\n",
            "        -5.2665e-01,  4.3687e-01, -3.4626e-01,  1.8108e-01,  2.9985e-01,\n",
            "         1.9763e-01, -4.6909e-01, -1.7708e-01, -4.3458e-01, -1.1220e-01,\n",
            "         3.6712e-01,  2.1840e-02,  1.4116e-01, -1.6430e-02, -3.7242e-01,\n",
            "        -3.9292e-01,  3.6662e-01,  1.0111e-01,  2.7092e-01,  3.8960e-01,\n",
            "        -1.4675e-01,  4.3602e-03, -2.6125e-01, -1.3363e-01, -3.0350e-01,\n",
            "         2.4519e-01,  1.5826e-02,  1.3794e-01,  4.3926e-01,  4.3787e-01,\n",
            "        -5.6832e-02,  5.2648e-01,  2.7763e-01, -5.2117e-01, -2.0752e-01,\n",
            "         4.7411e-01,  8.2201e-01, -5.0246e-02, -7.1995e-02,  1.4014e-01,\n",
            "        -4.7999e-01, -5.0547e-01,  1.8759e-01, -6.6655e-05, -1.5902e-01,\n",
            "         4.3610e-01, -9.7953e-02,  2.2921e-01,  2.9966e-01, -1.2760e-01,\n",
            "        -1.9084e-01,  6.2908e-02,  2.6794e-01, -8.2171e-02,  4.5585e-01,\n",
            "        -2.9386e-01,  4.4105e-01,  1.8279e-01, -1.2628e-01,  6.3132e-02,\n",
            "        -1.7415e-01,  9.9227e-02,  9.9807e-04, -1.1327e-01,  1.6945e-01,\n",
            "         1.7013e-01,  2.3656e-01,  1.0216e-01, -4.4838e-02, -1.9636e-01,\n",
            "        -2.3160e-01,  3.2332e-01,  3.8910e-01,  1.1067e-01,  2.0534e-01,\n",
            "         1.7578e-01, -3.9261e-01,  4.4616e-01, -1.5194e-01, -4.3407e-02,\n",
            "         3.8013e-01, -1.3084e-01,  6.7865e-01,  4.3919e-01,  2.7915e-01,\n",
            "         7.7327e-02, -2.2938e-01,  1.7831e-01,  2.0585e-01,  1.9542e-01,\n",
            "        -2.8418e-01, -2.8212e-01,  8.0073e-02,  1.3411e-01,  4.7451e-01,\n",
            "         1.7395e-01, -1.6281e-02, -1.5249e-02,  1.0266e-01, -2.9133e-01,\n",
            "        -8.2321e-03, -7.0014e-02, -9.4033e-02, -9.3086e-02,  1.8117e-03,\n",
            "        -2.5086e-01, -2.1267e-01,  6.8329e-01, -8.0926e-01, -1.0385e-01,\n",
            "        -4.0145e-01, -2.7893e-01,  1.5458e-01, -1.8902e-01, -1.6589e-01,\n",
            "        -3.5939e-01, -3.4101e-01,  3.2540e-01, -7.5493e-01, -4.7095e-02,\n",
            "        -2.3895e-01,  4.3292e-01, -2.6749e-01,  2.6873e-01, -7.8016e-02,\n",
            "        -2.6244e-03,  8.4834e-02, -2.1894e-01,  3.0696e-01, -2.8655e-03,\n",
            "         1.1183e-03, -1.1247e-01,  1.4437e-01,  1.1135e-01,  6.1763e-01,\n",
            "        -1.4411e-01,  2.2319e-01, -1.7955e-01,  4.3182e-01, -1.9182e-01,\n",
            "        -4.6000e-01,  1.5505e-01,  1.6849e-01, -3.6083e-01, -4.2233e-01,\n",
            "        -2.8627e-01,  4.4014e-01,  2.3751e-01, -4.4677e-01, -7.2146e-02,\n",
            "         3.7250e-01, -3.9023e-01,  8.6207e-02, -3.0446e-03,  2.4682e-01,\n",
            "         4.2711e-02, -2.0549e-01, -4.3953e-01,  1.7758e-01, -2.2281e-01,\n",
            "         2.5789e-03, -5.9707e-02,  1.6097e-01,  2.8034e-02,  8.8329e-02,\n",
            "        -2.7932e-01, -6.0618e-01, -1.4271e-01,  1.7936e-01,  3.5141e-02,\n",
            "        -1.5629e-01, -3.7059e-01,  3.9661e-01, -2.2100e-01, -5.4948e-01,\n",
            "        -3.3444e-02,  2.4089e-01, -6.7243e-02,  3.4272e-01, -3.0350e-02,\n",
            "        -4.4660e-01,  2.8479e-01, -7.4363e-02])\n"
          ]
        }
      ],
      "source": [
        "print(sentence_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoQNs5dRUXbp"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
