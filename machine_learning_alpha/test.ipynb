{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import (\n",
    "    StandardScaler,\n",
    "    LinearDiscriminantAnalysis as LDA,\n",
    ")\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mrmr import mrmr_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def feature_reduction_pca(x_train,x_test, variance: float):\n",
    "\n",
    "    pca = PCA(n_components=variance)\n",
    "\n",
    "    x_train = pca.fit_transform(x_train)\n",
    "    x_test = pca.transform(x_test)\n",
    "\n",
    "    return x_train,x_test\n",
    "\n",
    "\n",
    "def feature_reduction_lda(x_train,x_test, y_train):\n",
    "    \"\"\"\n",
    "    LDA is supervised so we need a test and train split\n",
    "    \"\"\"\n",
    "\n",
    "    # LDA\n",
    "    lda = LDA(n_components=1)\n",
    "    x_train = lda.fit_transform(x_train, y_train)\n",
    "    x_test = lda.transform(x_test)\n",
    "\n",
    "    return x_train,x_test\n",
    "\n",
    "\n",
    "def feature_reduction_mrmr(x_train,x_test, y_train, n_components):\n",
    "    selected_components = mrmr_classif(X=x_train, y=y_train, K=n_components)\n",
    "    x_train = pd.DataFrame(x_train).loc[:, selected_components]\n",
    "    x_test = pd.DataFrame(x_test).loc[:, selected_components]\n",
    "    return x_train,x_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "CV_SPLIT = 5\n",
    "\n",
    "\"\"\"\n",
    "GridSearch for parameter optimisation\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_best_param_RF(x_train, y_train):\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [100, 200, 500],\n",
    "        \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "        \"max_depth\": [4, 5, 6, 7, 8],\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "    }\n",
    "    grid = GridSearchCV(\n",
    "        RandomForestClassifier(),\n",
    "        param_grid,\n",
    "        refit=True,\n",
    "        verbose=0,\n",
    "        return_train_score=True,\n",
    "        cv=CV_SPLIT,\n",
    "    )\n",
    "    grid.fit(x_train, y_train)\n",
    "    print(grid.best_estimator_.get_params())\n",
    "    return grid\n",
    "\n",
    "\n",
    "def get_best_param_KNN(x_train, y_train):\n",
    "    param_grid = {\n",
    "        \"n_neighbors\": range(1, 21, 2),\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"],\n",
    "    }\n",
    "    grid = GridSearchCV(\n",
    "        KNeighborsClassifier(),\n",
    "        param_grid,\n",
    "        refit=True,\n",
    "        verbose=0,\n",
    "        return_train_score=True,\n",
    "        cv=CV_SPLIT,\n",
    "    )\n",
    "    grid.fit(x_train, y_train)\n",
    "    print(grid.best_estimator_.get_params())\n",
    "    return grid\n",
    "\n",
    "\n",
    "def get_best_param_LR(x_train, y_train):\n",
    "    param_grid = {\n",
    "        \"C\": [100, 10, 1.0, 0.1, 0.01],\n",
    "        \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"],\n",
    "        \"penalty\": [\"l1\", \"l2\"],\n",
    "    }\n",
    "    grid = GridSearchCV(\n",
    "        LogisticRegression(),\n",
    "        param_grid,\n",
    "        refit=True,\n",
    "        verbose=0,\n",
    "        return_train_score=True,\n",
    "        cv=CV_SPLIT,\n",
    "    )\n",
    "    grid.fit(x_train, y_train)\n",
    "    print(grid.best_estimator_.get_params())\n",
    "    return grid\n",
    "\n",
    "\n",
    "def get_best_param_SVC(x_train, y_train):\n",
    "    param_grid = {\n",
    "        \"C\": [0.1, 1, 10, 100],\n",
    "        \"gamma\": [1, 0.1, 0.01, 0.001],\n",
    "        \"kernel\": [\"rbf\", \"poly\", \"sigmoid\"],\n",
    "    }\n",
    "    grid = GridSearchCV(\n",
    "        SVC(), param_grid, refit=True, verbose=0, return_train_score=True, cv=CV_SPLIT\n",
    "    )\n",
    "    grid.fit(x_train, y_train)\n",
    "    print(grid.best_estimator_.get_params())\n",
    "    return grid\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def division_function(n, d):\n",
    "    if d:\n",
    "        return n / d\n",
    "    elif n == 0 and d == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def validate_model(model, X, Y):\n",
    "    \"\"\"\n",
    "    validates the model with a k-fold validation which is iterated\n",
    "    returns the mean accuracy, specificiy, recall, precision, f1 score and auc score\n",
    "    \"\"\"\n",
    "\n",
    "    splits = 5\n",
    "    iteration = 10\n",
    "\n",
    "    acc_list = []\n",
    "    specificity_list = []\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    folds = StratifiedKFold(n_splits=splits)\n",
    "\n",
    "    # Iterate \"interation\" times of k-fold\n",
    "    for i in range(1, iteration):\n",
    "        # print(f'Iteration {i}/{iteration}')\n",
    "\n",
    "        acc_total = 0\n",
    "        specificity_total = 0\n",
    "        recall_total = 0\n",
    "        precision_total = 0\n",
    "        f1_total = 0\n",
    "\n",
    "        for train_index, test_index in folds.split(X, Y):\n",
    "            x_train = X.iloc[train_index, :]\n",
    "            x_test = X.iloc[test_index, :]\n",
    "            y_train = Y.iloc[train_index, :]\n",
    "            y_test = Y.iloc[test_index, :]\n",
    "\n",
    "            # scale\n",
    "            sc = MinMaxScaler()\n",
    "            x_train = sc.fit_transform(x_train)\n",
    "            x_test = sc.transform(x_test)\n",
    "\n",
    "            # fit model and predict\n",
    "            model.fit(x_train, np.ravel(y_train))\n",
    "            y_pred = model.predict(x_test)\n",
    "\n",
    "            conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "            TN = conf_matrix[0][0]\n",
    "            FP = conf_matrix[0][1]\n",
    "            FN = conf_matrix[1][0]\n",
    "            TP = conf_matrix[1][1]\n",
    "\n",
    "            accuracy = (division_function((TP + TN), (TP + TN + FP + FN))) * 100\n",
    "            recall = division_function(TP, (TP + FN)) * 100  # recall\n",
    "            specificity = division_function(TN, (TN + FP)) * 100\n",
    "            precision = division_function(TP, (TP + FP)) * 100\n",
    "            f1_score = division_function(2 * (recall * precision), (recall + precision))\n",
    "\n",
    "            # sum it up\n",
    "            acc_total += accuracy\n",
    "            recall_total += recall\n",
    "            specificity_total += specificity\n",
    "            precision_total += precision\n",
    "            f1_total += f1_score\n",
    "\n",
    "        # avg\n",
    "        accuracy_mean = acc_total / splits\n",
    "        recall_mean = recall_total / splits\n",
    "        specificity_mean = specificity_total / splits\n",
    "        precision_mean = precision_total / splits\n",
    "        f1_mean = f1_total / splits\n",
    "\n",
    "        acc_list.append(accuracy_mean)\n",
    "        recall_list.append(recall_mean)\n",
    "        specificity_list.append(specificity_mean)\n",
    "        precision_list.append(precision_mean)\n",
    "        f1_list.append(f1_mean)\n",
    "\n",
    "    return (\n",
    "        np.mean(acc_list),\n",
    "        np.mean(specificity_list),\n",
    "        np.mean(recall_list),\n",
    "        np.mean(precision_list),\n",
    "        np.mean(f1_list),\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_model(model, x_train, x_test, y_train, y_test,x_test_index, df):\n",
    "    sc = MinMaxScaler()\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.transform(x_test)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    ids = df.iloc[x_test_index]['id']\n",
    "    data = {'id':ids,'y_pred':y_pred,'y_test':y_test}\n",
    "    data_df = pd.DataFrame(data)\n",
    "    data_df_group = data_df.groupby(by=['id'],sort=False).mean().round()\n",
    "    y_pred_2 = data_df_group['y_pred']\n",
    "    y_test_2 = data_df_group['y_test']\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test_2, y_pred_2)\n",
    "    TN = conf_matrix[0][0]\n",
    "    FP = conf_matrix[0][1]\n",
    "    FN = conf_matrix[1][0]\n",
    "    TP = conf_matrix[1][1]\n",
    "\n",
    "    accuracy = (division_function((TP + TN), (TP + TN + FP + FN))) * 100\n",
    "    recall = division_function(TP, (TP + FN)) * 100  # recall\n",
    "    specificity = division_function(TN, (TN + FP)) * 100\n",
    "    precision = division_function(TP, (TP + FP)) * 100\n",
    "    f1_score = division_function(2 * (recall * precision), (recall + precision))\n",
    "\n",
    "    return accuracy, recall, specificity, precision, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "\n",
    "path = '/Users/athena.kam/Documents/Thesis/codebase/thesis-2023-athena'\n",
    "os.chdir(path)\n",
    "\n",
    "\"\"\"\n",
    "Reducing the features, splitting the data into test and train, oversample the training data, train the model and validate and evaluate it\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def read_and_split(\n",
    "    filename: str, isTranscript: bool, reduce: str, random_state: int, chunked: bool\n",
    "):\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    if isTranscript:\n",
    "        # Remove Personal Questions\n",
    "        df = df[df[\"personalQ\"] != 1].reset_index(drop=True)\n",
    "\n",
    "        headers = df.columns\n",
    "        non_embeddings_headers = []\n",
    "        for header in headers:\n",
    "            if header.find(\"embbedings\") < 0:\n",
    "                non_embeddings_headers.append(header)\n",
    "\n",
    "        X = df.drop(columns=non_embeddings_headers)\n",
    "        Y = df[\"classification\"]\n",
    "        X = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "\n",
    "        # Train-test split\n",
    "        x_index = range(len(X))\n",
    "        x_train_index, x_test_index, y_train, y_test = train_test_split(\n",
    "            x_index, Y, test_size=0.30, random_state=random_state\n",
    "        )\n",
    "        x_train = pd.DataFrame(X).iloc[x_train_index]\n",
    "        x_test = pd.DataFrame(X).iloc[x_test_index]\n",
    "\n",
    "\n",
    "        # Oversample minority group\n",
    "        sm = SMOTE(random_state=12)\n",
    "        x_train, y_train = sm.fit_resample(x_train, y_train)\n",
    "\n",
    "        # Feature Reduction\n",
    "        if reduce == \"pca\":\n",
    "            x_train,x_test = feature_reduction_pca(x_train, x_test, 0.9)\n",
    "        elif reduce == \"lda\":\n",
    "            x_train,x_test = feature_reduction_lda(x_train, x_test, y_train)\n",
    "        elif reduce == \"mrmr\":\n",
    "            x_train,x_test = feature_reduction_mrmr(pd.DataFrame(x_train), pd.DataFrame(x_test), pd.DataFrame(y_train), 30)\n",
    "\n",
    "    else:\n",
    "        if chunked:\n",
    "            df.drop([\"voiceID\", \"label_x\"], inplace=True, axis=1)\n",
    "            df.rename(columns={\"label_y\": \"label\"}, inplace=True)\n",
    "        else:\n",
    "            df.drop([\"voiceID\"], inplace=True, axis=1)\n",
    "        df[\"label\"].value_counts()\n",
    "        df = df.dropna()\n",
    "\n",
    "        df_X = df.iloc[:, :-1]\n",
    "        df_Y = df.iloc[:, -1]\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(\n",
    "            df_X, df_Y, test_size=0.3, random_state=random_state\n",
    "        )\n",
    "\n",
    "        sc = MinMaxScaler()\n",
    "        x_train = sc.fit_transform(x_train)\n",
    "        x_test = sc.transform(x_test)\n",
    "        pd.DataFrame(x_train)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test,x_test_index,df\n",
    "\n",
    "\n",
    "def train_model(model_name: str, grid_search: bool, model_weights, x_train, y_train):\n",
    "    if model_name == \"svc\":\n",
    "        if grid_search:\n",
    "            grid = get_best_param_SVC(x_train=x_train, y_train=y_train)\n",
    "            model = grid.best_estimator_\n",
    "        else:\n",
    "            model = SVC(\n",
    "                C=model_weights[\"C\"],\n",
    "                gamma=model_weights[\"gamma\"],\n",
    "                kernel=model_weights[\"kernel\"],\n",
    "            )\n",
    "    elif model_name == \"lr\":\n",
    "        if grid_search:\n",
    "            grid = get_best_param_LR(x_train=x_train, y_train=y_train)\n",
    "            model = grid.best_estimator_\n",
    "        else:\n",
    "            model = LogisticRegression(\n",
    "                C=model_weights[\"C\"],\n",
    "                solver=model_weights[\"solver\"],\n",
    "                penalty=model_weights[\"penalty\"],\n",
    "            )\n",
    "    elif model_name == \"knn\":\n",
    "        if grid_search:\n",
    "            grid = get_best_param_KNN(x_train=x_train, y_train=y_train)\n",
    "            model = grid.best_estimator_\n",
    "        else:\n",
    "            model = KNeighborsClassifier(\n",
    "                n_neighbors=model_weights[\"n_neighbors\"],\n",
    "                weights=model_weights[\"weights\"],\n",
    "                metric=model_weights[\"metric\"],\n",
    "            )\n",
    "    elif model_name == \"rf\":\n",
    "        if grid_search:\n",
    "            grid = get_best_param_RF(x_train=x_train, y_train=y_train)\n",
    "            model = grid.best_estimator_\n",
    "        else:\n",
    "            model = RandomForestClassifier(\n",
    "                n_estimators=model_weights[\"n_estimators\"],\n",
    "                max_features=model_weights[\"max_features\"],\n",
    "                max_depth=model_weights[\"max_depth\"],\n",
    "                criterion=model_weights[\"criterion\"],\n",
    "            )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_test_model(\n",
    "    filename: str,\n",
    "    model_name: str,\n",
    "    chunked: bool = False,\n",
    "    reduce: str = \"mrmr\",\n",
    "    isTranscript: bool = True,\n",
    "    grid_search: bool = True,\n",
    "    model_weights: dict = {},\n",
    "    random_state: int = 0,\n",
    "):\n",
    "    x_train, x_test, y_train, y_test,x_test_index,df = read_and_split(\n",
    "        filename=filename,\n",
    "        isTranscript=isTranscript,\n",
    "        reduce=reduce,\n",
    "        random_state=random_state,\n",
    "        chunked=chunked,\n",
    "    )\n",
    "\n",
    "    # Train ML model\n",
    "    model = train_model(\n",
    "        model_name=model_name,\n",
    "        grid_search=grid_search,\n",
    "        model_weights=model_weights,\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "    )\n",
    "\n",
    "    # Validate with training data\n",
    "    accuracy, specificiy, recall, precision, f1_score = validate_model(\n",
    "        model, pd.DataFrame(x_train), pd.DataFrame(y_train)\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"\\tAverage Accuracy: {accuracy} \\n\\\n",
    "      Average Specificity: {specificiy} \\n\\\n",
    "      Average Recall: {recall}\\n\\\n",
    "      Average Precision:{precision}\\n\\\n",
    "      Average F1 score {f1_score}\\n\\\n",
    "      \"\n",
    "    )\n",
    "\n",
    "    # Test with test data\n",
    "    accuracy, specificiy, recall, precision, f1_score = evaluate_model(\n",
    "        model=model, x_train=x_train, x_test=x_test, y_train=y_train, y_test=y_test,x_test_index = x_test_index,df=df\n",
    "    )\n",
    "    print(\"___________________\")\n",
    "    print(\"Evaluate model\")\n",
    "    print(\n",
    "        f\"\\tAccuracy: {accuracy} \\n\\\n",
    "    Specificity: {specificiy} \\n\\\n",
    "    Recall: {recall}\\n\\\n",
    "    Precision:{precision}\\n\\\n",
    "    F1 score {f1_score}\\n\\\n",
    "    \"\n",
    "    )\n",
    "\n",
    "    return accuracy, specificiy, recall, precision, f1_score\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\tAverage Accuracy: 60.47619047619048 \n",
      "      Average Specificity: 60.0 \n",
      "      Average Recall: 66.66666666666666\n",
      "      Average Precision:48.57142857142857\n",
      "      Average F1 score 54.28571428571429\n",
      "      \n",
      "___________________\n",
      "Evaluate model\n",
      "\tAccuracy: 81.81818181818183 \n",
      "    Specificity: 100.0 \n",
      "    Recall: 66.66666666666666\n",
      "    Precision:71.42857142857143\n",
      "    F1 score 83.33333333333333\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(81.81818181818183,\n",
       " 100.0,\n",
       " 66.66666666666666,\n",
       " 71.42857142857143,\n",
       " 83.33333333333333)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_model(filename= 'datasets/transformed/google/spontaneousDialogueOnly_google_bert_embeddings_transformed.csv', model_name= 'svc',reduce='pca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\tAverage Accuracy: 53.33333333333333 \n",
      "      Average Specificity: 38.33333333333333 \n",
      "      Average Recall: 71.66666666666666\n",
      "      Average Precision:50.666666666666664\n",
      "      Average F1 score 56.666666666666664\n",
      "      \n",
      "___________________\n",
      "Evaluate model\n",
      "\tAccuracy: 72.72727272727273 \n",
      "    Specificity: 100.0 \n",
      "    Recall: 50.0\n",
      "    Precision:62.5\n",
      "    F1 score 76.92307692307692\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(72.72727272727273, 100.0, 50.0, 62.5, 76.92307692307692)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_model(filename= 'datasets/transformed/google/spontaneousDialogueOnly_google_bert_embeddings_transformed.csv', model_name= 'lr',reduce='pca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 1, 'kernel': 'sigmoid', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\tAverage Accuracy: 50.476190476190474 \n",
      "      Average Specificity: 33.33333333333333 \n",
      "      Average Recall: 73.33333333333333\n",
      "      Average Precision:41.57142857142857\n",
      "      Average F1 score 52.47619047619047\n",
      "      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ID31_hc_0_1_1.flac</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ID20_pd_3_0_1_noPersonalQ.flac</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ID15_hc_0_0_0_noPersonalQ.flac</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ID30_pd_2_1_1_noPersonalQ.flac</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ID22_hc_0_0_0_noPersonalQ.flac</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ID14_hc_0_0_0.flac</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ID09_hc_0_0_0.flac</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID02_pd_2_0_0.flac</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ID10_hc_0_0_0_noPersonalQ.flac</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ID29_pd_3_1_2_noPersonalQ.flac</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ID27_pd_4_1_1_noPersonalQ.flac</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  y_pred  y_test\n",
       "31              ID31_hc_0_1_1.flac       1       0\n",
       "20  ID20_pd_3_0_1_noPersonalQ.flac       1       1\n",
       "16  ID15_hc_0_0_0_noPersonalQ.flac       1       0\n",
       "30  ID30_pd_2_1_1_noPersonalQ.flac       1       1\n",
       "22  ID22_hc_0_0_0_noPersonalQ.flac       1       0\n",
       "15              ID14_hc_0_0_0.flac       0       0\n",
       "10              ID09_hc_0_0_0.flac       1       0\n",
       "2               ID02_pd_2_0_0.flac       1       1\n",
       "11  ID10_hc_0_0_0_noPersonalQ.flac       0       0\n",
       "29  ID29_pd_3_1_2_noPersonalQ.flac       1       1\n",
       "27  ID27_pd_4_1_1_noPersonalQ.flac       1       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "id\n",
       "ID31_hc_0_1_1.flac                1.0\n",
       "ID20_pd_3_0_1_noPersonalQ.flac    1.0\n",
       "ID15_hc_0_0_0_noPersonalQ.flac    1.0\n",
       "ID30_pd_2_1_1_noPersonalQ.flac    1.0\n",
       "ID22_hc_0_0_0_noPersonalQ.flac    1.0\n",
       "ID14_hc_0_0_0.flac                0.0\n",
       "ID09_hc_0_0_0.flac                1.0\n",
       "ID02_pd_2_0_0.flac                1.0\n",
       "ID10_hc_0_0_0_noPersonalQ.flac    0.0\n",
       "ID29_pd_3_1_2_noPersonalQ.flac    1.0\n",
       "ID27_pd_4_1_1_noPersonalQ.flac    1.0\n",
       "Name: y_pred, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________\n",
      "Evaluate model\n",
      "\tAccuracy: 63.63636363636363 \n",
      "    Specificity: 100.0 \n",
      "    Recall: 33.33333333333333\n",
      "    Precision:55.55555555555556\n",
      "    F1 score 71.42857142857143\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(63.63636363636363,\n",
       " 100.0,\n",
       " 33.33333333333333,\n",
       " 55.55555555555556,\n",
       " 71.42857142857143)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_model(filename= 'datasets/transformed/google/spontaneousDialogueOnly_google_bert_embeddings_transformed.csv', model_name= 'svc',reduce='lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 1, 'kernel': 'sigmoid', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\tAverage Accuracy: 97.49007936507937 \n",
      "      Average Specificity: 95.0 \n",
      "      Average Recall: 100.0\n",
      "      Average Precision:95.29106187929717\n",
      "      Average F1 score 97.56572469818738\n",
      "      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>ID35_hc_0_0_0_noPersonalQuestions.flac</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>ID11_hc_0_0_0_noPersonalQ.flac</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>ID28_hc_0_0_0_noPersonalQ.flac</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>ID22_hc_0_0_0_noPersonalQ.flac</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>ID15_hc_0_0_0_noPersonalQ.flac</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>ID10_hc_0_0_0_noPersonalQ.flac</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ID00_hc_0_0_0.flac</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>ID07_pd_2_0_0_noPersonalQ.flac</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>ID25_hc_0_0_0_noPersonalQ.flac</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>ID35_hc_0_0_0_noPersonalQuestions.flac</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  y_pred  y_test\n",
       "366  ID35_hc_0_0_0_noPersonalQuestions.flac       0       0\n",
       "155          ID11_hc_0_0_0_noPersonalQ.flac       1       0\n",
       "313          ID28_hc_0_0_0_noPersonalQ.flac       0       0\n",
       "269          ID22_hc_0_0_0_noPersonalQ.flac       0       0\n",
       "221          ID15_hc_0_0_0_noPersonalQ.flac       0       0\n",
       "..                                      ...     ...     ...\n",
       "144          ID10_hc_0_0_0_noPersonalQ.flac       0       0\n",
       "12                       ID00_hc_0_0_0.flac       0       0\n",
       "101          ID07_pd_2_0_0_noPersonalQ.flac       0       1\n",
       "293          ID25_hc_0_0_0_noPersonalQ.flac       0       0\n",
       "365  ID35_hc_0_0_0_noPersonalQuestions.flac       1       0\n",
       "\n",
       "[114 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "id\n",
       "ID35_hc_0_0_0_noPersonalQuestions.flac    1.0\n",
       "ID11_hc_0_0_0_noPersonalQ.flac            0.0\n",
       "ID28_hc_0_0_0_noPersonalQ.flac            1.0\n",
       "ID22_hc_0_0_0_noPersonalQ.flac            0.0\n",
       "ID15_hc_0_0_0_noPersonalQ.flac            0.0\n",
       "ID05_hc_0_0_0.flac                        0.0\n",
       "ID33_pd_3_2_2.flac                        0.0\n",
       "ID04_pd_2_0_1_noPersonalQ.flac            0.0\n",
       "ID09_hc_0_0_0.flac                        0.0\n",
       "ID03_hc_0_0_0_noPersonalQ.flac            0.0\n",
       "ID23_hc_0_0_0_noPersonalQ.flac            0.0\n",
       "ID20_pd_3_0_1_noPersonalQ.flac            1.0\n",
       "ID10_hc_0_0_0_noPersonalQ.flac            0.0\n",
       "ID16_pd_2_0_0_noPersonalQ.flac            1.0\n",
       "ID27_pd_4_1_1_noPersonalQ.flac            0.0\n",
       "ID26_hc_0_0_0_noPersonalQ.flac            0.0\n",
       "ID29_pd_3_1_2_noPersonalQ.flac            1.0\n",
       "ID07_pd_2_0_0_noPersonalQ.flac            0.0\n",
       "ID13_pd_3_2_2.flac                        0.0\n",
       "ID17_pd_2_1_0.flac                        1.0\n",
       "ID06_pd_3_1_1.flac                        0.0\n",
       "ID36_hc_0_0_0_noPersonalQ.flac            1.0\n",
       "ID00_hc_0_0_0.flac                        0.0\n",
       "ID24_pd_2_0_0_noPersonalQ.flac            1.0\n",
       "ID02_pd_2_0_0.flac                        0.0\n",
       "ID12_hc_0_0_0_noPersonalQ.flac            0.0\n",
       "ID01_hc_0_0_0.flac                        0.0\n",
       "ID05_hc_0_0_0_noPersonalQ.flac            0.0\n",
       "ID08_hc_0_0_0.flac                        0.0\n",
       "ID14_hc_0_0_0.flac                        0.0\n",
       "ID25_hc_0_0_0_noPersonalQ.flac            0.0\n",
       "ID31_hc_0_1_1.flac                        0.0\n",
       "Name: y_pred, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________\n",
      "Evaluate model\n",
      "\tAccuracy: 60.526315789473685 \n",
      "    Specificity: 50.0 \n",
      "    Recall: 66.66666666666666\n",
      "    Precision:46.666666666666664\n",
      "    F1 score 48.275862068965516\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60.526315789473685,\n",
       " 50.0,\n",
       " 66.66666666666666,\n",
       " 46.666666666666664,\n",
       " 48.275862068965516)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_model(filename= 'datasets/transformed/google/spontaneousDialogueOnly_google_bert_sentence_embeddings_transformed.csv', model_name= 'svc',reduce='lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 1, 'kernel': 'sigmoid', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\tAverage Accuracy: 97.49007936507937 \n",
      "      Average Specificity: 95.0 \n",
      "      Average Recall: 100.0\n",
      "      Average Precision:95.29106187929717\n",
      "      Average F1 score 97.56572469818738\n",
      "      \n",
      "___________________\n",
      "Evaluate model\n",
      "\tAccuracy: 68.75 \n",
      "    Specificity: 41.66666666666667 \n",
      "    Recall: 85.0\n",
      "    Precision:62.5\n",
      "    F1 score 50.0\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(68.75, 41.66666666666667, 85.0, 62.5, 50.0)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_model(filename= 'datasets/transformed/google/spontaneousDialogueOnly_google_bert_sentence_embeddings_transformed.csv', model_name= 'svc',reduce='lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:05<00:00,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'manhattan', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}\n",
      "\tAverage Accuracy: 96.66666666666667 \n",
      "      Average Specificity: 93.33333333333333 \n",
      "      Average Recall: 100.0\n",
      "      Average Precision:95.0\n",
      "      Average F1 score 97.14285714285714\n",
      "      \n",
      "___________________\n",
      "Evaluate model\n",
      "\tAccuracy: 63.63636363636363 \n",
      "    Specificity: 80.0 \n",
      "    Recall: 50.0\n",
      "    Precision:57.14285714285714\n",
      "    F1 score 66.66666666666666\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(63.63636363636363, 80.0, 50.0, 57.14285714285714, 66.66666666666666)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_model(filename= 'datasets/transformed/google/spontaneousDialogueOnly_google_bert_embeddings_transformed.csv', model_name= 'knn',reduce='mrmr')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
