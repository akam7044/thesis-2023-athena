{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369277.02s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (4.28.1)\n",
      "Requirement already satisfied: filelock in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from transformers) (0.13.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: requests in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/athena.kam/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2022.12.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "from time import ctime\n",
    "import tracemalloc\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create embeddings \n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "import pandas as pd\n",
    "tokenizer_nltk = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Max token whisper:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Max token google:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def split_paragraph(filename):\n",
    "    df = pd.read_csv(filename+'.csv')\n",
    "    col_names = list(df.columns)\n",
    "    df_new = pd.DataFrame()\n",
    "    rows = len(df)\n",
    "\n",
    "    for row in range(rows):\n",
    "        df_entry = pd.DataFrame()\n",
    "        transcript_list = []\n",
    "\n",
    "        transcript = df.iloc[row].transcripts\n",
    "        transcript_list=tokenizer_nltk.tokenize(transcript)\n",
    "        n_sentences = len(transcript_list)\n",
    "\n",
    "        for col in range(len(col_names)):\n",
    "            if col_names[col] != \"transcripts\":\n",
    "                df_entry[col_names[col]] = [df.iloc[row][col_names[col]]]*n_sentences\n",
    "            else:\n",
    "                df_entry[\"transcripts\"] = transcript_list\n",
    "\n",
    "        df_new = pd.concat([df_new,df_entry])\n",
    "\n",
    "    df_new = df_new.reset_index(drop=True)\n",
    "\n",
    "    return df_new\n",
    "\n",
    "def find_max_token (df):\n",
    "    max_len = 0\n",
    "    transcripts = df['transcripts'].values\n",
    "\n",
    "    for transcript in transcripts:\n",
    "        #transcript = \"[SEP]\".join(sent_detector.tokenize(transcript.strip())) #for each sentence we need a sentence seperator operator \n",
    "        input_ids = tokenizer.encode(transcript,add_special_tokens=True)\n",
    "        max_len = max(max_len,len(input_ids))\n",
    "    \n",
    "    return max_len\n",
    "\n",
    "df_whisper = split_paragraph(\"spontaneousDialogueOnly_whisper\")\n",
    "max_len_whisper = find_max_token(df_whisper)\n",
    "df_google = split_paragraph(\"spontaneousDialogueOnly_google\")\n",
    "max_len_google = find_max_token(df_google)\n",
    "\n",
    "display('Max token whisper:',max_len_whisper)\n",
    "display('Max token google:',max_len_google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create tokens \n",
    "def create_tokens(df,max_token_len):\n",
    "    print(\"creating tokens\")\n",
    "    print(ctime())\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    transcripts = df.transcripts.values\n",
    "\n",
    "    for transcript in transcripts:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                        transcript,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = max_token_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "    # Convert the lists into tensors.\n",
    "    df[\"input_ids\"] = input_ids\n",
    "    df[\"attention_masks\"] = attention_masks   \n",
    "\n",
    "    return df\n",
    "\n",
    "def create_embeddings(input_id,mask):\n",
    "    outputs = model(input_id, mask)\n",
    "\n",
    "    # Evaluating the model will return a different number of objects based on \n",
    "    # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "    # becase we set `output_hidden_states = True`, the third item will be the \n",
    "    # hidden states from all layers. See the documentation for more details:\n",
    "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "    hidden_states = outputs[2]\n",
    "\n",
    "    # Concatenate the tensors for all layers. We use `stack` here to\n",
    "    # create a new dimension in the tensor.\n",
    "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "\n",
    "    # Remove dimension 1, the \"batches\".\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "    # `token_vecs` is a tensor with shape [430 x 768]\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "\n",
    "    # Calculate the sentence token\n",
    "    return torch.mean(token_vecs, dim=0) \n",
    "\n",
    "\n",
    "def split_paragraph(filename):\n",
    "    df = pd.read_csv(filename+'.csv')\n",
    "    col_names = list(df.columns)\n",
    "    df_new = pd.DataFrame()\n",
    "    rows = len(df)\n",
    "\n",
    "    for row in range(rows):\n",
    "        df_entry = pd.DataFrame()\n",
    "        transcript_list = []\n",
    "\n",
    "        transcript = df.iloc[row].transcripts\n",
    "        transcript_list=tokenizer_nltk.tokenize(transcript)\n",
    "        n_sentences = len(transcript_list)\n",
    "\n",
    "        for col in range(len(col_names)):\n",
    "            if col_names[col] != \"transcripts\":\n",
    "                df_entry[col_names[col]] = [df.iloc[row][col_names[col]]]*n_sentences\n",
    "            else:\n",
    "                df_entry[\"transcripts\"] = transcript_list\n",
    "\n",
    "        df_new = pd.concat([df_new,df_entry])\n",
    "\n",
    "    df_new = df_new.reset_index(drop=True)\n",
    "\n",
    "    return df_new\n",
    "\n",
    "def collect_embeddings(filename:str,save_csv:bool,max_token_len:int):\n",
    "    df = split_paragraph(filename)\n",
    "    df = create_tokens(df,max_token_len)\n",
    "\n",
    "    print(\"creating embeddings\")\n",
    "    print(ctime())\n",
    "    embeddings = []\n",
    "    rows = len(df)\n",
    "    \n",
    "    tracemalloc.start()\n",
    "    for row in range(rows):\n",
    "        print(f\"{row} of {rows}\")\n",
    "        input_id = df.iloc[row].input_ids.reshape(1,max_token_len)\n",
    "        mask = df.iloc[row].attention_masks.reshape(1,max_token_len)\n",
    "        embeddings.append(create_embeddings(input_id,mask).detach().numpy())\n",
    "        print(\"done\")\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    print(f\"Current memory usage is {current / 10**6}MB; Peak was {peak / 10**6}MB\")\n",
    "    tracemalloc.stop()\n",
    "    \n",
    "    df[\"embeddings\"] = embeddings\n",
    "    if save_csv:\n",
    "        out_filename = filename+'_bert_sentence_embeddings.csv'\n",
    "        df.to_csv(out_filename)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating tokens\n",
      "Mon Jun 19 16:15:33 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/athena.kam/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating embeddings\n",
      "Mon Jun 19 16:15:34 2023\n",
      "0 of 720\n",
      "done\n",
      "1 of 720\n",
      "done\n",
      "2 of 720\n",
      "done\n",
      "3 of 720\n",
      "done\n",
      "4 of 720\n",
      "done\n",
      "5 of 720\n",
      "done\n",
      "6 of 720\n",
      "done\n",
      "7 of 720\n",
      "done\n",
      "8 of 720\n",
      "done\n",
      "9 of 720\n",
      "done\n",
      "10 of 720\n",
      "done\n",
      "11 of 720\n",
      "done\n",
      "12 of 720\n",
      "done\n",
      "13 of 720\n",
      "done\n",
      "14 of 720\n",
      "done\n",
      "15 of 720\n",
      "done\n",
      "16 of 720\n",
      "done\n",
      "17 of 720\n",
      "done\n",
      "18 of 720\n",
      "done\n",
      "19 of 720\n",
      "done\n",
      "20 of 720\n",
      "done\n",
      "21 of 720\n",
      "done\n",
      "22 of 720\n",
      "done\n",
      "23 of 720\n",
      "done\n",
      "24 of 720\n",
      "done\n",
      "25 of 720\n",
      "done\n",
      "26 of 720\n",
      "done\n",
      "27 of 720\n",
      "done\n",
      "28 of 720\n",
      "done\n",
      "29 of 720\n",
      "done\n",
      "30 of 720\n",
      "done\n",
      "31 of 720\n",
      "done\n",
      "32 of 720\n",
      "done\n",
      "33 of 720\n",
      "done\n",
      "34 of 720\n",
      "done\n",
      "35 of 720\n",
      "done\n",
      "36 of 720\n",
      "done\n",
      "37 of 720\n",
      "done\n",
      "38 of 720\n",
      "done\n",
      "39 of 720\n",
      "done\n",
      "40 of 720\n",
      "done\n",
      "41 of 720\n",
      "done\n",
      "42 of 720\n",
      "done\n",
      "43 of 720\n",
      "done\n",
      "44 of 720\n",
      "done\n",
      "45 of 720\n",
      "done\n",
      "46 of 720\n",
      "done\n",
      "47 of 720\n",
      "done\n",
      "48 of 720\n",
      "done\n",
      "49 of 720\n",
      "done\n",
      "50 of 720\n",
      "done\n",
      "51 of 720\n",
      "done\n",
      "52 of 720\n",
      "done\n",
      "53 of 720\n",
      "done\n",
      "54 of 720\n",
      "done\n",
      "55 of 720\n",
      "done\n",
      "56 of 720\n",
      "done\n",
      "57 of 720\n",
      "done\n",
      "58 of 720\n",
      "done\n",
      "59 of 720\n",
      "done\n",
      "60 of 720\n",
      "done\n",
      "61 of 720\n",
      "done\n",
      "62 of 720\n",
      "done\n",
      "63 of 720\n",
      "done\n",
      "64 of 720\n",
      "done\n",
      "65 of 720\n",
      "done\n",
      "66 of 720\n",
      "done\n",
      "67 of 720\n",
      "done\n",
      "68 of 720\n",
      "done\n",
      "69 of 720\n",
      "done\n",
      "70 of 720\n",
      "done\n",
      "71 of 720\n",
      "done\n",
      "72 of 720\n",
      "done\n",
      "73 of 720\n",
      "done\n",
      "74 of 720\n",
      "done\n",
      "75 of 720\n",
      "done\n",
      "76 of 720\n",
      "done\n",
      "77 of 720\n",
      "done\n",
      "78 of 720\n",
      "done\n",
      "79 of 720\n",
      "done\n",
      "80 of 720\n",
      "done\n",
      "81 of 720\n",
      "done\n",
      "82 of 720\n",
      "done\n",
      "83 of 720\n",
      "done\n",
      "84 of 720\n",
      "done\n",
      "85 of 720\n",
      "done\n",
      "86 of 720\n",
      "done\n",
      "87 of 720\n",
      "done\n",
      "88 of 720\n",
      "done\n",
      "89 of 720\n",
      "done\n",
      "90 of 720\n",
      "done\n",
      "91 of 720\n",
      "done\n",
      "92 of 720\n",
      "done\n",
      "93 of 720\n",
      "done\n",
      "94 of 720\n",
      "done\n",
      "95 of 720\n",
      "done\n",
      "96 of 720\n",
      "done\n",
      "97 of 720\n",
      "done\n",
      "98 of 720\n",
      "done\n",
      "99 of 720\n",
      "done\n",
      "100 of 720\n",
      "done\n",
      "101 of 720\n",
      "done\n",
      "102 of 720\n",
      "done\n",
      "103 of 720\n",
      "done\n",
      "104 of 720\n",
      "done\n",
      "105 of 720\n",
      "done\n",
      "106 of 720\n",
      "done\n",
      "107 of 720\n",
      "done\n",
      "108 of 720\n",
      "done\n",
      "109 of 720\n",
      "done\n",
      "110 of 720\n",
      "done\n",
      "111 of 720\n",
      "done\n",
      "112 of 720\n",
      "done\n",
      "113 of 720\n",
      "done\n",
      "114 of 720\n",
      "done\n",
      "115 of 720\n",
      "done\n",
      "116 of 720\n",
      "done\n",
      "117 of 720\n",
      "done\n",
      "118 of 720\n",
      "done\n",
      "119 of 720\n",
      "done\n",
      "120 of 720\n",
      "done\n",
      "121 of 720\n",
      "done\n",
      "122 of 720\n",
      "done\n",
      "123 of 720\n",
      "done\n",
      "124 of 720\n",
      "done\n",
      "125 of 720\n",
      "done\n",
      "126 of 720\n",
      "done\n",
      "127 of 720\n",
      "done\n",
      "128 of 720\n",
      "done\n",
      "129 of 720\n",
      "done\n",
      "130 of 720\n",
      "done\n",
      "131 of 720\n",
      "done\n",
      "132 of 720\n",
      "done\n",
      "133 of 720\n",
      "done\n",
      "134 of 720\n",
      "done\n",
      "135 of 720\n",
      "done\n",
      "136 of 720\n",
      "done\n",
      "137 of 720\n",
      "done\n",
      "138 of 720\n",
      "done\n",
      "139 of 720\n",
      "done\n",
      "140 of 720\n",
      "done\n",
      "141 of 720\n",
      "done\n",
      "142 of 720\n",
      "done\n",
      "143 of 720\n",
      "done\n",
      "144 of 720\n",
      "done\n",
      "145 of 720\n",
      "done\n",
      "146 of 720\n",
      "done\n",
      "147 of 720\n",
      "done\n",
      "148 of 720\n",
      "done\n",
      "149 of 720\n",
      "done\n",
      "150 of 720\n",
      "done\n",
      "151 of 720\n",
      "done\n",
      "152 of 720\n",
      "done\n",
      "153 of 720\n",
      "done\n",
      "154 of 720\n",
      "done\n",
      "155 of 720\n",
      "done\n",
      "156 of 720\n",
      "done\n",
      "157 of 720\n",
      "done\n",
      "158 of 720\n",
      "done\n",
      "159 of 720\n",
      "done\n",
      "160 of 720\n",
      "done\n",
      "161 of 720\n",
      "done\n",
      "162 of 720\n",
      "done\n",
      "163 of 720\n",
      "done\n",
      "164 of 720\n",
      "done\n",
      "165 of 720\n",
      "done\n",
      "166 of 720\n",
      "done\n",
      "167 of 720\n",
      "done\n",
      "168 of 720\n",
      "done\n",
      "169 of 720\n",
      "done\n",
      "170 of 720\n",
      "done\n",
      "171 of 720\n",
      "done\n",
      "172 of 720\n",
      "done\n",
      "173 of 720\n",
      "done\n",
      "174 of 720\n",
      "done\n",
      "175 of 720\n",
      "done\n",
      "176 of 720\n",
      "done\n",
      "177 of 720\n",
      "done\n",
      "178 of 720\n",
      "done\n",
      "179 of 720\n",
      "done\n",
      "180 of 720\n",
      "done\n",
      "181 of 720\n",
      "done\n",
      "182 of 720\n",
      "done\n",
      "183 of 720\n",
      "done\n",
      "184 of 720\n",
      "done\n",
      "185 of 720\n",
      "done\n",
      "186 of 720\n",
      "done\n",
      "187 of 720\n",
      "done\n",
      "188 of 720\n",
      "done\n",
      "189 of 720\n",
      "done\n",
      "190 of 720\n",
      "done\n",
      "191 of 720\n",
      "done\n",
      "192 of 720\n",
      "done\n",
      "193 of 720\n",
      "done\n",
      "194 of 720\n",
      "done\n",
      "195 of 720\n",
      "done\n",
      "196 of 720\n",
      "done\n",
      "197 of 720\n",
      "done\n",
      "198 of 720\n",
      "done\n",
      "199 of 720\n",
      "done\n",
      "200 of 720\n",
      "done\n",
      "201 of 720\n",
      "done\n",
      "202 of 720\n",
      "done\n",
      "203 of 720\n",
      "done\n",
      "204 of 720\n",
      "done\n",
      "205 of 720\n",
      "done\n",
      "206 of 720\n",
      "done\n",
      "207 of 720\n",
      "done\n",
      "208 of 720\n",
      "done\n",
      "209 of 720\n",
      "done\n",
      "210 of 720\n",
      "done\n",
      "211 of 720\n",
      "done\n",
      "212 of 720\n",
      "done\n",
      "213 of 720\n",
      "done\n",
      "214 of 720\n",
      "done\n",
      "215 of 720\n",
      "done\n",
      "216 of 720\n",
      "done\n",
      "217 of 720\n",
      "done\n",
      "218 of 720\n",
      "done\n",
      "219 of 720\n",
      "done\n",
      "220 of 720\n",
      "done\n",
      "221 of 720\n",
      "done\n",
      "222 of 720\n",
      "done\n",
      "223 of 720\n",
      "done\n",
      "224 of 720\n",
      "done\n",
      "225 of 720\n",
      "done\n",
      "226 of 720\n",
      "done\n",
      "227 of 720\n",
      "done\n",
      "228 of 720\n",
      "done\n",
      "229 of 720\n",
      "done\n",
      "230 of 720\n",
      "done\n",
      "231 of 720\n",
      "done\n",
      "232 of 720\n",
      "done\n",
      "233 of 720\n",
      "done\n",
      "234 of 720\n",
      "done\n",
      "235 of 720\n",
      "done\n",
      "236 of 720\n",
      "done\n",
      "237 of 720\n",
      "done\n",
      "238 of 720\n",
      "done\n",
      "239 of 720\n",
      "done\n",
      "240 of 720\n",
      "done\n",
      "241 of 720\n",
      "done\n",
      "242 of 720\n",
      "done\n",
      "243 of 720\n",
      "done\n",
      "244 of 720\n",
      "done\n",
      "245 of 720\n",
      "done\n",
      "246 of 720\n",
      "done\n",
      "247 of 720\n",
      "done\n",
      "248 of 720\n",
      "done\n",
      "249 of 720\n",
      "done\n",
      "250 of 720\n",
      "done\n",
      "251 of 720\n",
      "done\n",
      "252 of 720\n",
      "done\n",
      "253 of 720\n",
      "done\n",
      "254 of 720\n",
      "done\n",
      "255 of 720\n",
      "done\n",
      "256 of 720\n",
      "done\n",
      "257 of 720\n",
      "done\n",
      "258 of 720\n",
      "done\n",
      "259 of 720\n",
      "done\n",
      "260 of 720\n",
      "done\n",
      "261 of 720\n",
      "done\n",
      "262 of 720\n",
      "done\n",
      "263 of 720\n",
      "done\n",
      "264 of 720\n",
      "done\n",
      "265 of 720\n",
      "done\n",
      "266 of 720\n",
      "done\n",
      "267 of 720\n",
      "done\n",
      "268 of 720\n",
      "done\n",
      "269 of 720\n",
      "done\n",
      "270 of 720\n",
      "done\n",
      "271 of 720\n",
      "done\n",
      "272 of 720\n",
      "done\n",
      "273 of 720\n",
      "done\n",
      "274 of 720\n",
      "done\n",
      "275 of 720\n",
      "done\n",
      "276 of 720\n",
      "done\n",
      "277 of 720\n",
      "done\n",
      "278 of 720\n",
      "done\n",
      "279 of 720\n",
      "done\n",
      "280 of 720\n",
      "done\n",
      "281 of 720\n",
      "done\n",
      "282 of 720\n",
      "done\n",
      "283 of 720\n",
      "done\n",
      "284 of 720\n",
      "done\n",
      "285 of 720\n",
      "done\n",
      "286 of 720\n",
      "done\n",
      "287 of 720\n",
      "done\n",
      "288 of 720\n",
      "done\n",
      "289 of 720\n",
      "done\n",
      "290 of 720\n",
      "done\n",
      "291 of 720\n",
      "done\n",
      "292 of 720\n",
      "done\n",
      "293 of 720\n",
      "done\n",
      "294 of 720\n",
      "done\n",
      "295 of 720\n",
      "done\n",
      "296 of 720\n",
      "done\n",
      "297 of 720\n",
      "done\n",
      "298 of 720\n",
      "done\n",
      "299 of 720\n",
      "done\n",
      "300 of 720\n",
      "done\n",
      "301 of 720\n",
      "done\n",
      "302 of 720\n",
      "done\n",
      "303 of 720\n",
      "done\n",
      "304 of 720\n",
      "done\n",
      "305 of 720\n",
      "done\n",
      "306 of 720\n",
      "done\n",
      "307 of 720\n",
      "done\n",
      "308 of 720\n",
      "done\n",
      "309 of 720\n",
      "done\n",
      "310 of 720\n",
      "done\n",
      "311 of 720\n",
      "done\n",
      "312 of 720\n",
      "done\n",
      "313 of 720\n",
      "done\n",
      "314 of 720\n",
      "done\n",
      "315 of 720\n",
      "done\n",
      "316 of 720\n",
      "done\n",
      "317 of 720\n",
      "done\n",
      "318 of 720\n",
      "done\n",
      "319 of 720\n",
      "done\n",
      "320 of 720\n",
      "done\n",
      "321 of 720\n",
      "done\n",
      "322 of 720\n",
      "done\n",
      "323 of 720\n",
      "done\n",
      "324 of 720\n",
      "done\n",
      "325 of 720\n",
      "done\n",
      "326 of 720\n",
      "done\n",
      "327 of 720\n",
      "done\n",
      "328 of 720\n",
      "done\n",
      "329 of 720\n",
      "done\n",
      "330 of 720\n",
      "done\n",
      "331 of 720\n",
      "done\n",
      "332 of 720\n",
      "done\n",
      "333 of 720\n",
      "done\n",
      "334 of 720\n",
      "done\n",
      "335 of 720\n",
      "done\n",
      "336 of 720\n",
      "done\n",
      "337 of 720\n",
      "done\n",
      "338 of 720\n",
      "done\n",
      "339 of 720\n",
      "done\n",
      "340 of 720\n",
      "done\n",
      "341 of 720\n",
      "done\n",
      "342 of 720\n",
      "done\n",
      "343 of 720\n",
      "done\n",
      "344 of 720\n",
      "done\n",
      "345 of 720\n",
      "done\n",
      "346 of 720\n",
      "done\n",
      "347 of 720\n",
      "done\n",
      "348 of 720\n",
      "done\n",
      "349 of 720\n",
      "done\n",
      "350 of 720\n",
      "done\n",
      "351 of 720\n",
      "done\n",
      "352 of 720\n",
      "done\n",
      "353 of 720\n",
      "done\n",
      "354 of 720\n",
      "done\n",
      "355 of 720\n",
      "done\n",
      "356 of 720\n",
      "done\n",
      "357 of 720\n",
      "done\n",
      "358 of 720\n",
      "done\n",
      "359 of 720\n",
      "done\n",
      "360 of 720\n",
      "done\n",
      "361 of 720\n",
      "done\n",
      "362 of 720\n",
      "done\n",
      "363 of 720\n",
      "done\n",
      "364 of 720\n",
      "done\n",
      "365 of 720\n",
      "done\n",
      "366 of 720\n",
      "done\n",
      "367 of 720\n",
      "done\n",
      "368 of 720\n",
      "done\n",
      "369 of 720\n",
      "done\n",
      "370 of 720\n",
      "done\n",
      "371 of 720\n",
      "done\n",
      "372 of 720\n",
      "done\n",
      "373 of 720\n",
      "done\n",
      "374 of 720\n",
      "done\n",
      "375 of 720\n",
      "done\n",
      "376 of 720\n",
      "done\n",
      "377 of 720\n",
      "done\n",
      "378 of 720\n",
      "done\n",
      "379 of 720\n",
      "done\n",
      "380 of 720\n",
      "done\n",
      "381 of 720\n",
      "done\n",
      "382 of 720\n",
      "done\n",
      "383 of 720\n",
      "done\n",
      "384 of 720\n",
      "done\n",
      "385 of 720\n",
      "done\n",
      "386 of 720\n",
      "done\n",
      "387 of 720\n",
      "done\n",
      "388 of 720\n",
      "done\n",
      "389 of 720\n",
      "done\n",
      "390 of 720\n",
      "done\n",
      "391 of 720\n",
      "done\n",
      "392 of 720\n",
      "done\n",
      "393 of 720\n",
      "done\n",
      "394 of 720\n",
      "done\n",
      "395 of 720\n",
      "done\n",
      "396 of 720\n",
      "done\n",
      "397 of 720\n",
      "done\n",
      "398 of 720\n",
      "done\n",
      "399 of 720\n",
      "done\n",
      "400 of 720\n",
      "done\n",
      "401 of 720\n",
      "done\n",
      "402 of 720\n",
      "done\n",
      "403 of 720\n",
      "done\n",
      "404 of 720\n",
      "done\n",
      "405 of 720\n",
      "done\n",
      "406 of 720\n",
      "done\n",
      "407 of 720\n",
      "done\n",
      "408 of 720\n",
      "done\n",
      "409 of 720\n",
      "done\n",
      "410 of 720\n",
      "done\n",
      "411 of 720\n",
      "done\n",
      "412 of 720\n",
      "done\n",
      "413 of 720\n",
      "done\n",
      "414 of 720\n",
      "done\n",
      "415 of 720\n",
      "done\n",
      "416 of 720\n",
      "done\n",
      "417 of 720\n",
      "done\n",
      "418 of 720\n",
      "done\n",
      "419 of 720\n",
      "done\n",
      "420 of 720\n",
      "done\n",
      "421 of 720\n",
      "done\n",
      "422 of 720\n",
      "done\n",
      "423 of 720\n",
      "done\n",
      "424 of 720\n",
      "done\n",
      "425 of 720\n",
      "done\n",
      "426 of 720\n",
      "done\n",
      "427 of 720\n",
      "done\n",
      "428 of 720\n",
      "done\n",
      "429 of 720\n",
      "done\n",
      "430 of 720\n",
      "done\n",
      "431 of 720\n",
      "done\n",
      "432 of 720\n",
      "done\n",
      "433 of 720\n",
      "done\n",
      "434 of 720\n",
      "done\n",
      "435 of 720\n",
      "done\n",
      "436 of 720\n",
      "done\n",
      "437 of 720\n",
      "done\n",
      "438 of 720\n",
      "done\n",
      "439 of 720\n",
      "done\n",
      "440 of 720\n",
      "done\n",
      "441 of 720\n",
      "done\n",
      "442 of 720\n",
      "done\n",
      "443 of 720\n",
      "done\n",
      "444 of 720\n",
      "done\n",
      "445 of 720\n",
      "done\n",
      "446 of 720\n",
      "done\n",
      "447 of 720\n",
      "done\n",
      "448 of 720\n",
      "done\n",
      "449 of 720\n",
      "done\n",
      "450 of 720\n",
      "done\n",
      "451 of 720\n",
      "done\n",
      "452 of 720\n",
      "done\n",
      "453 of 720\n",
      "done\n",
      "454 of 720\n",
      "done\n",
      "455 of 720\n",
      "done\n",
      "456 of 720\n",
      "done\n",
      "457 of 720\n",
      "done\n",
      "458 of 720\n",
      "done\n",
      "459 of 720\n",
      "done\n",
      "460 of 720\n",
      "done\n",
      "461 of 720\n",
      "done\n",
      "462 of 720\n",
      "done\n",
      "463 of 720\n",
      "done\n",
      "464 of 720\n",
      "done\n",
      "465 of 720\n",
      "done\n",
      "466 of 720\n",
      "done\n",
      "467 of 720\n",
      "done\n",
      "468 of 720\n",
      "done\n",
      "469 of 720\n",
      "done\n",
      "470 of 720\n",
      "done\n",
      "471 of 720\n",
      "done\n",
      "472 of 720\n",
      "done\n",
      "473 of 720\n",
      "done\n",
      "474 of 720\n",
      "done\n",
      "475 of 720\n",
      "done\n",
      "476 of 720\n",
      "done\n",
      "477 of 720\n",
      "done\n",
      "478 of 720\n",
      "done\n",
      "479 of 720\n",
      "done\n",
      "480 of 720\n",
      "done\n",
      "481 of 720\n",
      "done\n",
      "482 of 720\n",
      "done\n",
      "483 of 720\n",
      "done\n",
      "484 of 720\n",
      "done\n",
      "485 of 720\n",
      "done\n",
      "486 of 720\n",
      "done\n",
      "487 of 720\n",
      "done\n",
      "488 of 720\n",
      "done\n",
      "489 of 720\n",
      "done\n",
      "490 of 720\n",
      "done\n",
      "491 of 720\n",
      "done\n",
      "492 of 720\n",
      "done\n",
      "493 of 720\n",
      "done\n",
      "494 of 720\n",
      "done\n",
      "495 of 720\n",
      "done\n",
      "496 of 720\n",
      "done\n",
      "497 of 720\n",
      "done\n",
      "498 of 720\n",
      "done\n",
      "499 of 720\n",
      "done\n",
      "500 of 720\n",
      "done\n",
      "501 of 720\n",
      "done\n",
      "502 of 720\n",
      "done\n",
      "503 of 720\n",
      "done\n",
      "504 of 720\n",
      "done\n",
      "505 of 720\n",
      "done\n",
      "506 of 720\n",
      "done\n",
      "507 of 720\n",
      "done\n",
      "508 of 720\n",
      "done\n",
      "509 of 720\n",
      "done\n",
      "510 of 720\n",
      "done\n",
      "511 of 720\n",
      "done\n",
      "512 of 720\n",
      "done\n",
      "513 of 720\n",
      "done\n",
      "514 of 720\n",
      "done\n",
      "515 of 720\n",
      "done\n",
      "516 of 720\n",
      "done\n",
      "517 of 720\n",
      "done\n",
      "518 of 720\n",
      "done\n",
      "519 of 720\n",
      "done\n",
      "520 of 720\n",
      "done\n",
      "521 of 720\n",
      "done\n",
      "522 of 720\n",
      "done\n",
      "523 of 720\n",
      "done\n",
      "524 of 720\n",
      "done\n",
      "525 of 720\n",
      "done\n",
      "526 of 720\n",
      "done\n",
      "527 of 720\n",
      "done\n",
      "528 of 720\n",
      "done\n",
      "529 of 720\n",
      "done\n",
      "530 of 720\n",
      "done\n",
      "531 of 720\n",
      "done\n",
      "532 of 720\n",
      "done\n",
      "533 of 720\n",
      "done\n",
      "534 of 720\n",
      "done\n",
      "535 of 720\n",
      "done\n",
      "536 of 720\n",
      "done\n",
      "537 of 720\n",
      "done\n",
      "538 of 720\n",
      "done\n",
      "539 of 720\n",
      "done\n",
      "540 of 720\n",
      "done\n",
      "541 of 720\n",
      "done\n",
      "542 of 720\n",
      "done\n",
      "543 of 720\n",
      "done\n",
      "544 of 720\n",
      "done\n",
      "545 of 720\n",
      "done\n",
      "546 of 720\n",
      "done\n",
      "547 of 720\n",
      "done\n",
      "548 of 720\n",
      "done\n",
      "549 of 720\n",
      "done\n",
      "550 of 720\n",
      "done\n",
      "551 of 720\n",
      "done\n",
      "552 of 720\n",
      "done\n",
      "553 of 720\n",
      "done\n",
      "554 of 720\n",
      "done\n",
      "555 of 720\n",
      "done\n",
      "556 of 720\n",
      "done\n",
      "557 of 720\n",
      "done\n",
      "558 of 720\n",
      "done\n",
      "559 of 720\n",
      "done\n",
      "560 of 720\n",
      "done\n",
      "561 of 720\n",
      "done\n",
      "562 of 720\n",
      "done\n",
      "563 of 720\n",
      "done\n",
      "564 of 720\n",
      "done\n",
      "565 of 720\n",
      "done\n",
      "566 of 720\n",
      "done\n",
      "567 of 720\n",
      "done\n",
      "568 of 720\n",
      "done\n",
      "569 of 720\n",
      "done\n",
      "570 of 720\n",
      "done\n",
      "571 of 720\n",
      "done\n",
      "572 of 720\n",
      "done\n",
      "573 of 720\n",
      "done\n",
      "574 of 720\n",
      "done\n",
      "575 of 720\n",
      "done\n",
      "576 of 720\n",
      "done\n",
      "577 of 720\n",
      "done\n",
      "578 of 720\n",
      "done\n",
      "579 of 720\n",
      "done\n",
      "580 of 720\n",
      "done\n",
      "581 of 720\n",
      "done\n",
      "582 of 720\n",
      "done\n",
      "583 of 720\n",
      "done\n",
      "584 of 720\n",
      "done\n",
      "585 of 720\n",
      "done\n",
      "586 of 720\n",
      "done\n",
      "587 of 720\n",
      "done\n",
      "588 of 720\n",
      "done\n",
      "589 of 720\n",
      "done\n",
      "590 of 720\n",
      "done\n",
      "591 of 720\n",
      "done\n",
      "592 of 720\n",
      "done\n",
      "593 of 720\n",
      "done\n",
      "594 of 720\n",
      "done\n",
      "595 of 720\n",
      "done\n",
      "596 of 720\n",
      "done\n",
      "597 of 720\n",
      "done\n",
      "598 of 720\n",
      "done\n",
      "599 of 720\n",
      "done\n",
      "600 of 720\n",
      "done\n",
      "601 of 720\n",
      "done\n",
      "602 of 720\n",
      "done\n",
      "603 of 720\n",
      "done\n",
      "604 of 720\n",
      "done\n",
      "605 of 720\n",
      "done\n",
      "606 of 720\n",
      "done\n",
      "607 of 720\n",
      "done\n",
      "608 of 720\n",
      "done\n",
      "609 of 720\n",
      "done\n",
      "610 of 720\n",
      "done\n",
      "611 of 720\n",
      "done\n",
      "612 of 720\n",
      "done\n",
      "613 of 720\n",
      "done\n",
      "614 of 720\n",
      "done\n",
      "615 of 720\n",
      "done\n",
      "616 of 720\n",
      "done\n",
      "617 of 720\n",
      "done\n",
      "618 of 720\n",
      "done\n",
      "619 of 720\n",
      "done\n",
      "620 of 720\n",
      "done\n",
      "621 of 720\n",
      "done\n",
      "622 of 720\n",
      "done\n",
      "623 of 720\n",
      "done\n",
      "624 of 720\n",
      "done\n",
      "625 of 720\n",
      "done\n",
      "626 of 720\n",
      "done\n",
      "627 of 720\n",
      "done\n",
      "628 of 720\n",
      "done\n",
      "629 of 720\n",
      "done\n",
      "630 of 720\n",
      "done\n",
      "631 of 720\n",
      "done\n",
      "632 of 720\n",
      "done\n",
      "633 of 720\n",
      "done\n",
      "634 of 720\n",
      "done\n",
      "635 of 720\n",
      "done\n",
      "636 of 720\n",
      "done\n",
      "637 of 720\n",
      "done\n",
      "638 of 720\n",
      "done\n",
      "639 of 720\n",
      "done\n",
      "640 of 720\n",
      "done\n",
      "641 of 720\n",
      "done\n",
      "642 of 720\n",
      "done\n",
      "643 of 720\n",
      "done\n",
      "644 of 720\n",
      "done\n",
      "645 of 720\n",
      "done\n",
      "646 of 720\n",
      "done\n",
      "647 of 720\n",
      "done\n",
      "648 of 720\n",
      "done\n",
      "649 of 720\n",
      "done\n",
      "650 of 720\n",
      "done\n",
      "651 of 720\n",
      "done\n",
      "652 of 720\n",
      "done\n",
      "653 of 720\n",
      "done\n",
      "654 of 720\n",
      "done\n",
      "655 of 720\n",
      "done\n",
      "656 of 720\n",
      "done\n",
      "657 of 720\n",
      "done\n",
      "658 of 720\n",
      "done\n",
      "659 of 720\n",
      "done\n",
      "660 of 720\n",
      "done\n",
      "661 of 720\n",
      "done\n",
      "662 of 720\n",
      "done\n",
      "663 of 720\n",
      "done\n",
      "664 of 720\n",
      "done\n",
      "665 of 720\n",
      "done\n",
      "666 of 720\n",
      "done\n",
      "667 of 720\n",
      "done\n",
      "668 of 720\n",
      "done\n",
      "669 of 720\n",
      "done\n",
      "670 of 720\n",
      "done\n",
      "671 of 720\n",
      "done\n",
      "672 of 720\n",
      "done\n",
      "673 of 720\n",
      "done\n",
      "674 of 720\n",
      "done\n",
      "675 of 720\n",
      "done\n",
      "676 of 720\n",
      "done\n",
      "677 of 720\n",
      "done\n",
      "678 of 720\n",
      "done\n",
      "679 of 720\n",
      "done\n",
      "680 of 720\n",
      "done\n",
      "681 of 720\n",
      "done\n",
      "682 of 720\n",
      "done\n",
      "683 of 720\n",
      "done\n",
      "684 of 720\n",
      "done\n",
      "685 of 720\n",
      "done\n",
      "686 of 720\n",
      "done\n",
      "687 of 720\n",
      "done\n",
      "688 of 720\n",
      "done\n",
      "689 of 720\n",
      "done\n",
      "690 of 720\n",
      "done\n",
      "691 of 720\n",
      "done\n",
      "692 of 720\n",
      "done\n",
      "693 of 720\n",
      "done\n",
      "694 of 720\n",
      "done\n",
      "695 of 720\n",
      "done\n",
      "696 of 720\n",
      "done\n",
      "697 of 720\n",
      "done\n",
      "698 of 720\n",
      "done\n",
      "699 of 720\n",
      "done\n",
      "700 of 720\n",
      "done\n",
      "701 of 720\n",
      "done\n",
      "702 of 720\n",
      "done\n",
      "703 of 720\n",
      "done\n",
      "704 of 720\n",
      "done\n",
      "705 of 720\n",
      "done\n",
      "706 of 720\n",
      "done\n",
      "707 of 720\n",
      "done\n",
      "708 of 720\n",
      "done\n",
      "709 of 720\n",
      "done\n",
      "710 of 720\n",
      "done\n",
      "711 of 720\n",
      "done\n",
      "712 of 720\n",
      "done\n",
      "713 of 720\n",
      "done\n",
      "714 of 720\n",
      "done\n",
      "715 of 720\n",
      "done\n",
      "716 of 720\n",
      "done\n",
      "717 of 720\n",
      "done\n",
      "718 of 720\n",
      "done\n",
      "719 of 720\n",
      "done\n",
      "Current memory usage is 0.315499MB; Peak was 0.325291MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>transcripts</th>\n",
       "      <th>classification</th>\n",
       "      <th>noPersonalQ</th>\n",
       "      <th>personalQ</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_masks</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00_hc_0_0_0.wav</td>\n",
       "      <td>Yeah, in London you can go to Oxford Street, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(101), tensor(3398), tensor(1010), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>[0.4941955, -0.18511416, 0.46687454, -0.095507...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00_hc_0_0_0.wav</td>\n",
       "      <td>So it's a good place to see when you come to L...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(101), tensor(2061), tensor(2009), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>[0.25287876, -0.32395035, 0.529815, -0.0971847...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00_hc_0_0_0.wav</td>\n",
       "      <td>That's the Royal Family lives so you can come ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(101), tensor(2008), tensor(1005), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>[0.18737839, -0.5163338, 0.41265774, 0.4367547...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00_hc_0_0_0.wav</td>\n",
       "      <td>And there's other, there's Big Ben, the houses...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(101), tensor(1998), tensor(2045), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>[0.38002455, -0.02911241, 0.37295663, 0.010036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00_hc_0_0_0.wav</td>\n",
       "      <td>So that's a good place to go and there's the L...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(101), tensor(2061), tensor(2008), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>[0.55974483, -0.28615302, 0.37134624, -0.25334...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                        transcripts   \n",
       "0  ID00_hc_0_0_0.wav   Yeah, in London you can go to Oxford Street, ...  \\\n",
       "1  ID00_hc_0_0_0.wav  So it's a good place to see when you come to L...   \n",
       "2  ID00_hc_0_0_0.wav  That's the Royal Family lives so you can come ...   \n",
       "3  ID00_hc_0_0_0.wav  And there's other, there's Big Ben, the houses...   \n",
       "4  ID00_hc_0_0_0.wav  So that's a good place to go and there's the L...   \n",
       "\n",
       "   classification  noPersonalQ  personalQ   \n",
       "0               0            0          0  \\\n",
       "1               0            0          0   \n",
       "2               0            0          0   \n",
       "3               0            0          0   \n",
       "4               0            0          0   \n",
       "\n",
       "                                           input_ids   \n",
       "0  [[tensor(101), tensor(3398), tensor(1010), ten...  \\\n",
       "1  [[tensor(101), tensor(2061), tensor(2009), ten...   \n",
       "2  [[tensor(101), tensor(2008), tensor(1005), ten...   \n",
       "3  [[tensor(101), tensor(1998), tensor(2045), ten...   \n",
       "4  [[tensor(101), tensor(2061), tensor(2008), ten...   \n",
       "\n",
       "                                     attention_masks   \n",
       "0  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \\\n",
       "1  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "2  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "3  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "4  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.4941955, -0.18511416, 0.46687454, -0.095507...  \n",
       "1  [0.25287876, -0.32395035, 0.529815, -0.0971847...  \n",
       "2  [0.18737839, -0.5163338, 0.41265774, 0.4367547...  \n",
       "3  [0.38002455, -0.02911241, 0.37295663, 0.010036...  \n",
       "4  [0.55974483, -0.28615302, 0.37134624, -0.25334...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embeddings_whisper = collect_embeddings(\"spontaneousDialogueOnly_whisper\",False,150)\n",
    "df_embeddings_whisper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating tokens\n",
      "Mon Jun 19 16:19:17 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/athena.kam/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating embeddings\n",
      "Mon Jun 19 16:19:17 2023\n",
      "0 of 650\n",
      "done\n",
      "1 of 650\n",
      "done\n",
      "2 of 650\n",
      "done\n",
      "3 of 650\n",
      "done\n",
      "4 of 650\n",
      "done\n",
      "5 of 650\n",
      "done\n",
      "6 of 650\n",
      "done\n",
      "7 of 650\n",
      "done\n",
      "8 of 650\n",
      "done\n",
      "9 of 650\n",
      "done\n",
      "10 of 650\n",
      "done\n",
      "11 of 650\n",
      "done\n",
      "12 of 650\n",
      "done\n",
      "13 of 650\n",
      "done\n",
      "14 of 650\n",
      "done\n",
      "15 of 650\n",
      "done\n",
      "16 of 650\n",
      "done\n",
      "17 of 650\n",
      "done\n",
      "18 of 650\n",
      "done\n",
      "19 of 650\n",
      "done\n",
      "20 of 650\n",
      "done\n",
      "21 of 650\n",
      "done\n",
      "22 of 650\n",
      "done\n",
      "23 of 650\n",
      "done\n",
      "24 of 650\n",
      "done\n",
      "25 of 650\n",
      "done\n",
      "26 of 650\n",
      "done\n",
      "27 of 650\n",
      "done\n",
      "28 of 650\n",
      "done\n",
      "29 of 650\n",
      "done\n",
      "30 of 650\n",
      "done\n",
      "31 of 650\n",
      "done\n",
      "32 of 650\n",
      "done\n",
      "33 of 650\n",
      "done\n",
      "34 of 650\n",
      "done\n",
      "35 of 650\n",
      "done\n",
      "36 of 650\n",
      "done\n",
      "37 of 650\n",
      "done\n",
      "38 of 650\n",
      "done\n",
      "39 of 650\n",
      "done\n",
      "40 of 650\n",
      "done\n",
      "41 of 650\n",
      "done\n",
      "42 of 650\n",
      "done\n",
      "43 of 650\n",
      "done\n",
      "44 of 650\n",
      "done\n",
      "45 of 650\n",
      "done\n",
      "46 of 650\n",
      "done\n",
      "47 of 650\n",
      "done\n",
      "48 of 650\n",
      "done\n",
      "49 of 650\n",
      "done\n",
      "50 of 650\n",
      "done\n",
      "51 of 650\n",
      "done\n",
      "52 of 650\n",
      "done\n",
      "53 of 650\n",
      "done\n",
      "54 of 650\n",
      "done\n",
      "55 of 650\n",
      "done\n",
      "56 of 650\n",
      "done\n",
      "57 of 650\n",
      "done\n",
      "58 of 650\n",
      "done\n",
      "59 of 650\n",
      "done\n",
      "60 of 650\n",
      "done\n",
      "61 of 650\n",
      "done\n",
      "62 of 650\n",
      "done\n",
      "63 of 650\n",
      "done\n",
      "64 of 650\n",
      "done\n",
      "65 of 650\n",
      "done\n",
      "66 of 650\n",
      "done\n",
      "67 of 650\n",
      "done\n",
      "68 of 650\n",
      "done\n",
      "69 of 650\n",
      "done\n",
      "70 of 650\n",
      "done\n",
      "71 of 650\n",
      "done\n",
      "72 of 650\n",
      "done\n",
      "73 of 650\n",
      "done\n",
      "74 of 650\n",
      "done\n",
      "75 of 650\n",
      "done\n",
      "76 of 650\n",
      "done\n",
      "77 of 650\n",
      "done\n",
      "78 of 650\n",
      "done\n",
      "79 of 650\n",
      "done\n",
      "80 of 650\n",
      "done\n",
      "81 of 650\n",
      "done\n",
      "82 of 650\n",
      "done\n",
      "83 of 650\n",
      "done\n",
      "84 of 650\n",
      "done\n",
      "85 of 650\n",
      "done\n",
      "86 of 650\n",
      "done\n",
      "87 of 650\n",
      "done\n",
      "88 of 650\n",
      "done\n",
      "89 of 650\n",
      "done\n",
      "90 of 650\n",
      "done\n",
      "91 of 650\n",
      "done\n",
      "92 of 650\n",
      "done\n",
      "93 of 650\n",
      "done\n",
      "94 of 650\n",
      "done\n",
      "95 of 650\n",
      "done\n",
      "96 of 650\n",
      "done\n",
      "97 of 650\n",
      "done\n",
      "98 of 650\n",
      "done\n",
      "99 of 650\n",
      "done\n",
      "100 of 650\n",
      "done\n",
      "101 of 650\n",
      "done\n",
      "102 of 650\n",
      "done\n",
      "103 of 650\n",
      "done\n",
      "104 of 650\n",
      "done\n",
      "105 of 650\n",
      "done\n",
      "106 of 650\n",
      "done\n",
      "107 of 650\n",
      "done\n",
      "108 of 650\n",
      "done\n",
      "109 of 650\n",
      "done\n",
      "110 of 650\n",
      "done\n",
      "111 of 650\n",
      "done\n",
      "112 of 650\n",
      "done\n",
      "113 of 650\n",
      "done\n",
      "114 of 650\n",
      "done\n",
      "115 of 650\n",
      "done\n",
      "116 of 650\n",
      "done\n",
      "117 of 650\n",
      "done\n",
      "118 of 650\n",
      "done\n",
      "119 of 650\n",
      "done\n",
      "120 of 650\n",
      "done\n",
      "121 of 650\n",
      "done\n",
      "122 of 650\n",
      "done\n",
      "123 of 650\n",
      "done\n",
      "124 of 650\n",
      "done\n",
      "125 of 650\n",
      "done\n",
      "126 of 650\n",
      "done\n",
      "127 of 650\n",
      "done\n",
      "128 of 650\n",
      "done\n",
      "129 of 650\n",
      "done\n",
      "130 of 650\n",
      "done\n",
      "131 of 650\n",
      "done\n",
      "132 of 650\n",
      "done\n",
      "133 of 650\n",
      "done\n",
      "134 of 650\n",
      "done\n",
      "135 of 650\n",
      "done\n",
      "136 of 650\n",
      "done\n",
      "137 of 650\n",
      "done\n",
      "138 of 650\n",
      "done\n",
      "139 of 650\n",
      "done\n",
      "140 of 650\n",
      "done\n",
      "141 of 650\n",
      "done\n",
      "142 of 650\n",
      "done\n",
      "143 of 650\n",
      "done\n",
      "144 of 650\n",
      "done\n",
      "145 of 650\n",
      "done\n",
      "146 of 650\n",
      "done\n",
      "147 of 650\n",
      "done\n",
      "148 of 650\n",
      "done\n",
      "149 of 650\n",
      "done\n",
      "150 of 650\n",
      "done\n",
      "151 of 650\n",
      "done\n",
      "152 of 650\n",
      "done\n",
      "153 of 650\n",
      "done\n",
      "154 of 650\n",
      "done\n",
      "155 of 650\n",
      "done\n",
      "156 of 650\n",
      "done\n",
      "157 of 650\n",
      "done\n",
      "158 of 650\n",
      "done\n",
      "159 of 650\n",
      "done\n",
      "160 of 650\n",
      "done\n",
      "161 of 650\n",
      "done\n",
      "162 of 650\n",
      "done\n",
      "163 of 650\n",
      "done\n",
      "164 of 650\n",
      "done\n",
      "165 of 650\n",
      "done\n",
      "166 of 650\n",
      "done\n",
      "167 of 650\n",
      "done\n",
      "168 of 650\n",
      "done\n",
      "169 of 650\n",
      "done\n",
      "170 of 650\n",
      "done\n",
      "171 of 650\n",
      "done\n",
      "172 of 650\n",
      "done\n",
      "173 of 650\n",
      "done\n",
      "174 of 650\n",
      "done\n",
      "175 of 650\n",
      "done\n",
      "176 of 650\n",
      "done\n",
      "177 of 650\n",
      "done\n",
      "178 of 650\n",
      "done\n",
      "179 of 650\n",
      "done\n",
      "180 of 650\n",
      "done\n",
      "181 of 650\n",
      "done\n",
      "182 of 650\n",
      "done\n",
      "183 of 650\n",
      "done\n",
      "184 of 650\n",
      "done\n",
      "185 of 650\n",
      "done\n",
      "186 of 650\n",
      "done\n",
      "187 of 650\n",
      "done\n",
      "188 of 650\n",
      "done\n",
      "189 of 650\n",
      "done\n",
      "190 of 650\n",
      "done\n",
      "191 of 650\n",
      "done\n",
      "192 of 650\n",
      "done\n",
      "193 of 650\n",
      "done\n",
      "194 of 650\n",
      "done\n",
      "195 of 650\n",
      "done\n",
      "196 of 650\n",
      "done\n",
      "197 of 650\n",
      "done\n",
      "198 of 650\n",
      "done\n",
      "199 of 650\n",
      "done\n",
      "200 of 650\n",
      "done\n",
      "201 of 650\n",
      "done\n",
      "202 of 650\n",
      "done\n",
      "203 of 650\n",
      "done\n",
      "204 of 650\n",
      "done\n",
      "205 of 650\n",
      "done\n",
      "206 of 650\n",
      "done\n",
      "207 of 650\n",
      "done\n",
      "208 of 650\n",
      "done\n",
      "209 of 650\n",
      "done\n",
      "210 of 650\n",
      "done\n",
      "211 of 650\n",
      "done\n",
      "212 of 650\n",
      "done\n",
      "213 of 650\n",
      "done\n",
      "214 of 650\n",
      "done\n",
      "215 of 650\n",
      "done\n",
      "216 of 650\n",
      "done\n",
      "217 of 650\n",
      "done\n",
      "218 of 650\n",
      "done\n",
      "219 of 650\n",
      "done\n",
      "220 of 650\n",
      "done\n",
      "221 of 650\n",
      "done\n",
      "222 of 650\n",
      "done\n",
      "223 of 650\n",
      "done\n",
      "224 of 650\n",
      "done\n",
      "225 of 650\n",
      "done\n",
      "226 of 650\n",
      "done\n",
      "227 of 650\n",
      "done\n",
      "228 of 650\n",
      "done\n",
      "229 of 650\n",
      "done\n",
      "230 of 650\n",
      "done\n",
      "231 of 650\n",
      "done\n",
      "232 of 650\n",
      "done\n",
      "233 of 650\n",
      "done\n",
      "234 of 650\n",
      "done\n",
      "235 of 650\n",
      "done\n",
      "236 of 650\n",
      "done\n",
      "237 of 650\n",
      "done\n",
      "238 of 650\n",
      "done\n",
      "239 of 650\n",
      "done\n",
      "240 of 650\n",
      "done\n",
      "241 of 650\n",
      "done\n",
      "242 of 650\n",
      "done\n",
      "243 of 650\n",
      "done\n",
      "244 of 650\n",
      "done\n",
      "245 of 650\n",
      "done\n",
      "246 of 650\n",
      "done\n",
      "247 of 650\n",
      "done\n",
      "248 of 650\n",
      "done\n",
      "249 of 650\n",
      "done\n",
      "250 of 650\n",
      "done\n",
      "251 of 650\n",
      "done\n",
      "252 of 650\n",
      "done\n",
      "253 of 650\n",
      "done\n",
      "254 of 650\n",
      "done\n",
      "255 of 650\n",
      "done\n",
      "256 of 650\n",
      "done\n",
      "257 of 650\n",
      "done\n",
      "258 of 650\n",
      "done\n",
      "259 of 650\n",
      "done\n",
      "260 of 650\n",
      "done\n",
      "261 of 650\n",
      "done\n",
      "262 of 650\n",
      "done\n",
      "263 of 650\n",
      "done\n",
      "264 of 650\n",
      "done\n",
      "265 of 650\n",
      "done\n",
      "266 of 650\n",
      "done\n",
      "267 of 650\n",
      "done\n",
      "268 of 650\n",
      "done\n",
      "269 of 650\n",
      "done\n",
      "270 of 650\n",
      "done\n",
      "271 of 650\n",
      "done\n",
      "272 of 650\n",
      "done\n",
      "273 of 650\n",
      "done\n",
      "274 of 650\n",
      "done\n",
      "275 of 650\n",
      "done\n",
      "276 of 650\n",
      "done\n",
      "277 of 650\n",
      "done\n",
      "278 of 650\n",
      "done\n",
      "279 of 650\n",
      "done\n",
      "280 of 650\n",
      "done\n",
      "281 of 650\n",
      "done\n",
      "282 of 650\n",
      "done\n",
      "283 of 650\n",
      "done\n",
      "284 of 650\n",
      "done\n",
      "285 of 650\n",
      "done\n",
      "286 of 650\n",
      "done\n",
      "287 of 650\n",
      "done\n",
      "288 of 650\n",
      "done\n",
      "289 of 650\n",
      "done\n",
      "290 of 650\n",
      "done\n",
      "291 of 650\n",
      "done\n",
      "292 of 650\n",
      "done\n",
      "293 of 650\n",
      "done\n",
      "294 of 650\n",
      "done\n",
      "295 of 650\n",
      "done\n",
      "296 of 650\n",
      "done\n",
      "297 of 650\n",
      "done\n",
      "298 of 650\n",
      "done\n",
      "299 of 650\n",
      "done\n",
      "300 of 650\n",
      "done\n",
      "301 of 650\n",
      "done\n",
      "302 of 650\n",
      "done\n",
      "303 of 650\n",
      "done\n",
      "304 of 650\n",
      "done\n",
      "305 of 650\n",
      "done\n",
      "306 of 650\n",
      "done\n",
      "307 of 650\n",
      "done\n",
      "308 of 650\n",
      "done\n",
      "309 of 650\n",
      "done\n",
      "310 of 650\n",
      "done\n",
      "311 of 650\n",
      "done\n",
      "312 of 650\n",
      "done\n",
      "313 of 650\n",
      "done\n",
      "314 of 650\n",
      "done\n",
      "315 of 650\n",
      "done\n",
      "316 of 650\n",
      "done\n",
      "317 of 650\n",
      "done\n",
      "318 of 650\n",
      "done\n",
      "319 of 650\n",
      "done\n",
      "320 of 650\n",
      "done\n",
      "321 of 650\n",
      "done\n",
      "322 of 650\n",
      "done\n",
      "323 of 650\n",
      "done\n",
      "324 of 650\n",
      "done\n",
      "325 of 650\n",
      "done\n",
      "326 of 650\n",
      "done\n",
      "327 of 650\n",
      "done\n",
      "328 of 650\n",
      "done\n",
      "329 of 650\n",
      "done\n",
      "330 of 650\n",
      "done\n",
      "331 of 650\n",
      "done\n",
      "332 of 650\n",
      "done\n",
      "333 of 650\n",
      "done\n",
      "334 of 650\n",
      "done\n",
      "335 of 650\n",
      "done\n",
      "336 of 650\n",
      "done\n",
      "337 of 650\n",
      "done\n",
      "338 of 650\n",
      "done\n",
      "339 of 650\n",
      "done\n",
      "340 of 650\n",
      "done\n",
      "341 of 650\n",
      "done\n",
      "342 of 650\n",
      "done\n",
      "343 of 650\n",
      "done\n",
      "344 of 650\n",
      "done\n",
      "345 of 650\n",
      "done\n",
      "346 of 650\n",
      "done\n",
      "347 of 650\n",
      "done\n",
      "348 of 650\n",
      "done\n",
      "349 of 650\n",
      "done\n",
      "350 of 650\n",
      "done\n",
      "351 of 650\n",
      "done\n",
      "352 of 650\n",
      "done\n",
      "353 of 650\n",
      "done\n",
      "354 of 650\n",
      "done\n",
      "355 of 650\n",
      "done\n",
      "356 of 650\n",
      "done\n",
      "357 of 650\n",
      "done\n",
      "358 of 650\n",
      "done\n",
      "359 of 650\n",
      "done\n",
      "360 of 650\n",
      "done\n",
      "361 of 650\n",
      "done\n",
      "362 of 650\n",
      "done\n",
      "363 of 650\n",
      "done\n",
      "364 of 650\n",
      "done\n",
      "365 of 650\n",
      "done\n",
      "366 of 650\n",
      "done\n",
      "367 of 650\n",
      "done\n",
      "368 of 650\n",
      "done\n",
      "369 of 650\n",
      "done\n",
      "370 of 650\n",
      "done\n",
      "371 of 650\n",
      "done\n",
      "372 of 650\n",
      "done\n",
      "373 of 650\n",
      "done\n",
      "374 of 650\n",
      "done\n",
      "375 of 650\n",
      "done\n",
      "376 of 650\n",
      "done\n",
      "377 of 650\n",
      "done\n",
      "378 of 650\n",
      "done\n",
      "379 of 650\n",
      "done\n",
      "380 of 650\n",
      "done\n",
      "381 of 650\n",
      "done\n",
      "382 of 650\n",
      "done\n",
      "383 of 650\n",
      "done\n",
      "384 of 650\n",
      "done\n",
      "385 of 650\n",
      "done\n",
      "386 of 650\n",
      "done\n",
      "387 of 650\n",
      "done\n",
      "388 of 650\n",
      "done\n",
      "389 of 650\n",
      "done\n",
      "390 of 650\n",
      "done\n",
      "391 of 650\n",
      "done\n",
      "392 of 650\n",
      "done\n",
      "393 of 650\n",
      "done\n",
      "394 of 650\n",
      "done\n",
      "395 of 650\n",
      "done\n",
      "396 of 650\n",
      "done\n",
      "397 of 650\n",
      "done\n",
      "398 of 650\n",
      "done\n",
      "399 of 650\n",
      "done\n",
      "400 of 650\n",
      "done\n",
      "401 of 650\n",
      "done\n",
      "402 of 650\n",
      "done\n",
      "403 of 650\n",
      "done\n",
      "404 of 650\n",
      "done\n",
      "405 of 650\n",
      "done\n",
      "406 of 650\n",
      "done\n",
      "407 of 650\n",
      "done\n",
      "408 of 650\n",
      "done\n",
      "409 of 650\n",
      "done\n",
      "410 of 650\n",
      "done\n",
      "411 of 650\n",
      "done\n",
      "412 of 650\n",
      "done\n",
      "413 of 650\n",
      "done\n",
      "414 of 650\n",
      "done\n",
      "415 of 650\n",
      "done\n",
      "416 of 650\n",
      "done\n",
      "417 of 650\n",
      "done\n",
      "418 of 650\n",
      "done\n",
      "419 of 650\n",
      "done\n",
      "420 of 650\n",
      "done\n",
      "421 of 650\n",
      "done\n",
      "422 of 650\n",
      "done\n",
      "423 of 650\n",
      "done\n",
      "424 of 650\n",
      "done\n",
      "425 of 650\n",
      "done\n",
      "426 of 650\n",
      "done\n",
      "427 of 650\n",
      "done\n",
      "428 of 650\n",
      "done\n",
      "429 of 650\n",
      "done\n",
      "430 of 650\n",
      "done\n",
      "431 of 650\n",
      "done\n",
      "432 of 650\n",
      "done\n",
      "433 of 650\n",
      "done\n",
      "434 of 650\n",
      "done\n",
      "435 of 650\n",
      "done\n",
      "436 of 650\n",
      "done\n",
      "437 of 650\n",
      "done\n",
      "438 of 650\n",
      "done\n",
      "439 of 650\n",
      "done\n",
      "440 of 650\n",
      "done\n",
      "441 of 650\n",
      "done\n",
      "442 of 650\n",
      "done\n",
      "443 of 650\n",
      "done\n",
      "444 of 650\n",
      "done\n",
      "445 of 650\n",
      "done\n",
      "446 of 650\n",
      "done\n",
      "447 of 650\n",
      "done\n",
      "448 of 650\n",
      "done\n",
      "449 of 650\n",
      "done\n",
      "450 of 650\n",
      "done\n",
      "451 of 650\n",
      "done\n",
      "452 of 650\n",
      "done\n",
      "453 of 650\n",
      "done\n",
      "454 of 650\n",
      "done\n",
      "455 of 650\n",
      "done\n",
      "456 of 650\n",
      "done\n",
      "457 of 650\n",
      "done\n",
      "458 of 650\n",
      "done\n",
      "459 of 650\n",
      "done\n",
      "460 of 650\n",
      "done\n",
      "461 of 650\n",
      "done\n",
      "462 of 650\n",
      "done\n",
      "463 of 650\n",
      "done\n",
      "464 of 650\n",
      "done\n",
      "465 of 650\n",
      "done\n",
      "466 of 650\n",
      "done\n",
      "467 of 650\n",
      "done\n",
      "468 of 650\n",
      "done\n",
      "469 of 650\n",
      "done\n",
      "470 of 650\n",
      "done\n",
      "471 of 650\n",
      "done\n",
      "472 of 650\n",
      "done\n",
      "473 of 650\n",
      "done\n",
      "474 of 650\n",
      "done\n",
      "475 of 650\n",
      "done\n",
      "476 of 650\n",
      "done\n",
      "477 of 650\n",
      "done\n",
      "478 of 650\n",
      "done\n",
      "479 of 650\n",
      "done\n",
      "480 of 650\n",
      "done\n",
      "481 of 650\n",
      "done\n",
      "482 of 650\n",
      "done\n",
      "483 of 650\n",
      "done\n",
      "484 of 650\n",
      "done\n",
      "485 of 650\n",
      "done\n",
      "486 of 650\n",
      "done\n",
      "487 of 650\n",
      "done\n",
      "488 of 650\n",
      "done\n",
      "489 of 650\n",
      "done\n",
      "490 of 650\n",
      "done\n",
      "491 of 650\n",
      "done\n",
      "492 of 650\n",
      "done\n",
      "493 of 650\n",
      "done\n",
      "494 of 650\n",
      "done\n",
      "495 of 650\n",
      "done\n",
      "496 of 650\n",
      "done\n",
      "497 of 650\n",
      "done\n",
      "498 of 650\n",
      "done\n",
      "499 of 650\n",
      "done\n",
      "500 of 650\n",
      "done\n",
      "501 of 650\n",
      "done\n",
      "502 of 650\n",
      "done\n",
      "503 of 650\n",
      "done\n",
      "504 of 650\n",
      "done\n",
      "505 of 650\n",
      "done\n",
      "506 of 650\n",
      "done\n",
      "507 of 650\n",
      "done\n",
      "508 of 650\n",
      "done\n",
      "509 of 650\n",
      "done\n",
      "510 of 650\n",
      "done\n",
      "511 of 650\n",
      "done\n",
      "512 of 650\n",
      "done\n",
      "513 of 650\n",
      "done\n",
      "514 of 650\n",
      "done\n",
      "515 of 650\n",
      "done\n",
      "516 of 650\n",
      "done\n",
      "517 of 650\n",
      "done\n",
      "518 of 650\n",
      "done\n",
      "519 of 650\n",
      "done\n",
      "520 of 650\n",
      "done\n",
      "521 of 650\n",
      "done\n",
      "522 of 650\n",
      "done\n",
      "523 of 650\n",
      "done\n",
      "524 of 650\n",
      "done\n",
      "525 of 650\n",
      "done\n",
      "526 of 650\n",
      "done\n",
      "527 of 650\n",
      "done\n",
      "528 of 650\n",
      "done\n",
      "529 of 650\n",
      "done\n",
      "530 of 650\n",
      "done\n",
      "531 of 650\n",
      "done\n",
      "532 of 650\n",
      "done\n",
      "533 of 650\n",
      "done\n",
      "534 of 650\n",
      "done\n",
      "535 of 650\n",
      "done\n",
      "536 of 650\n",
      "done\n",
      "537 of 650\n",
      "done\n",
      "538 of 650\n",
      "done\n",
      "539 of 650\n",
      "done\n",
      "540 of 650\n",
      "done\n",
      "541 of 650\n",
      "done\n",
      "542 of 650\n",
      "done\n",
      "543 of 650\n",
      "done\n",
      "544 of 650\n",
      "done\n",
      "545 of 650\n",
      "done\n",
      "546 of 650\n",
      "done\n",
      "547 of 650\n",
      "done\n",
      "548 of 650\n",
      "done\n",
      "549 of 650\n",
      "done\n",
      "550 of 650\n",
      "done\n",
      "551 of 650\n",
      "done\n",
      "552 of 650\n",
      "done\n",
      "553 of 650\n",
      "done\n",
      "554 of 650\n",
      "done\n",
      "555 of 650\n",
      "done\n",
      "556 of 650\n",
      "done\n",
      "557 of 650\n",
      "done\n",
      "558 of 650\n",
      "done\n",
      "559 of 650\n",
      "done\n",
      "560 of 650\n",
      "done\n",
      "561 of 650\n",
      "done\n",
      "562 of 650\n",
      "done\n",
      "563 of 650\n",
      "done\n",
      "564 of 650\n",
      "done\n",
      "565 of 650\n",
      "done\n",
      "566 of 650\n",
      "done\n",
      "567 of 650\n",
      "done\n",
      "568 of 650\n",
      "done\n",
      "569 of 650\n",
      "done\n",
      "570 of 650\n",
      "done\n",
      "571 of 650\n",
      "done\n",
      "572 of 650\n",
      "done\n",
      "573 of 650\n",
      "done\n",
      "574 of 650\n",
      "done\n",
      "575 of 650\n",
      "done\n",
      "576 of 650\n",
      "done\n",
      "577 of 650\n",
      "done\n",
      "578 of 650\n",
      "done\n",
      "579 of 650\n",
      "done\n",
      "580 of 650\n",
      "done\n",
      "581 of 650\n",
      "done\n",
      "582 of 650\n",
      "done\n",
      "583 of 650\n",
      "done\n",
      "584 of 650\n",
      "done\n",
      "585 of 650\n",
      "done\n",
      "586 of 650\n",
      "done\n",
      "587 of 650\n",
      "done\n",
      "588 of 650\n",
      "done\n",
      "589 of 650\n",
      "done\n",
      "590 of 650\n",
      "done\n",
      "591 of 650\n",
      "done\n",
      "592 of 650\n",
      "done\n",
      "593 of 650\n",
      "done\n",
      "594 of 650\n",
      "done\n",
      "595 of 650\n",
      "done\n",
      "596 of 650\n",
      "done\n",
      "597 of 650\n",
      "done\n",
      "598 of 650\n",
      "done\n",
      "599 of 650\n",
      "done\n",
      "600 of 650\n",
      "done\n",
      "601 of 650\n",
      "done\n",
      "602 of 650\n",
      "done\n",
      "603 of 650\n",
      "done\n",
      "604 of 650\n",
      "done\n",
      "605 of 650\n",
      "done\n",
      "606 of 650\n",
      "done\n",
      "607 of 650\n",
      "done\n",
      "608 of 650\n",
      "done\n",
      "609 of 650\n",
      "done\n",
      "610 of 650\n",
      "done\n",
      "611 of 650\n",
      "done\n",
      "612 of 650\n",
      "done\n",
      "613 of 650\n",
      "done\n",
      "614 of 650\n",
      "done\n",
      "615 of 650\n",
      "done\n",
      "616 of 650\n",
      "done\n",
      "617 of 650\n",
      "done\n",
      "618 of 650\n",
      "done\n",
      "619 of 650\n",
      "done\n",
      "620 of 650\n",
      "done\n",
      "621 of 650\n",
      "done\n",
      "622 of 650\n",
      "done\n",
      "623 of 650\n",
      "done\n",
      "624 of 650\n",
      "done\n",
      "625 of 650\n",
      "done\n",
      "626 of 650\n",
      "done\n",
      "627 of 650\n",
      "done\n",
      "628 of 650\n",
      "done\n",
      "629 of 650\n",
      "done\n",
      "630 of 650\n",
      "done\n",
      "631 of 650\n",
      "done\n",
      "632 of 650\n",
      "done\n",
      "633 of 650\n",
      "done\n",
      "634 of 650\n",
      "done\n",
      "635 of 650\n",
      "done\n",
      "636 of 650\n",
      "done\n",
      "637 of 650\n",
      "done\n",
      "638 of 650\n",
      "done\n",
      "639 of 650\n",
      "done\n",
      "640 of 650\n",
      "done\n",
      "641 of 650\n",
      "done\n",
      "642 of 650\n",
      "done\n",
      "643 of 650\n",
      "done\n",
      "644 of 650\n",
      "done\n",
      "645 of 650\n",
      "done\n",
      "646 of 650\n",
      "done\n",
      "647 of 650\n",
      "done\n",
      "648 of 650\n",
      "done\n",
      "649 of 650\n",
      "done\n",
      "Current memory usage is 0.254966MB; Peak was 0.265846MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>transcripts</th>\n",
       "      <th>classification</th>\n",
       "      <th>noPersonalQ</th>\n",
       "      <th>personalQ</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_masks</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00_hc_0_0_0.flac</td>\n",
       "      <td>Yeah, I'm in London.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(101), tensor(3398), tensor(1010), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>[0.32835236, -0.010593282, 0.32343817, -0.1283...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00_hc_0_0_0.flac</td>\n",
       "      <td>You can go to Oxford Street, which is famous f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(101), tensor(2017), tensor(2064), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>[0.23485234, -0.93995064, 0.49484923, 0.388636...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00_hc_0_0_0.flac</td>\n",
       "      <td>And the Selfridge is there and a lot of touris...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(101), tensor(1998), tensor(1996), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>[0.58746594, -0.122157216, 0.3925981, -0.27175...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00_hc_0_0_0.flac</td>\n",
       "      <td>So it's a good place to see me come to London ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(101), tensor(2061), tensor(2009), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>[0.120439835, -0.10013776, 0.6384494, -0.02844...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00_hc_0_0_0.flac</td>\n",
       "      <td>That's the way the royal family lives.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[tensor(101), tensor(2008), tensor(1005), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>[0.2735068, -0.24023503, 0.20387809, 0.1197098...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                        transcripts   \n",
       "0  ID00_hc_0_0_0.flac                               Yeah, I'm in London.  \\\n",
       "1  ID00_hc_0_0_0.flac  You can go to Oxford Street, which is famous f...   \n",
       "2  ID00_hc_0_0_0.flac  And the Selfridge is there and a lot of touris...   \n",
       "3  ID00_hc_0_0_0.flac  So it's a good place to see me come to London ...   \n",
       "4  ID00_hc_0_0_0.flac             That's the way the royal family lives.   \n",
       "\n",
       "   classification  noPersonalQ  personalQ   \n",
       "0               0            0          0  \\\n",
       "1               0            0          0   \n",
       "2               0            0          0   \n",
       "3               0            0          0   \n",
       "4               0            0          0   \n",
       "\n",
       "                                           input_ids   \n",
       "0  [[tensor(101), tensor(3398), tensor(1010), ten...  \\\n",
       "1  [[tensor(101), tensor(2017), tensor(2064), ten...   \n",
       "2  [[tensor(101), tensor(1998), tensor(1996), ten...   \n",
       "3  [[tensor(101), tensor(2061), tensor(2009), ten...   \n",
       "4  [[tensor(101), tensor(2008), tensor(1005), ten...   \n",
       "\n",
       "                                     attention_masks   \n",
       "0  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \\\n",
       "1  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "2  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "3  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "4  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.32835236, -0.010593282, 0.32343817, -0.1283...  \n",
       "1  [0.23485234, -0.93995064, 0.49484923, 0.388636...  \n",
       "2  [0.58746594, -0.122157216, 0.3925981, -0.27175...  \n",
       "3  [0.120439835, -0.10013776, 0.6384494, -0.02844...  \n",
       "4  [0.2735068, -0.24023503, 0.20387809, 0.1197098...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embeddings_google = collect_embeddings(\"spontaneousDialogueOnly_google\",True,90)\n",
    "df_embeddings_google.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
