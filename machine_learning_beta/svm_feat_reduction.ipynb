{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate modle code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def weird_division(n, d):\n",
    "    return n / d if d else 0\n",
    "\n",
    "\n",
    "def validate_model(model, X, Y, fold):\n",
    "    \"\"\"\n",
    "    validates the model with a k-fold validation which is iterated\n",
    "    returns the mean accuracy, specificiy, recall, precision, f1 score and auc score\n",
    "    \"\"\"\n",
    "\n",
    "    splits = 5\n",
    "    iteration = 10\n",
    "\n",
    "    acc_list = []\n",
    "    specificity_list = []\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    if fold == \"Strat\":\n",
    "        folds = StratifiedKFold(n_splits=splits)\n",
    "    elif fold == \"K\":\n",
    "        folds = KFold(splits, shuffle=True)\n",
    "\n",
    "    # Iterate \"interation\" times of k-fold\n",
    "    for i in range(1, iteration):\n",
    "        # print(f'Iteration {i}/{iteration}')\n",
    "\n",
    "        acc_total = 0\n",
    "        specificity_total = 0\n",
    "        recall_total = 0\n",
    "        precision_total = 0\n",
    "        f1_total = 0\n",
    "\n",
    "        for train_index, test_index in folds.split(X, Y):\n",
    "            x_train = X.iloc[train_index, :]\n",
    "            x_test = X.iloc[test_index, :]\n",
    "            y_train = Y.iloc[train_index, :]\n",
    "            y_test = Y.iloc[test_index, :]\n",
    "\n",
    "            # scale\n",
    "            sc = MinMaxScaler()\n",
    "            x_train = sc.fit_transform(x_train)\n",
    "            x_test = sc.transform(x_test)\n",
    "\n",
    "            # fit model and predict\n",
    "            model.fit(x_train, np.ravel(y_train))\n",
    "            y_pred = model.predict(x_test)\n",
    "\n",
    "            conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "            TN = conf_matrix[0][0]\n",
    "            FP = conf_matrix[0][1]\n",
    "            FN = conf_matrix[1][0]\n",
    "            TP = conf_matrix[1][1]\n",
    "\n",
    "            accuracy = (weird_division((TP + TN), (TP + TN + FP + FN))) * 100\n",
    "            recall = weird_division(TP, (TP + FN)) * 100  # recall\n",
    "            specificity = weird_division(TN, (TN + FP)) * 100\n",
    "            precision = weird_division(TP, (TP + FP)) * 100\n",
    "            f1_score = weird_division(2 * (recall * precision), (recall + precision))\n",
    "\n",
    "            # sum it up\n",
    "            acc_total += accuracy\n",
    "            recall_total += recall\n",
    "            specificity_total += specificity\n",
    "            precision_total += precision\n",
    "            f1_total += f1_score\n",
    "\n",
    "        # avg\n",
    "        accuracy_mean = acc_total / splits\n",
    "        recall_mean = recall_total / splits\n",
    "        specificity_mean = specificity_total / splits\n",
    "        precision_mean = precision_total / splits\n",
    "        f1_mean = f1_total / splits\n",
    "\n",
    "        acc_list.append(accuracy_mean)\n",
    "        recall_list.append(recall_mean)\n",
    "        specificity_list.append(specificity_mean)\n",
    "        precision_list.append(precision_mean)\n",
    "        f1_list.append(f1_mean)\n",
    "\n",
    "    # print(\"Accuracy for the 10 iterations: \",  acc_list) #mean accuracy acros the 6 folds for each iteration\n",
    "    # print(\"Recall for the 10 iterations: \",  recall_list) #mean accuracy acros the 6 folds for each iteration\n",
    "    # print(\"Specificity for the 10 iterations: \",  specificity_list)\n",
    "    # print(\"Precision for the 10 iterations: \",  precision_list)\n",
    "    # print(\"F1  score for the 10 iterations: \",  f1_list)\n",
    "\n",
    "    return (\n",
    "        np.mean(acc_list),\n",
    "        np.mean(specificity_list),\n",
    "        np.mean(recall_list),\n",
    "        np.mean(precision_list),\n",
    "        np.mean(f1_list),\n",
    "        # np.mean(auc_list),\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate modle code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_train, x_test, y_train, y_test):\n",
    "    sc = MinMaxScaler()\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.transform(x_test)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    TN = conf_matrix[0][0]\n",
    "    FP = conf_matrix[0][1]\n",
    "    FN = conf_matrix[1][0]\n",
    "    TP = conf_matrix[1][1]\n",
    "\n",
    "    accuracy = ((TP + TN) / (TP + TN + FP + FN)) * 100\n",
    "    recall = (TP / (TP + FN)) * 100  # recall\n",
    "    specificity = (TN / (TN + FP)) * 100\n",
    "    precision = (TP / (TP + FP)) * 100\n",
    "    f1_score = 2 * (recall * precision) / (recall + precision)\n",
    "\n",
    "    return accuracy, recall, specificity, precision, f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from feature_reduction import feature_reduction_lda, feature_reduction_mrmr\n",
    "from imblearn.over_sampling import SMOTE\n",
    "path = '/Users/athena.kam/Documents/Thesis/codebase/thesis-2023-athena'\n",
    "os.chdir(path)\n",
    "\n",
    "CV_SPLIT = 5\n",
    "\n",
    "def get_best_param(x_train,y_train):\n",
    "    param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "    grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=0,return_train_score=True,cv = CV_SPLIT)\n",
    "    #print(grid.cv_results_)\n",
    "    grid.fit(x_train,y_train)\n",
    "    print(grid.best_estimator_.get_params())\n",
    "    return grid\n",
    "\n",
    "def train_test_SVC(filename:str,hold_out:bool,include_personal_q:bool, grid_search:bool,reduce:bool,over_sample:bool = False,model_weights:dict = {},random_state:int = 0):\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    if include_personal_q:\n",
    "        df = df[df['noPersonalQ']!=1].reset_index(drop=True)\n",
    "    else:\n",
    "        df = df[df['personalQ']!=1].reset_index(drop=True)\n",
    "    \n",
    "    headers = df.columns\n",
    "    non_embeddings_headers = []\n",
    "    \n",
    "    for header in headers:\n",
    "        if header.find('embbedings')<0:\n",
    "            non_embeddings_headers.append(header)\n",
    "\n",
    "    X = df.drop(columns=non_embeddings_headers)\n",
    "    Y = df['classification']\n",
    "\n",
    "    # Feature Reduction \n",
    "    if reduce:\n",
    "        #x_train = feature_reduction_pca(x_train,0.9).values\n",
    "        #X = feature_reduction_lda(X,Y)\n",
    "        X = feature_reduction_mrmr(X,Y,20)\n",
    "        \n",
    "    else:\n",
    "        x_val = X.values\n",
    "        X = StandardScaler().fit_transform(x_val)\n",
    "    \n",
    "    # Test Train split\n",
    "    if hold_out:\n",
    "        x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.20,random_state=random_state)\n",
    "\n",
    "        # Oversample on training set\n",
    "        if over_sample:\n",
    "            sm = SMOTE(random_state=12)\n",
    "            x_train,y_train = sm.fit_resample(x_train, y_train) \n",
    "    else:\n",
    "        x_train = X\n",
    "        y_train = Y\n",
    "\n",
    "\n",
    "    if grid_search: \n",
    "        grid = get_best_param(x_train=x_train,y_train=y_train) \n",
    "        model_svc = grid.best_estimator_\n",
    "    else:\n",
    "        model_svc = SVC(C = model_weights['C'],gamma=model_weights['gamma'],kernel=model_weights['kernel'])\n",
    "        \n",
    "    accuracy, specificiy, recall, precision, f1_score =validate_model(model_svc,pd.DataFrame(x_train),pd.DataFrame(y_train),\"Strat\")\n",
    "    print(f'\\tAverage Accuracy: {accuracy} \\n\\\n",
    "      Average Specificity: {specificiy} \\n\\\n",
    "      Average Recall: {recall}\\n\\\n",
    "      Average Precision:{precision}\\n\\\n",
    "      Average F1 score {f1_score}\\n\\\n",
    "      ')\n",
    "    \n",
    "    if hold_out:\n",
    "        accuracy, specificiy, recall, precision, f1_score =evaluate_model(model_svc,x_train,x_test,y_train,y_test)\n",
    "        print('____________________________________________')\n",
    "        print('Evaluate model')\n",
    "        print(f'\\tAccuracy: {accuracy} \\n\\\n",
    "        Specificity: {specificiy} \\n\\\n",
    "        Recall: {recall}\\n\\\n",
    "        Precision:{precision}\\n\\\n",
    "        F1 score {f1_score}\\n\\\n",
    "        ')\n",
    "        return accuracy, specificiy, recall, precision, f1_score\n",
    "    else: \n",
    "        return accuracy, specificiy, recall, precision, f1_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing different seeds (Hold out only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_SVC_TEST_avg_seeds(\n",
    "    filename: str,\n",
    "    hold_out: bool = True,\n",
    "    include_personal_q: bool = False,\n",
    "    grid_search: bool = True,\n",
    "    reduce: bool = True,\n",
    "    model_weights: dict = {},\n",
    "    over_sample: bool = False,\n",
    "):\n",
    "    random_states = [0, 5, 13, 27, 36, 42]\n",
    "    n_states = len(random_states)\n",
    "\n",
    "    acc_list = []\n",
    "    specificity_list = []\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    for random_state in random_states:\n",
    "        print(f\"Random State: {random_state}\")\n",
    "        accuracy, specificiy, recall, precision, f1_score = train_test_SVC(\n",
    "            filename=filename,\n",
    "            hold_out=hold_out,\n",
    "            include_personal_q=include_personal_q,\n",
    "            grid_search=grid_search,\n",
    "            reduce=reduce,\n",
    "            model_weights=model_weights,\n",
    "            random_state=random_state,\n",
    "            over_sample=over_sample\n",
    "        )\n",
    "        acc_list.append(accuracy)\n",
    "        specificity_list.append(specificiy)\n",
    "        recall_list.append(recall)\n",
    "        precision_list.append(precision)\n",
    "        f1_list.append(f1_score)\n",
    "\n",
    "    accuracy_mean = np.mean(acc_list)\n",
    "    recall_mean = np.mean(recall_list)\n",
    "    specificity_mean = np.mean(specificity_list)\n",
    "    precision_mean = np.mean(precision_list)\n",
    "    f1_mean = np.mean(f1_list)\n",
    "\n",
    "    print(\n",
    "        \"Accuracy list: \", acc_list\n",
    "    )  # mean accuracy acros the 6 folds for each iteration\n",
    "    print(\n",
    "        \"Recall list: \", recall_list\n",
    "    )  # mean accuracy acros the 6 folds for each iteration\n",
    "    print(\"Specificity list: \", specificity_list)\n",
    "    print(\"Precision list: \", precision_list)\n",
    "    print(\"F1  score list: \", f1_list)\n",
    "\n",
    "    print(\n",
    "        f\"\\tAverage Accuracy: {accuracy_mean} \\n\\\n",
    "      Average Specificity: {recall_mean} \\n\\\n",
    "      Average Recall: {specificity_mean}\\n\\\n",
    "      Average Precision:{precision_mean}\\n\\\n",
    "      Average F1 score {f1_mean}\\n\\\n",
    "      \"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  8.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 1, 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\tAverage Accuracy: 81.07142857142858 \n",
      "      Average Specificity: 86.0 \n",
      "      Average Recall: 73.33333333333333\n",
      "      Average Precision:61.666666666666664\n",
      "      Average F1 score 66.47619047619047\n",
      "      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(81.07142857142858,\n",
       " 86.0,\n",
       " 73.33333333333333,\n",
       " 61.666666666666664,\n",
       " 66.47619047619047)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_SVC('datasets/transformed/spontaneousDialogueOnly_google_bert_embeddings_transformed.csv',False,False,True,reduce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:03<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 1, 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\tAverage Accuracy: 97.14285714285714 \n",
      "      Average Specificity: 100.0 \n",
      "      Average Recall: 95.0\n",
      "      Average Precision:100.0\n",
      "      Average F1 score 97.14285714285714\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 75.0 \n",
      "        Specificity: 66.66666666666666 \n",
      "        Recall: 80.0\n",
      "        Precision:66.66666666666666\n",
      "        F1 score 66.66666666666666\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(75.0, 66.66666666666666, 80.0, 66.66666666666666, 66.66666666666666)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_SVC('datasets/transformed/spontaneousDialogueOnly_google_bert_embeddings_transformed.csv', hold_out=True,include_personal_q=False,grid_search=True,reduce=True,over_sample=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV score is none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  9.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 1, 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\tAverage Accuracy: 97.14285714285714 \n",
      "      Average Specificity: 100.0 \n",
      "      Average Recall: 95.0\n",
      "      Average Precision:100.0\n",
      "      Average F1 score 97.14285714285714\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 75.0 \n",
      "        Specificity: 66.66666666666666 \n",
      "        Recall: 80.0\n",
      "        Precision:66.66666666666666\n",
      "        F1 score 66.66666666666666\n",
      "        \n",
      "Random State: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 1, 'kernel': 'poly', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\tAverage Accuracy: 81.42857142857142 \n",
      "      Average Specificity: 65.0 \n",
      "      Average Recall: 100.0\n",
      "      Average Precision:77.0\n",
      "      Average F1 score 85.47619047619048\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 100.0 \n",
      "        Specificity: 100.0 \n",
      "        Recall: 100.0\n",
      "        Precision:100.0\n",
      "        F1 score 100.0\n",
      "        \n",
      "Random State: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\tAverage Accuracy: 90.55555555555556 \n",
      "      Average Specificity: 86.0 \n",
      "      Average Recall: 95.0\n",
      "      Average Precision:88.33333333333333\n",
      "      Average F1 score 91.0\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 75.0 \n",
      "        Specificity: 71.42857142857143 \n",
      "        Recall: 100.0\n",
      "        Precision:100.0\n",
      "        F1 score 83.33333333333333\n",
      "        \n",
      "Random State: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  9.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 0.1, 'kernel': 'sigmoid', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\tAverage Accuracy: 93.33333333333334 \n",
      "      Average Specificity: 86.66666666666666 \n",
      "      Average Recall: 100.0\n",
      "      Average Precision:90.0\n",
      "      Average F1 score 94.28571428571429\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 100.0 \n",
      "        Specificity: 100.0 \n",
      "        Recall: 100.0\n",
      "        Precision:100.0\n",
      "        F1 score 100.0\n",
      "        \n",
      "Random State: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 10.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 0.1, 'kernel': 'sigmoid', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\tAverage Accuracy: 97.14285714285714 \n",
      "      Average Specificity: 95.0 \n",
      "      Average Recall: 100.0\n",
      "      Average Precision:95.0\n",
      "      Average F1 score 97.14285714285714\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 62.5 \n",
      "        Specificity: 33.33333333333333 \n",
      "        Recall: 80.0\n",
      "        Precision:50.0\n",
      "        F1 score 40.0\n",
      "        \n",
      "Random State: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 10.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 1, 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\tAverage Accuracy: 76.66666666666666 \n",
      "      Average Specificity: 79.99999999999999 \n",
      "      Average Recall: 73.33333333333333\n",
      "      Average Precision:85.33333333333333\n",
      "      Average F1 score 74.33333333333333\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 87.5 \n",
      "        Specificity: 100.0 \n",
      "        Recall: 85.71428571428571\n",
      "        Precision:50.0\n",
      "        F1 score 66.66666666666667\n",
      "        \n",
      "Accuracy list:  [75.0, 100.0, 75.0, 100.0, 62.5, 87.5]\n",
      "Recall list:  [80.0, 100.0, 100.0, 100.0, 80.0, 85.71428571428571]\n",
      "Specificity list:  [66.66666666666666, 100.0, 71.42857142857143, 100.0, 33.33333333333333, 100.0]\n",
      "Precision list:  [66.66666666666666, 100.0, 100.0, 100.0, 50.0, 50.0]\n",
      "F1  score list:  [66.66666666666666, 100.0, 83.33333333333333, 100.0, 40.0, 66.66666666666667]\n",
      "\tAverage Accuracy: 83.33333333333333 \n",
      "      Average Specificity: 90.95238095238095 \n",
      "      Average Recall: 78.57142857142857\n",
      "      Average Precision:77.77777777777777\n",
      "      Average F1 score 76.11111111111111\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "train_test_SVC_TEST_avg_seeds('datasets/transformed/spontaneousDialogueOnly_google_bert_embeddings_transformed.csv',over_sample=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV F1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 1, 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\tAverage Accuracy: 97.14285714285714 \n",
      "      Average Specificity: 100.0 \n",
      "      Average Recall: 95.0\n",
      "      Average Precision:100.0\n",
      "      Average F1 score 97.14285714285714\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 75.0 \n",
      "        Specificity: 66.66666666666666 \n",
      "        Recall: 80.0\n",
      "        Precision:66.66666666666666\n",
      "        F1 score 66.66666666666666\n",
      "        \n",
      "Random State: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 1, 'kernel': 'poly', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\tAverage Accuracy: 81.42857142857142 \n",
      "      Average Specificity: 65.0 \n",
      "      Average Recall: 100.0\n",
      "      Average Precision:77.0\n",
      "      Average F1 score 85.47619047619048\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 100.0 \n",
      "        Specificity: 100.0 \n",
      "        Recall: 100.0\n",
      "        Precision:100.0\n",
      "        F1 score 100.0\n",
      "        \n",
      "Random State: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 1, 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\tAverage Accuracy: 100.0 \n",
      "      Average Specificity: 100.0 \n",
      "      Average Recall: 100.0\n",
      "      Average Precision:100.0\n",
      "      Average F1 score 100.0\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 62.5 \n",
      "        Specificity: 57.14285714285714 \n",
      "        Recall: 100.0\n",
      "        Precision:100.0\n",
      "        F1 score 72.72727272727272\n",
      "        \n",
      "Random State: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  8.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 0.1, 'kernel': 'sigmoid', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\tAverage Accuracy: 93.33333333333334 \n",
      "      Average Specificity: 86.66666666666666 \n",
      "      Average Recall: 100.0\n",
      "      Average Precision:90.0\n",
      "      Average F1 score 94.28571428571429\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 100.0 \n",
      "        Specificity: 100.0 \n",
      "        Recall: 100.0\n",
      "        Precision:100.0\n",
      "        F1 score 100.0\n",
      "        \n",
      "Random State: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 0.1, 'kernel': 'sigmoid', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\tAverage Accuracy: 97.14285714285714 \n",
      "      Average Specificity: 95.0 \n",
      "      Average Recall: 100.0\n",
      "      Average Precision:95.0\n",
      "      Average F1 score 97.14285714285714\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 62.5 \n",
      "        Specificity: 33.33333333333333 \n",
      "        Recall: 80.0\n",
      "        Precision:50.0\n",
      "        F1 score 40.0\n",
      "        \n",
      "Random State: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 1, 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\tAverage Accuracy: 76.66666666666666 \n",
      "      Average Specificity: 79.99999999999999 \n",
      "      Average Recall: 73.33333333333333\n",
      "      Average Precision:85.33333333333333\n",
      "      Average F1 score 74.33333333333333\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 87.5 \n",
      "        Specificity: 100.0 \n",
      "        Recall: 85.71428571428571\n",
      "        Precision:50.0\n",
      "        F1 score 66.66666666666667\n",
      "        \n",
      "Accuracy list:  [75.0, 100.0, 62.5, 100.0, 62.5, 87.5]\n",
      "Recall list:  [80.0, 100.0, 100.0, 100.0, 80.0, 85.71428571428571]\n",
      "Specificity list:  [66.66666666666666, 100.0, 57.14285714285714, 100.0, 33.33333333333333, 100.0]\n",
      "Precision list:  [66.66666666666666, 100.0, 100.0, 100.0, 50.0, 50.0]\n",
      "F1  score list:  [66.66666666666666, 100.0, 72.72727272727272, 100.0, 40.0, 66.66666666666667]\n",
      "\tAverage Accuracy: 81.25 \n",
      "      Average Specificity: 90.95238095238095 \n",
      "      Average Recall: 76.19047619047619\n",
      "      Average Precision:77.77777777777777\n",
      "      Average F1 score 74.34343434343434\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "train_test_SVC_TEST_avg_seeds('datasets/transformed/spontaneousDialogueOnly_google_bert_embeddings_transformed.csv',over_sample=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
