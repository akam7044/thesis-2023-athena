{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate modle code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def division_function(n, d):\n",
    "    if d:\n",
    "        return n / d\n",
    "    elif n == 0 and d == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def validate_model(model, X, Y, fold):\n",
    "    \"\"\"\n",
    "    validates the model with a k-fold validation which is iterated\n",
    "    returns the mean accuracy, specificiy, recall, precision, f1 score and auc score\n",
    "    \"\"\"\n",
    "\n",
    "    splits = 5\n",
    "    iteration = 10\n",
    "\n",
    "    acc_list = []\n",
    "    specificity_list = []\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    if fold == \"Strat\":\n",
    "        folds = StratifiedKFold(n_splits=splits)\n",
    "    elif fold == \"K\":\n",
    "        folds = KFold(splits, shuffle=True)\n",
    "\n",
    "    # Iterate \"interation\" times of k-fold\n",
    "    for i in range(1, iteration):\n",
    "        # print(f'Iteration {i}/{iteration}')\n",
    "\n",
    "        acc_total = 0\n",
    "        specificity_total = 0\n",
    "        recall_total = 0\n",
    "        precision_total = 0\n",
    "        f1_total = 0\n",
    "\n",
    "        for train_index, test_index in folds.split(X, Y):\n",
    "            x_train = X.iloc[train_index, :]\n",
    "            x_test = X.iloc[test_index, :]\n",
    "            y_train = Y.iloc[train_index, :]\n",
    "            y_test = Y.iloc[test_index, :]\n",
    "\n",
    "            # scale\n",
    "            sc = MinMaxScaler()\n",
    "            x_train = sc.fit_transform(x_train)\n",
    "            x_test = sc.transform(x_test)\n",
    "\n",
    "            # fit model and predict\n",
    "            model.fit(x_train, np.ravel(y_train))\n",
    "            y_pred = model.predict(x_test)\n",
    "\n",
    "            conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "            TN = conf_matrix[0][0]\n",
    "            FP = conf_matrix[0][1]\n",
    "            FN = conf_matrix[1][0]\n",
    "            TP = conf_matrix[1][1]\n",
    "\n",
    "            accuracy = (division_function((TP + TN), (TP + TN + FP + FN))) * 100\n",
    "            specificity = division_function(TN, (TN + FP)) * 100\n",
    "            recall = division_function(TP, (TP + FN)) * 100  # recall\n",
    "            precision = division_function(TP, (TP + FP)) * 100\n",
    "            f1_score = division_function(2 * (recall * precision), (recall + precision))\n",
    "\n",
    "            # sum it up\n",
    "            acc_total += accuracy\n",
    "            specificity_total += specificity\n",
    "            recall_total += recall\n",
    "            precision_total += precision\n",
    "            f1_total += f1_score\n",
    "\n",
    "        # avg\n",
    "        accuracy_mean = acc_total / splits\n",
    "        recall_mean = recall_total / splits\n",
    "        specificity_mean = specificity_total / splits\n",
    "        precision_mean = precision_total / splits\n",
    "        f1_mean = f1_total / splits\n",
    "\n",
    "        acc_list.append(accuracy_mean)\n",
    "        recall_list.append(recall_mean)\n",
    "        specificity_list.append(specificity_mean)\n",
    "        precision_list.append(precision_mean)\n",
    "        f1_list.append(f1_mean)\n",
    "\n",
    "    return (\n",
    "        np.mean(acc_list),\n",
    "        np.mean(specificity_list),\n",
    "        np.mean(recall_list),\n",
    "        np.mean(precision_list),\n",
    "        np.mean(f1_list)\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate modle code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_train, x_test, y_train, y_test):\n",
    "    sc = MinMaxScaler()\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.transform(x_test)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    TN = conf_matrix[0][0]\n",
    "    FP = conf_matrix[0][1]\n",
    "    FN = conf_matrix[1][0]\n",
    "    TP = conf_matrix[1][1]\n",
    "\n",
    "    accuracy = (division_function((TP + TN), (TP + TN + FP + FN))) * 100\n",
    "    specificity = division_function(TN, (TN + FP)) * 100\n",
    "    precision = division_function(TP, (TP + FP)) * 100\n",
    "    recall = division_function(TP, (TP + FN)) * 100  # recall\n",
    "    f1_score = division_function(2 * (recall * precision), (recall + precision))\n",
    "\n",
    "    return accuracy, specificity, recall, precision, f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from feature_reduction import feature_reduction_lda, feature_reduction_mrmr\n",
    "from imblearn.over_sampling import SMOTE\n",
    "path = '/Users/athena.kam/Documents/Thesis/codebase/thesis-2023-athena'\n",
    "os.chdir(path)\n",
    "\n",
    "CV_SPLIT = 5\n",
    "\n",
    "def get_best_param_LR(x_train, y_train):\n",
    "    param_grid = {\n",
    "        \"C\": [100, 10, 1.0, 0.1, 0.01],\n",
    "        \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"],\n",
    "        \"penalty\": [\"l1\", \"l2\"],\n",
    "    }\n",
    "    grid = GridSearchCV(\n",
    "        LogisticRegression(),\n",
    "        param_grid,\n",
    "        refit=True,\n",
    "        verbose=0,\n",
    "        return_train_score=True,\n",
    "        cv=CV_SPLIT,\n",
    "    )\n",
    "    grid.fit(x_train, y_train)\n",
    "    print(grid.best_estimator_.get_params())\n",
    "    return grid\n",
    "\n",
    "\n",
    "def train_test_LR(filename:str,hold_out:bool = True,include_personal_q:bool = False , grid_search:bool = True,reduce:bool = True,over_sample:bool = False,model_weights:dict = {},random_state:int = 0):\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    if include_personal_q:\n",
    "        df = df[df['noPersonalQ']!=1].reset_index(drop=True)\n",
    "    else:\n",
    "        df = df[df['personalQ']!=1].reset_index(drop=True)\n",
    "    \n",
    "    headers = df.columns\n",
    "    non_embeddings_headers = []\n",
    "    \n",
    "    for header in headers:\n",
    "        if header.find('embbedings')<0:\n",
    "            non_embeddings_headers.append(header)\n",
    "\n",
    "    X = df.drop(columns=non_embeddings_headers)\n",
    "    Y = df['classification']\n",
    "\n",
    "    # Feature Reduction \n",
    "    if reduce:\n",
    "        #x_train = feature_reduction_pca(x_train,0.9).values\n",
    "        #X = feature_reduction_lda(X,Y)\n",
    "        X = feature_reduction_mrmr(X,Y,25)\n",
    "        \n",
    "    else:\n",
    "        x_val = X.values\n",
    "        X = StandardScaler().fit_transform(x_val)\n",
    "    \n",
    "    # Test Train split\n",
    "    if hold_out:\n",
    "        x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.20,random_state=random_state)\n",
    "\n",
    "        # Oversample on training set\n",
    "        if over_sample:\n",
    "            sm = SMOTE(random_state=12)\n",
    "            x_train,y_train = sm.fit_resample(x_train, y_train) \n",
    "    else:\n",
    "        x_train = X\n",
    "        y_train = Y\n",
    "\n",
    "\n",
    "    if grid_search: \n",
    "        grid = get_best_param_LR(x_train=x_train,y_train=y_train) \n",
    "        model_svc = grid.best_estimator_\n",
    "    else:\n",
    "        model_svc = LogisticRegression(C = model_weights['C'],gamma=model_weights['gamma'],kernel=model_weights['kernel'])\n",
    "        \n",
    "    accuracy, specificiy, recall, precision, f1_score =validate_model(model_svc,pd.DataFrame(x_train),pd.DataFrame(y_train),\"Strat\")\n",
    "    print(f'\\tAverage Accuracy: {accuracy} \\n\\\n",
    "      Average Specificity: {specificiy} \\n\\\n",
    "      Average Recall: {recall}\\n\\\n",
    "      Average Precision:{precision}\\n\\\n",
    "      Average F1 score {f1_score}\\n\\\n",
    "      ')\n",
    "    \n",
    "    if hold_out:\n",
    "        accuracy, specificiy, recall, precision, f1_score =evaluate_model(model_svc,x_train,x_test,y_train,y_test)\n",
    "        print('____________________________________________')\n",
    "        print('Evaluate model')\n",
    "        print(f'\\tAccuracy: {accuracy} \\n\\\n",
    "        Specificity: {specificiy} \\n\\\n",
    "        Recall: {recall}\\n\\\n",
    "        Precision:{precision}\\n\\\n",
    "        F1 score {f1_score}\\n\\\n",
    "        ')\n",
    "        return accuracy, specificiy, recall, precision, f1_score\n",
    "    else: \n",
    "        return accuracy, specificiy, recall, precision, f1_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing different seeds (Hold out only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_TEST_avg_seeds(\n",
    "    filename: str,\n",
    "    hold_out: bool = True,\n",
    "    include_personal_q: bool = False,\n",
    "    grid_search: bool = True,\n",
    "    reduce: bool = True,\n",
    "    model_weights: dict = {},\n",
    "    over_sample: bool = False,\n",
    "):\n",
    "    random_states = [0, 5, 13, 27, 36, 42]\n",
    "    n_states = len(random_states)\n",
    "\n",
    "    acc_list = []\n",
    "    specificity_list = []\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    for random_state in random_states:\n",
    "        print(f\"Random State: {random_state}\")\n",
    "        accuracy, specificity, recall, precision, f1_score = train_test_LR(\n",
    "            filename=filename,\n",
    "            hold_out=hold_out,\n",
    "            include_personal_q=include_personal_q,\n",
    "            grid_search=grid_search,\n",
    "            reduce=reduce,\n",
    "            model_weights=model_weights,\n",
    "            random_state=random_state,\n",
    "            over_sample=over_sample,\n",
    "        )\n",
    "        acc_list.append(accuracy)\n",
    "        specificity_list.append(specificity)\n",
    "        recall_list.append(recall)\n",
    "        precision_list.append(precision)\n",
    "        f1_list.append(f1_score)\n",
    "\n",
    "    accuracy_mean = np.mean(acc_list)\n",
    "    specificity_mean = np.mean(specificity_list)\n",
    "    recall_mean = np.mean(recall_list)\n",
    "    precision_mean = np.mean(precision_list)\n",
    "    f1_mean = np.mean(f1_list)\n",
    "\n",
    "    print(\"Accuracy list: \", acc_list)\n",
    "    print(\"Specificity list: \", specificity_list)\n",
    "    print(\"Recall list: \", recall_list)\n",
    "    print(\"Precision list: \", precision_list)\n",
    "    print(\"F1  score list: \", f1_list)\n",
    "\n",
    "    print(\n",
    "        f\"\\tAverage Accuracy: {accuracy_mean} \\n\\\n",
    "      Average Specificity: {specificity_mean} \\n\\\n",
    "      Average Recall: {recall_mean}\\n\\\n",
    "      Average Precision:{precision_mean}\\n\\\n",
    "      Average F1 score {f1_mean}\\n\\\n",
    "      \"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:03<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\tAverage Accuracy: 94.28571428571429 \n",
      "      Average Specificity: 88.33333333333333 \n",
      "      Average Recall: 100.0\n",
      "      Average Precision:91.0\n",
      "      Average F1 score 94.92063492063491\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 87.5 \n",
      "        Specificity: 80.0 \n",
      "        Recall: 100.0\n",
      "        Precision:75.0\n",
      "        F1 score 85.71428571428571\n",
      "        \n",
      "Random State: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:03<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\tAverage Accuracy: 90.47619047619048 \n",
      "      Average Specificity: 81.66666666666666 \n",
      "      Average Recall: 100.0\n",
      "      Average Precision:87.0\n",
      "      Average F1 score 92.14285714285714\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 100.0 \n",
      "        Specificity: 100.0 \n",
      "        Recall: 100.0\n",
      "        Precision:100.0\n",
      "        F1 score 100.0\n",
      "        \n",
      "Random State: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:03<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\tAverage Accuracy: 93.05555555555556 \n",
      "      Average Specificity: 91.0 \n",
      "      Average Recall: 95.0\n",
      "      Average Precision:91.0\n",
      "      Average F1 score 92.77777777777779\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 75.0 \n",
      "        Specificity: 100.0 \n",
      "        Recall: 71.42857142857143\n",
      "        Precision:100.0\n",
      "        F1 score 83.33333333333333\n",
      "        \n",
      "Random State: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:02<00:00,  9.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\tAverage Accuracy: 93.80952380952381 \n",
      "      Average Specificity: 86.66666666666666 \n",
      "      Average Recall: 100.0\n",
      "      Average Precision:91.0\n",
      "      Average F1 score 94.92063492063491\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 87.5 \n",
      "        Specificity: 100.0 \n",
      "        Recall: 50.0\n",
      "        Precision:100.0\n",
      "        F1 score 66.66666666666667\n",
      "        \n",
      "Random State: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:02<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\tAverage Accuracy: 85.23809523809523 \n",
      "      Average Specificity: 81.66666666666666 \n",
      "      Average Recall: 88.33333333333333\n",
      "      Average Precision:86.0\n",
      "      Average F1 score 85.20634920634922\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 87.5 \n",
      "        Specificity: 100.0 \n",
      "        Recall: 66.66666666666666\n",
      "        Precision:100.0\n",
      "        F1 score 80.0\n",
      "        \n",
      "Random State: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:02<00:00,  9.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\tAverage Accuracy: 90.0 \n",
      "      Average Specificity: 86.66666666666666 \n",
      "      Average Recall: 93.33333333333333\n",
      "      Average Precision:88.33333333333333\n",
      "      Average F1 score 90.47619047619047\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 87.5 \n",
      "        Specificity: 85.71428571428571 \n",
      "        Recall: 100.0\n",
      "        Precision:50.0\n",
      "        F1 score 66.66666666666667\n",
      "        \n",
      "Accuracy list:  [87.5, 100.0, 75.0, 87.5, 87.5, 87.5]\n",
      "Specificity list:  [80.0, 100.0, 100.0, 100.0, 100.0, 85.71428571428571]\n",
      "Recall list:  [100.0, 100.0, 71.42857142857143, 50.0, 66.66666666666666, 100.0]\n",
      "Precision list:  [75.0, 100.0, 100.0, 100.0, 100.0, 50.0]\n",
      "F1  score list:  [85.71428571428571, 100.0, 83.33333333333333, 66.66666666666667, 80.0, 66.66666666666667]\n",
      "\tAverage Accuracy: 87.5 \n",
      "      Average Specificity: 94.28571428571428 \n",
      "      Average Recall: 81.34920634920634\n",
      "      Average Precision:87.5\n",
      "      Average F1 score 80.3968253968254\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "train_test_TEST_avg_seeds('datasets/transformed/spontaneousDialogueOnly_google_bert_embeddings_transformed.csv',over_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:02<00:00,  8.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\tAverage Accuracy: 88.0 \n",
      "      Average Specificity: 86.66666666666666 \n",
      "      Average Recall: 80.0\n",
      "      Average Precision:66.66666666666666\n",
      "      Average F1 score 72.0\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 90.9090909090909 \n",
      "        Specificity: 83.33333333333334 \n",
      "        Recall: 100.0\n",
      "        Precision:83.33333333333334\n",
      "        F1 score 90.9090909090909\n",
      "        \n",
      "Random State: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:02<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\tAverage Accuracy: 84.0 \n",
      "      Average Specificity: 83.33333333333333 \n",
      "      Average Recall: 83.33333333333333\n",
      "      Average Precision:83.33333333333333\n",
      "      Average F1 score 83.33333333333333\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 100.0 \n",
      "        Specificity: 100.0 \n",
      "        Recall: 100.0\n",
      "        Precision:100.0\n",
      "        F1 score 100.0\n",
      "        \n",
      "Random State: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:02<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\tAverage Accuracy: 88.0 \n",
      "      Average Specificity: 95.0 \n",
      "      Average Recall: 60.0\n",
      "      Average Precision:50.0\n",
      "      Average F1 score 53.333333333333336\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 72.72727272727273 \n",
      "        Specificity: 100.0 \n",
      "        Recall: 62.5\n",
      "        Precision:100.0\n",
      "        F1 score 76.92307692307692\n",
      "        \n",
      "Random State: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:03<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\tAverage Accuracy: 84.0 \n",
      "      Average Specificity: 86.66666666666666 \n",
      "      Average Recall: 80.0\n",
      "      Average Precision:83.33333333333333\n",
      "      Average F1 score 79.33333333333334\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 90.9090909090909 \n",
      "        Specificity: 100.0 \n",
      "        Recall: 66.66666666666666\n",
      "        Precision:100.0\n",
      "        F1 score 80.0\n",
      "        \n",
      "Random State: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:02<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\tAverage Accuracy: 84.0 \n",
      "      Average Specificity: 83.33333333333333 \n",
      "      Average Recall: 90.0\n",
      "      Average Precision:80.0\n",
      "      Average F1 score 79.33333333333334\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 81.81818181818183 \n",
      "        Specificity: 100.0 \n",
      "        Recall: 60.0\n",
      "        Precision:100.0\n",
      "        F1 score 75.0\n",
      "        \n",
      "Random State: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:03<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\tAverage Accuracy: 92.0 \n",
      "      Average Specificity: 93.33333333333333 \n",
      "      Average Recall: 90.0\n",
      "      Average Precision:93.33333333333333\n",
      "      Average F1 score 89.33333333333334\n",
      "      \n",
      "____________________________________________\n",
      "Evaluate model\n",
      "\tAccuracy: 90.9090909090909 \n",
      "        Specificity: 87.5 \n",
      "        Recall: 100.0\n",
      "        Precision:75.0\n",
      "        F1 score 85.71428571428571\n",
      "        \n",
      "Accuracy list:  [90.9090909090909, 100.0, 72.72727272727273, 90.9090909090909, 81.81818181818183, 90.9090909090909]\n",
      "Specificity list:  [83.33333333333334, 100.0, 100.0, 100.0, 100.0, 87.5]\n",
      "Recall list:  [100.0, 100.0, 62.5, 66.66666666666666, 60.0, 100.0]\n",
      "Precision list:  [83.33333333333334, 100.0, 100.0, 100.0, 100.0, 75.0]\n",
      "F1  score list:  [90.9090909090909, 100.0, 76.92307692307692, 80.0, 75.0, 85.71428571428571]\n",
      "\tAverage Accuracy: 87.87878787878788 \n",
      "      Average Specificity: 95.1388888888889 \n",
      "      Average Recall: 81.52777777777777\n",
      "      Average Precision:93.05555555555556\n",
      "      Average F1 score 84.75774225774227\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "train_test_TEST_avg_seeds('datasets/transformed/spontaneousDialogueOnly_google_bert_embeddings_transformed.csv',over_sample=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
